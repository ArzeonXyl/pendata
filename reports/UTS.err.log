Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/usr/local/lib/python3.11/dist-packages/nbclient/client.py", line 1319, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/asyncio/base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/usr/local/lib/python3.11/dist-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/usr/local/lib/python3.11/dist-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import pandas as pd
import numpy as np
# Load dataset dari UCI repository
url = "https://archive.ics.uci.edu/static/public/878/cirrhosis+patient+survival+prediction+dataset-1.zip"
data = pd.read_csv(url)
data.head()
data = data.dropna(subset=['Status']).copy()


data['Status'] = data['Status'].map({'C': 0, 'D': 1})
num_cols = data.select_dtypes(include=np.number).columns.drop('Status', errors='ignore')
medians = data[num_cols].median()

data[num_cols] = data[num_cols].fillna(medians)
cat_cols = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']
for col in cat_cols:
    if col in data.columns:
        modes = data[col].mode()
        if not modes.empty:
            data[col] = data[col].fillna(modes[0])
        else:
            print(f"WARNING: no mode found for '{col}', dropping this column.")
            data.drop(columns=[col], inplace=True)
for col in cat_cols:
    if col in data.columns:
        data[col] = pd.Categorical(data[col]).codes
print("Sisa missing per kolom:\n", data.isna().sum())
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
scaler = StandardScaler()
data[num_cols] = scaler.fit_transform(data[num_cols])
X = data.drop('Status', axis=1).values
y = data['Status'].values
nan_mask = np.isnan(data['Status'])
y = data['Status'][~nan_mask].values
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print("Preprocessing selesai. Ukuran dataset:", data.shape)
------------------

----- stdout -----
Sisa missing per kolom:
 ID                0
N_Days            0
Status           25
Drug              0
Age               0
Sex               0
Ascites           0
Hepatomegaly      0
Spiders           0
Edema             0
Bilirubin         0
Cholesterol       0
Albumin           0
Copper            0
Alk_Phos          0
SGOT              0
Tryglicerides     0
Platelets         0
Prothrombin       0
Stage             0
dtype: int64
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-4-46c38bdeafcb>[0m in [0;36m<cell line: 0>[0;34m()[0m
[1;32m     34[0m [0mnan_mask[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0misnan[0m[0;34m([0m[0mdata[0m[0;34m[[0m[0;34m'Status'[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     35[0m [0my[0m [0;34m=[0m [0mdata[0m[0;34m[[0m[0;34m'Status'[0m[0;34m][0m[0;34m[[0m[0;34m~[0m[0mnan_mask[0m[0;34m][0m[0;34m.[0m[0mvalues[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 36[0;31m X_train, X_test, y_train, y_test = train_test_split(
[0m[1;32m     37[0m     [0mX[0m[0;34m,[0m [0my[0m[0;34m,[0m [0mtest_size[0m[0;34m=[0m[0;36m0.2[0m[0;34m,[0m [0mrandom_state[0m[0;34m=[0m[0;36m42[0m[0;34m,[0m [0mstratify[0m[0;34m=[0m[0my[0m[0;34m[0m[0;34m[0m[0m
[1;32m     38[0m )

[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py[0m in [0;36mwrapper[0;34m(*args, **kwargs)[0m
[1;32m    214[0m                     )
[1;32m    215[0m                 ):
[0;32m--> 216[0;31m                     [0;32mreturn[0m [0mfunc[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    217[0m             [0;32mexcept[0m [0mInvalidParameterError[0m [0;32mas[0m [0me[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    218[0m                 [0;31m# When the function is just a wrapper around an estimator, we allow[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py[0m in [0;36mtrain_test_split[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)[0m
[1;32m   2846[0m         [0;32mraise[0m [0mValueError[0m[0;34m([0m[0;34m"At least one array required as input"[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m   2847[0m [0;34m[0m[0m
[0;32m-> 2848[0;31m     [0marrays[0m [0;34m=[0m [0mindexable[0m[0;34m([0m[0;34m*[0m[0marrays[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   2849[0m [0;34m[0m[0m
[1;32m   2850[0m     [0mn_samples[0m [0;34m=[0m [0m_num_samples[0m[0;34m([0m[0marrays[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py[0m in [0;36mindexable[0;34m(*iterables)[0m
[1;32m    530[0m [0;34m[0m[0m
[1;32m    531[0m     [0mresult[0m [0;34m=[0m [0;34m[[0m[0m_make_indexable[0m[0;34m([0m[0mX[0m[0;34m)[0m [0;32mfor[0m [0mX[0m [0;32min[0m [0miterables[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 532[0;31m     [0mcheck_consistent_length[0m[0;34m([0m[0;34m*[0m[0mresult[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    533[0m     [0;32mreturn[0m [0mresult[0m[0;34m[0m[0;34m[0m[0m
[1;32m    534[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py[0m in [0;36mcheck_consistent_length[0;34m(*arrays)[0m
[1;32m    473[0m     [0muniques[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0munique[0m[0;34m([0m[0mlengths[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    474[0m     [0;32mif[0m [0mlen[0m[0;34m([0m[0muniques[0m[0;34m)[0m [0;34m>[0m [0;36m1[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 475[0;31m         raise ValueError(
[0m[1;32m    476[0m             [0;34m"Found input variables with inconsistent numbers of samples: %r"[0m[0;34m[0m[0;34m[0m[0m
[1;32m    477[0m             [0;34m%[0m [0;34m[[0m[0mint[0m[0;34m([0m[0ml[0m[0;34m)[0m [0;32mfor[0m [0ml[0m [0;32min[0m [0mlengths[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: Found input variables with inconsistent numbers of samples: [418, 393]

