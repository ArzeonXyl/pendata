
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>ğŸ§© Clustering &#8212; Penambangan Data Aldi</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'k-mean_clustering';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Memahami Decision Tree: Dari Konsep Hingga Perhitungan" href="Decisiontree.html" />
    <link rel="prev" title="UTS Analisis data" href="UTS.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Penambangan Data Aldi - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Penambangan Data Aldi - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Selamat Datang di Proyek Penambangan Data Aldi
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="data_understanding.html">ğŸŒŸ Data Understanding</a></li>
<li class="toctree-l1"><a class="reference internal" href="deteksi_outlier.html">ğŸŒŸ Deteksi Outlier dengan K-Nearest Neighbors (KNN)</a></li>


<li class="toctree-l1"><a class="reference internal" href="LOF.html">1. Local Outlier Factor (LOF)</a></li>
<li class="toctree-l1"><a class="reference internal" href="naive_bayes.html">ğŸ“Œ Penjelasan NaÃ¯ve Bayes &amp; Alasan Langkah-langkahnya</a></li>


<li class="toctree-l1"><a class="reference internal" href="UTS.html">UTS Analisis data</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">ğŸ§© Clustering</a></li>






<li class="toctree-l1"><a class="reference internal" href="Decisiontree.html">Memahami Decision Tree: Dari Konsep Hingga Perhitungan</a></li>
<li class="toctree-l1"><a class="reference internal" href="Diskritisasi.html">Diskritisasi</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_mining_PRA_UAS.html">penjelasan dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="UAS.html">UAS</a></li>

</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fk-mean_clustering.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/k-mean_clustering.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>ğŸ§© Clustering</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">ğŸ§© Clustering</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-clustering">ğŸ” Apa itu Clustering?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mengapa-clustering-penting">ğŸ¯ Mengapa Clustering Penting?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jenis-clustering">âš™ï¸ Jenis Clustering</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fokus-kita-k-means-clustering">ğŸ† Fokus Kita: K-Means Clustering</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#instalasi-pustaka-untuk-load-database-di-google-colab">ğŸ—ï¸ Instalasi Pustaka untuk Load Database di Google Colab</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mengapa-perlu-instalasi-pustaka">ğŸ” Mengapa Perlu Instalasi Pustaka?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-instalasi-pustaka">âš¡ Langkah Instalasi Pustaka</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#koneksi-ke-database-mysql-di-google-colab">ğŸ”— Koneksi ke Database MySQL di Google Colab</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-koneksi-ke-database">ğŸ“Œ Langkah Koneksi ke Database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#informasi-koneksi">ğŸ—ï¸ Informasi Koneksi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kode-koneksi-ke-database">âš¡ Kode Koneksi ke Database</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#menghitung-jarak-ke-centroid-dalam-k-means-clustering">ğŸ“ Menghitung Jarak ke Centroid dalam K-Means Clustering</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-jarak-ke-centroid">ğŸ” Apa Itu Jarak ke Centroid?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rumus-jarak-euclidean">ğŸ“ Rumus Jarak Euclidean</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#proses-perhitungan-jarak-dalam-k-means">âš™ï¸ Proses Perhitungan Jarak dalam K-Means</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mengapa-jarak-euclidean-digunakan">ğŸ† Mengapa Jarak Euclidean Digunakan?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-k-means-clustering-pada-dataset-iris">ğŸ“Š Implementasi K-Means Clustering pada Dataset Iris</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means">ğŸ”k-means</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-implementasi">âš™ï¸ Langkah-langkah Implementasi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-visualisasi">ğŸ¨ Hasil Visualisasi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#informasi-tambahan">ğŸ” Informasi tambahan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-akhir-k-means-clustering">Hasil Akhir K-Means Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#centroid-akhir">Centroid Akhir:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cluster-assignment-untuk-setiap-titik-data">Cluster Assignment untuk Setiap Titik Data:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#centroid-akhir-per-fitur-setiap-cluster">Centroid Akhir per Fitur (Setiap Cluster):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretasi-singkat">Interpretasi Singkat:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#memahami-inertia-dalam-k-means-clustering">ğŸ” Memahami Inertia dalam K-Means Clustering ğŸ’¡</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-inertia">ğŸ“Œ Apa Itu Inertia?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rumus-inertia">ğŸ“ Rumus Inertia</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#peran-inertia-dalam-menentukan-jumlah-klaster-optimal-k">ğŸ¯ Peran Inertia dalam Menentukan Jumlah Klaster Optimal (K)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretasi-nilai-inertia">ğŸ† Interpretasi Nilai Inertia</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#penjelasan-kode-mencari-inertia-untuk-k-means-clustering">Penjelasan Kode: Mencari Inertia untuk K-Means Clustering</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metode-elbow-menentukan-jumlah-cluster-optimal-dalam-k-means">ğŸ“‰ Metode Elbow: Menentukan Jumlah Cluster Optimal dalam K-Means</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cara-kerja-metode-elbow">âš™ï¸ Cara Kerja Metode Elbow</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#code-elbow">code elbow</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretasi-grafik-elbow">ğŸ’¡ Interpretasi Grafik Elbow</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metode-elbow-menentukan-jumlah-cluster-optimal-k-dalam-k-means-fokus-pada-k-3">ğŸ“‰ Metode Elbow: Menentukan Jumlah Cluster Optimal (K) dalam K-Means (Fokus pada K=3)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretasi-grafik-elbow-dengan-siku-di-k-3">âš™ï¸ Interpretasi Grafik Elbow dengan Siku di K=3</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#memahami-silhouette-score-dalam-clustering">Memahami Silhouette Score dalam Clustering ğŸ§â†”ï¸ğŸ§â€â™€ï¸</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rumus-silhouette-score">Rumus Silhouette Score ğŸ“</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretasi-nilai-silhouette-score">Interpretasi Nilai Silhouette Score ğŸ¤”</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan-sementara">Kesimpulan Sementara ğŸ¤”</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#penggunaan-silhouette-score-dalam-praktik">Penggunaan Silhouette Score dalam Praktik ğŸ› ï¸</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kelebihan-silhouette-score">Kelebihan Silhouette Score âœ¨</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kekurangan-silhouette-score">Kekurangan Silhouette Score âš ï¸</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritma-fuzzy-c-mean-clustering-fcm">algoritma Fuzzy C-Mean Clustering (FCM)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-fcm">Langkah-langkah FCM:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#iterasi-1">Iterasi 1</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#perhitungan-pusat-cluster-v-1">1. Perhitungan Pusat Cluster (<span class="math notranslate nohighlight">\(V^{(1)}\)</span>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#perhitungan-matriks-keanggotaan-u-1">2. Perhitungan Matriks Keanggotaan (<span class="math notranslate nohighlight">\(U^{(1)}\)</span>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#perhitungan-fungsi-objektif-j-1-opsional-untuk-verifikasi">3. Perhitungan Fungsi Objektif (<span class="math notranslate nohighlight">\(J^{(1)}\)</span>) (Opsional, untuk verifikasi)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#normalisasi-data">normalisasi data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#penjelasan-normalisasi-min-max-scaling">Penjelasan Normalisasi (Min-Max Scaling)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mengapa-normalisasi-penting">Mengapa Normalisasi Penting?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bagaimana-minmaxscaler-bekerja">Bagaimana <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code> Bekerja?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-dalam-kode-anda">Implementasi dalam Kode Anda:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluasi-akurasi-dengan-pseudo-true-labels">EVALUASI AKURASI DENGAN PSEUDO-TRUE-LABELS</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="clustering">
<h1>ğŸ§© Clustering<a class="headerlink" href="#clustering" title="Link to this heading">#</a></h1>
<section id="apa-itu-clustering">
<h2>ğŸ” Apa itu Clustering?<a class="headerlink" href="#apa-itu-clustering" title="Link to this heading">#</a></h2>
<p>Clustering adalah metode dalam <strong>unsupervised learning</strong> yang digunakan untuk <strong>mengelompokkan data</strong> berdasarkan kemiripan antara elemen-elemen dalam dataset. ğŸ“ŠğŸ’¡</p>
<p>Dalam clustering, model berusaha menemukan pola dalam data tanpa label, lalu <strong>mengelompokkannya ke dalam beberapa klaster yang memiliki karakteristik serupa</strong>. ğŸ·ï¸ğŸ”</p>
</section>
<section id="mengapa-clustering-penting">
<h2>ğŸ¯ Mengapa Clustering Penting?<a class="headerlink" href="#mengapa-clustering-penting" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>ğŸ“Œ <strong>Analisis Data</strong> â€“ Membantu menemukan struktur tersembunyi dalam data tanpa perlu label.</p></li>
<li><p>ğŸ¨ <strong>Segmentasi Pelanggan</strong> â€“ Digunakan dalam bisnis untuk mengelompokkan pelanggan berdasarkan perilaku mereka.</p></li>
<li><p>ğŸ”¬ <strong>Pengenalan Pola</strong> â€“ Berguna dalam pengolahan gambar, pengelompokan teks, dan analisis tren.</p></li>
</ul>
</section>
<section id="jenis-clustering">
<h2>âš™ï¸ Jenis Clustering<a class="headerlink" href="#jenis-clustering" title="Link to this heading">#</a></h2>
<p>Ada beberapa metode clustering yang umum digunakan:</p>
<p>1ï¸âƒ£ <strong>K-Means Clustering</strong> ğŸ† â€“ Mengelompokkan data berdasarkan pusat klaster (<em>centroids</em>).<br />
2ï¸âƒ£ <strong>Hierarchical Clustering</strong> ğŸŒ³ â€“ Membentuk hierarki klaster secara bertahap.<br />
3ï¸âƒ£ <strong>DBSCAN</strong> ğŸ› ï¸ â€“ Mampu menangani data dengan distribusi tidak teratur, termasuk <em>outlier</em>.</p>
</section>
<section id="fokus-kita-k-means-clustering">
<h2>ğŸ† Fokus Kita: K-Means Clustering<a class="headerlink" href="#fokus-kita-k-means-clustering" title="Link to this heading">#</a></h2>
<p>Pada tutorial ini, kita akan berfokus pada <strong>K-Means Clustering</strong>, salah satu metode yang paling populer dan efisien dalam mengelompokkan data! ğŸš€ğŸ”µğŸŸ¢ğŸŸ </p>
<hr class="docutils" />
<p>ğŸ“ <strong>Selanjutnya:</strong> Kita akan menentukan jumlah klaster yang optimal dengan <strong>Metode Elbow</strong> dan <strong>Silhouette Score</strong> sebelum mengimplementasikan K-Means di Python! ğŸâš¡</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="instalasi-pustaka-untuk-load-database-di-google-colab">
<h1>ğŸ—ï¸ Instalasi Pustaka untuk Load Database di Google Colab<a class="headerlink" href="#instalasi-pustaka-untuk-load-database-di-google-colab" title="Link to this heading">#</a></h1>
<section id="mengapa-perlu-instalasi-pustaka">
<h2>ğŸ” Mengapa Perlu Instalasi Pustaka?<a class="headerlink" href="#mengapa-perlu-instalasi-pustaka" title="Link to this heading">#</a></h2>
<p>Sebelum kita bisa memuat database MySQL ke dalam <strong>Google Colab</strong>, kita harus menginstal beberapa pustaka penting terlebih dahulu. ğŸ“¦âœ¨<br />
Pustaka ini membantu kita dalam proses koneksi ke database, manipulasi data, dan penyajian hasil yang lebih rapi.</p>
</section>
<section id="langkah-instalasi-pustaka">
<h2>âš¡ Langkah Instalasi Pustaka<a class="headerlink" href="#langkah-instalasi-pustaka" title="Link to this heading">#</a></h2>
<p>Jalankan perintah berikut di <strong>Google Colab</strong> untuk menginstal pustaka yang diperlukan:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">pymysql</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">pandas</span> <span class="n">tabulate</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">pymysql</span> <span class="n">sqlalchemy</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pymysql
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pandas
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>tabulate
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pymysql<span class="w"> </span>sqlalchemy
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pymysql in /usr/local/lib/python3.11/dist-packages (1.1.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)
Requirement already satisfied: numpy&gt;=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.17.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pymysql in /usr/local/lib/python3.11/dist-packages (1.1.1)
Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.41)
Requirement already satisfied: greenlet&gt;=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.2.3)
Requirement already satisfied: typing-extensions&gt;=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.14.0)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="koneksi-ke-database-mysql-di-google-colab">
<h1>ğŸ”— Koneksi ke Database MySQL di Google Colab<a class="headerlink" href="#koneksi-ke-database-mysql-di-google-colab" title="Link to this heading">#</a></h1>
<section id="langkah-koneksi-ke-database">
<h2>ğŸ“Œ Langkah Koneksi ke Database<a class="headerlink" href="#langkah-koneksi-ke-database" title="Link to this heading">#</a></h2>
<p>Setelah menginstal pustaka yang diperlukan, kita akan <strong>membuat koneksi</strong> ke database <strong>MySQL</strong> menggunakan <strong>SQLAlchemy</strong> dan memuat data ke dalam <strong>Pandas DataFrame</strong> untuk analisis lebih lanjut. ğŸš€âœ¨</p>
</section>
<section id="informasi-koneksi">
<h2>ğŸ—ï¸ Informasi Koneksi<a class="headerlink" href="#informasi-koneksi" title="Link to this heading">#</a></h2>
<p>Untuk terhubung ke database MySQL, kita perlu informasi berikut:
ğŸ”¹ <strong>Host</strong> â€“ Alamat server database.<br />
ğŸ”¹ <strong>Port</strong> â€“ Nomor port tempat database berjalan.<br />
ğŸ”¹ <strong>Nama Database</strong> â€“ Nama database yang ingin diakses.<br />
ğŸ”¹ <strong>Username &amp; Password</strong> â€“ Kredensial untuk autentikasi akses.</p>
</section>
<section id="kode-koneksi-ke-database">
<h2>âš¡ Kode Koneksi ke Database<a class="headerlink" href="#kode-koneksi-ke-database" title="Link to this heading">#</a></h2>
<p>Gunakan skrip berikut untuk membuat koneksi ke database MySQL dan membaca data dari tabel <code class="docutils literal notranslate"><span class="pre">iris</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sqlalchemy</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_engine</span>

<span class="c1"># Info koneksi MySQL</span>
<span class="n">DB_HOST</span> <span class="o">=</span> <span class="s2">&quot;mysql-34425cbd-irismysqlaldi.h.aivencloud.com&quot;</span>
<span class="n">DB_PORT</span> <span class="o">=</span> <span class="mi">22476</span>
<span class="n">DB_NAME</span> <span class="o">=</span> <span class="s2">&quot;iris_baru&quot;</span>
<span class="n">DB_USER</span> <span class="o">=</span> <span class="s2">&quot;avnadmin&quot;</span>
<span class="n">DB_PASS</span> <span class="o">=</span> <span class="s2">&quot;AVNS_QsQ7Yf7zzcmrk83yFgg&quot;</span>

<span class="c1"># Buat koneksi ke database via SQLAlchemy</span>
<span class="n">engine</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mysql+pymysql://</span><span class="si">{</span><span class="n">DB_USER</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">DB_PASS</span><span class="si">}</span><span class="s2">@</span><span class="si">{</span><span class="n">DB_HOST</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">DB_PORT</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">DB_NAME</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Query contoh: ambil semua data dari tabel iris</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;SELECT * FROM iris&quot;</span>

<span class="c1"># Load hasil query ke DataFrame</span>
<span class="n">data_iris</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">engine</span><span class="p">)</span>

<span class="c1"># Hapus kolom &#39;species&#39; dari DataFrame</span>
<span class="n">data_iris</span> <span class="o">=</span> <span class="n">data_iris</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">])</span>

<span class="c1"># Tampilkan hasil</span>
<span class="n">data_iris</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sqlalchemy</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_engine</span>

<span class="c1"># Info koneksi MySQL</span>
<span class="n">DB_HOST</span> <span class="o">=</span> <span class="s2">&quot;mysql-34425cbd-irismysqlaldi.h.aivencloud.com&quot;</span>
<span class="n">DB_PORT</span> <span class="o">=</span> <span class="mi">22476</span>
<span class="n">DB_NAME</span> <span class="o">=</span> <span class="s2">&quot;iris_baru&quot;</span>
<span class="n">DB_USER</span> <span class="o">=</span> <span class="s2">&quot;avnadmin&quot;</span>
<span class="n">DB_PASS</span> <span class="o">=</span> <span class="s2">&quot;AVNS_QsQ7Yf7zzcmrk83yFgg&quot;</span>

<span class="c1"># Buat koneksi ke database via SQLAlchemy</span>
<span class="n">engine</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mysql+pymysql://</span><span class="si">{</span><span class="n">DB_USER</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">DB_PASS</span><span class="si">}</span><span class="s2">@</span><span class="si">{</span><span class="n">DB_HOST</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">DB_PORT</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">DB_NAME</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Query contoh: ambil semua data dari tabel iris</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;SELECT * FROM iris&quot;</span>

<span class="c1"># Load hasil query ke DataFrame</span>
<span class="n">data_iris</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">engine</span><span class="p">)</span>
<span class="c1"># Hapus kolom &#39;species&#39; dari DataFrame df</span>
<span class="n">data_iris</span> <span class="o">=</span> <span class="n">data_iris</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">])</span>


<span class="c1"># Tampilkan hasil</span>
<span class="n">data_iris</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-b73981e5-89c6-4361-8664-af7c30eacb82" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>sepal_length_cm</th>
      <th>sepal_width_cm</th>
      <th>petal_length_cm</th>
      <th>petal_width_cm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">
      
  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-b73981e5-89c6-4361-8664-af7c30eacb82')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">
      
  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>
    
  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-b73981e5-89c6-4361-8664-af7c30eacb82 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-b73981e5-89c6-4361-8664-af7c30eacb82');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>
  
    </div>
  </div>
  </div></div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="menghitung-jarak-ke-centroid-dalam-k-means-clustering">
<h1>ğŸ“ Menghitung Jarak ke Centroid dalam K-Means Clustering<a class="headerlink" href="#menghitung-jarak-ke-centroid-dalam-k-means-clustering" title="Link to this heading">#</a></h1>
<section id="apa-itu-jarak-ke-centroid">
<h2>ğŸ” Apa Itu Jarak ke Centroid?<a class="headerlink" href="#apa-itu-jarak-ke-centroid" title="Link to this heading">#</a></h2>
<p>Dalam <strong>K-Means Clustering</strong>, setiap titik data dikaitkan dengan <strong>klaster terdekat</strong>, yang ditentukan berdasarkan <strong>jarak</strong> ke pusat klaster (<em>centroid</em>).<br />
Metode yang paling umum digunakan untuk mengukur jarak dalam K-Means adalah <strong>jarak Euclidean</strong>. ğŸ“ŠğŸ’¡</p>
</section>
<section id="rumus-jarak-euclidean">
<h2>ğŸ“ Rumus Jarak Euclidean<a class="headerlink" href="#rumus-jarak-euclidean" title="Link to this heading">#</a></h2>
<p>Jarak antara titik data ( x ) dan centroid ( \mu ) dihitung menggunakan <strong>rumus Euclidean</strong> berikut:</p>
<div class="math notranslate nohighlight">
\[
d(x, \mu) = \sqrt{\sum_{i=1}^{m} (x_i - \mu_i)^2}
\]</div>
<p>Dimana:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> = titik data yang akan diklasifikasikan</p></li>
<li><p><span class="math notranslate nohighlight">\(\mu\)</span> = pusat klaster (<em>centroid</em>)</p></li>
<li><p><span class="math notranslate nohighlight">\(x_i\)</span> = koordinat fitur ke-<span class="math notranslate nohighlight">\(i\)</span> dari titik data</p></li>
<li><p><span class="math notranslate nohighlight">\(\mu_i\)</span> = koordinat fitur ke-<span class="math notranslate nohighlight">\(i\)</span> dari centroid</p></li>
<li><p><span class="math notranslate nohighlight">\(m\)</span> = jumlah fitur dalam dataset</p></li>
</ul>
</section>
<section id="proses-perhitungan-jarak-dalam-k-means">
<h2>âš™ï¸ Proses Perhitungan Jarak dalam K-Means<a class="headerlink" href="#proses-perhitungan-jarak-dalam-k-means" title="Link to this heading">#</a></h2>
<p>1ï¸âƒ£ <strong>Menginisialisasi centroid secara acak</strong> pada tahap awal algoritma. ğŸ¯<br />
2ï¸âƒ£ <strong>Menghitung jarak Euclidean</strong> antara setiap titik data dan semua centroid. ğŸ“<br />
3ï¸âƒ£ <strong>Menetapkan titik data ke klaster terdekat</strong> berdasarkan jarak terkecil. ğŸ”„<br />
4ï¸âƒ£ <strong>Menghitung ulang centroid</strong> dengan mengambil rata-rata semua titik dalam klaster. âœ¨<br />
5ï¸âƒ£ <strong>Mengulangi proses</strong> sampai centroid tidak berubah lagi. âœ…</p>
</section>
<section id="mengapa-jarak-euclidean-digunakan">
<h2>ğŸ† Mengapa Jarak Euclidean Digunakan?<a class="headerlink" href="#mengapa-jarak-euclidean-digunakan" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Mudah dihitung</strong> secara komputasional.</p></li>
<li><p><strong>Memberikan pemisahan yang jelas</strong> antara klaster berdasarkan kedekatan geometris.</p></li>
<li><p><strong>Efektif dalam data dengan distribusi yang seragam</strong> tanpa banyak <em>outlier</em>.</p></li>
</ul>
<hr class="docutils" />
<p>ğŸ’¡ <strong>Selanjutnya:</strong> Setelah memahami cara menghitung jarak ke centroid, kita akan melihat bagaimana <strong>K-Means memproses data hingga mencapai konvergensi</strong>! ğŸš€ğŸ”¥</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="implementasi-k-means-clustering-pada-dataset-iris">
<h1>ğŸ“Š Implementasi K-Means Clustering pada Dataset Iris<a class="headerlink" href="#implementasi-k-means-clustering-pada-dataset-iris" title="Link to this heading">#</a></h1>
<section id="k-means">
<h2>ğŸ”k-means<a class="headerlink" href="#k-means" title="Link to this heading">#</a></h2>
<p>K-Means Clustering adalah algoritma <strong>unsupervised learning</strong> yang digunakan untuk <strong>mengelompokkan data</strong> ke dalam beberapa klaster berdasarkan kemiripan fitur.<br />
Pada contoh ini, kita akan menggunakan dataset <strong>Iris</strong> dan menerapkan <strong>K-Means Clustering</strong> untuk mengelompokkan data menjadi <strong>3 klaster</strong> berdasarkan fitur-fitur dalam dataset.</p>
</section>
<hr class="docutils" />
<section id="langkah-langkah-implementasi">
<h2>âš™ï¸ Langkah-langkah Implementasi<a class="headerlink" href="#langkah-langkah-implementasi" title="Link to this heading">#</a></h2>
<p>1ï¸âƒ£ <strong>Import pustaka yang diperlukan</strong>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">numpy</span></code> untuk manipulasi numerik</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> untuk visualisasi</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sklearn.cluster.KMeans</span></code> untuk implementasi K-Means</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sklearn.datasets.load_iris</span></code> untuk memuat dataset Iris</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sklearn.decomposition.PCA</span></code> untuk reduksi dimensi</p></li>
</ul>
<p>2ï¸âƒ£ <strong>Load dataset Iris</strong>:</p>
<ul class="simple">
<li><p>Dataset Iris terdiri dari <strong>empat fitur</strong> untuk masing-masing sampel bunga.</p></li>
<li><p>Fitur yang digunakan: <em>sepal length, sepal width, petal length, petal width</em>.</p></li>
</ul>
<p>3ï¸âƒ£ <strong>Menentukan jumlah klaster (K)</strong>:</p>
<ul class="simple">
<li><p>Dalam contoh ini, kita menetapkan <strong>K = 3</strong>, sesuai dengan jumlah spesies dalam dataset Iris.</p></li>
</ul>
<p>4ï¸âƒ£ <strong>Inisialisasi dan pelatihan model K-Means</strong>:</p>
<ul class="simple">
<li><p>Parameter yang digunakan dalam K-Means:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">n_clusters=3</span></code> (jumlah klaster)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">init='k-means++'</span></code> (strategi pemilihan centroid awal)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_iter=500</span></code> (batas jumlah iterasi)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tol=0.000001</span></code> (toleransi konvergensi)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">algorithm='lloyd'</span></code> (algoritma klasik untuk K-Means)</p></li>
</ul>
</li>
<li><p>Model dilatih menggunakan <code class="docutils literal notranslate"><span class="pre">.fit(X)</span></code>, di mana <code class="docutils literal notranslate"><span class="pre">X</span></code> adalah fitur dari dataset Iris.</p></li>
</ul>
<p>5ï¸âƒ£ <strong>Mengambil hasil clustering</strong>:</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">kmeans.cluster_centers_</span></code></strong>: Posisi centroid setelah konvergensi.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">kmeans.labels_</span></code></strong>: Label klaster untuk setiap titik data dalam dataset.</p></li>
</ul>
<p>6ï¸âƒ£ <strong>Reduksi dimensi menggunakan PCA</strong>:</p>
<ul class="simple">
<li><p>PCA digunakan untuk <strong>mengurangi jumlah fitur dari 4 menjadi 2</strong>, sehingga data bisa divisualisasikan dengan lebih mudah.</p></li>
<li><p>Transformasi dilakukan menggunakan <code class="docutils literal notranslate"><span class="pre">PCA(n_components=2)</span></code>.</p></li>
</ul>
<p>7ï¸âƒ£ <strong>Visualisasi hasil clustering</strong>:</p>
<ul class="simple">
<li><p>Data yang telah direduksi dimensinya diplot berdasarkan label klasternya.</p></li>
<li><p>Centroid ditampilkan dengan simbol <strong>X</strong> berwarna hitam agar mudah dikenali.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="hasil-visualisasi">
<h2>ğŸ¨ Hasil Visualisasi<a class="headerlink" href="#hasil-visualisasi" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Grafik menunjukkan pembagian klaster berdasarkan hasil K-Means Clustering</strong>.</p></li>
<li><p><strong>Centroid ditandai dengan titik hitam</strong>, yang menunjukkan titik tengah dari masing-masing klaster.</p></li>
<li><p>Dengan PCA, kita bisa melihat bagaimana data dikelompokkan dalam <strong>ruang dua dimensi</strong> berdasarkan komponen utama.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="informasi-tambahan">
<h2>ğŸ” Informasi tambahan<a class="headerlink" href="#informasi-tambahan" title="Link to this heading">#</a></h2>
<p>Selain visualisasi, model juga mencetak:</p>
<ul class="simple">
<li><p><strong>Koordinat centroid akhir</strong> setelah iterasi K-Means selesai.</p></li>
<li><p><strong>Label klaster untuk masing-masing sampel</strong> dalam dataset.</p></li>
<li><p><strong>Rata-rata setiap fitur per klaster</strong> setelah proses clustering selesai.</p></li>
</ul>
<hr class="docutils" />
<p>ğŸ’¡ <strong>Selanjutnya:</strong> Kita bisa mengevaluasi hasil clustering dengan <strong>Metode Elbow</strong> atau <strong>Silhouette Score</strong> untuk menentukan jumlah klaster optimal! ğŸš€ğŸ”¥</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>

<span class="c1"># Load dataset Iris</span>
<span class="n">data_iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data_iris</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># Fitur dataset</span>

<span class="c1"># Tentukan jumlah cluster (K)</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># 1. Inisialisasi K-Means dengan jumlah cluster K dan parameter sesuai dokumentasi</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span>
    <span class="n">n_clusters</span><span class="o">=</span><span class="n">K</span><span class="p">,</span>
    <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span>
    <span class="n">n_init</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span>
    <span class="n">tol</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">copy_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;lloyd&#39;</span>
<span class="p">)</span>

<span class="c1"># 2. Latih model K-Means pada data</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># 3. Ambil hasil clustering</span>
<span class="n">centroids</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>  <span class="c1"># Centroid akhir</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>  <span class="c1"># Label cluster untuk tiap titik data</span>

<span class="c1"># 4. Reduksi dimensi menggunakan PCA untuk visualisasi (menggunakan 2 komponen utama)</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>



<span class="c1"># Outputkan centroid dan label cluster untuk setiap titik data</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Centroid akhir:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">centroids</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Cluster assignment untuk setiap titik data:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">clusters</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Centroid akhir per fitur (setiap cluster):&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cluster </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data_iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">centroids</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Centroid akhir:
[[6.85384615 3.07692308 5.71538462 2.05384615]
 [5.006      3.428      1.462      0.246     ]
 [5.88360656 2.74098361 4.38852459 1.43442623]]

Cluster assignment untuk setiap titik data:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 0 0 2 0 0 0 0
 0 0 2 2 0 0 0 0 2 0 2 0 2 0 0 2 2 0 0 0 0 0 2 0 0 0 0 2 0 0 0 2 0 0 0 2 0
 0 2]

Centroid akhir per fitur (setiap cluster):
Cluster 1:
  sepal length (cm): 6.8538
  sepal width (cm): 3.0769
  petal length (cm): 5.7154
  petal width (cm): 2.0538

Cluster 2:
  sepal length (cm): 5.0060
  sepal width (cm): 3.4280
  petal length (cm): 1.4620
  petal width (cm): 0.2460

Cluster 3:
  sepal length (cm): 5.8836
  sepal width (cm): 2.7410
  petal length (cm): 4.3885
  petal width (cm): 1.4344
</pre></div>
</div>
</div>
</div>
</section>
<section id="hasil-akhir-k-means-clustering">
<h2>Hasil Akhir K-Means Clustering<a class="headerlink" href="#hasil-akhir-k-means-clustering" title="Link to this heading">#</a></h2>
<p>Berikut adalah hasil akhir dari algoritma K-Means Clustering yang telah dijalankan:</p>
<section id="centroid-akhir">
<h3>Centroid Akhir:<a class="headerlink" href="#centroid-akhir" title="Link to this heading">#</a></h3>
<p>Array di atas menunjukkan koordinat dari pusat (centroid) dari tiga cluster yang telah ditemukan. Setiap baris merepresentasikan satu centroid, dan setiap kolom merepresentasikan nilai rata-rata fitur untuk cluster tersebut.</p>
<ul class="simple">
<li><p><strong>Centroid 1:</strong> <code class="docutils literal notranslate"><span class="pre">[6.85384615</span> <span class="pre">3.07692308</span> <span class="pre">5.71538462</span> <span class="pre">2.05384615]</span></code></p></li>
<li><p><strong>Centroid 2:</strong> <code class="docutils literal notranslate"><span class="pre">[5.006</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">3.428</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">1.462</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">0.246</span>&#160;&#160;&#160;&#160; <span class="pre">]</span></code></p></li>
<li><p><strong>Centroid 3:</strong> <code class="docutils literal notranslate"><span class="pre">[5.88360656</span> <span class="pre">2.74098361</span> <span class="pre">4.38852459</span> <span class="pre">1.43442623]</span></code></p></li>
</ul>
</section>
<section id="cluster-assignment-untuk-setiap-titik-data">
<h3>Cluster Assignment untuk Setiap Titik Data:<a class="headerlink" href="#cluster-assignment-untuk-setiap-titik-data" title="Link to this heading">#</a></h3>
<p>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 0 0 2 0 0 0 0
0 0 2 2 0 0 0 0 2 0 2 0 2 0 0 2 2 0 0 0 0 0 2 0 0 0 0 2 0 0 0 2 0 0 0 2 0
0 2]</p>
<p>Array ini menunjukkan cluster mana yang telah ditetapkan ke setiap titik data dalam dataset. Indeks array sesuai dengan indeks titik data, dan nilai pada indeks tersebut menunjukkan nomor cluster (dimulai dari 0).</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">1</span></code>: Titik data masuk ke dalam Cluster 2.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0</span></code>: Titik data masuk ke dalam Cluster 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">2</span></code>: Titik data masuk ke dalam Cluster 3.</p></li>
</ul>
</section>
<section id="centroid-akhir-per-fitur-setiap-cluster">
<h3>Centroid Akhir per Fitur (Setiap Cluster):<a class="headerlink" href="#centroid-akhir-per-fitur-setiap-cluster" title="Link to this heading">#</a></h3>
<p>Berikut adalah nilai centroid akhir untuk setiap fitur dalam setiap cluster:</p>
<p><strong>Cluster 1:</strong></p>
<ul class="simple">
<li><p>Sepal Length (cm): 6.8538</p></li>
<li><p>Sepal Width (cm): 3.0769</p></li>
<li><p>Petal Length (cm): 5.7154</p></li>
<li><p>Petal Width (cm): 2.0538</p></li>
</ul>
<p><strong>Cluster 2:</strong></p>
<ul class="simple">
<li><p>Sepal Length (cm): 5.0060</p></li>
<li><p>Sepal Width (cm): 3.4280</p></li>
<li><p>Petal Length (cm): 1.4620</p></li>
<li><p>Petal Width (cm): 0.2460</p></li>
</ul>
<p><strong>Cluster 3:</strong></p>
<ul class="simple">
<li><p>Sepal Length (cm): 5.8836</p></li>
<li><p>Sepal Width (cm): 2.7410</p></li>
<li><p>Petal Length (cm): 4.3885</p></li>
<li><p>Petal Width (cm): 1.4344</p></li>
</ul>
</section>
<section id="interpretasi-singkat">
<h3>Interpretasi Singkat:<a class="headerlink" href="#interpretasi-singkat" title="Link to this heading">#</a></h3>
<p>Berdasarkan nilai centroid, kita dapat melihat karakteristik rata-rata dari setiap cluster. Misalnya, Cluster 2 memiliki nilai petal length dan width yang paling rendah, sementara Cluster 1 memiliki nilai petal length dan width yang paling tinggi. Cluster 3 memiliki nilai-nilai fitur yang berada di antara keduanya. Jika dataset ini adalah dataset Iris, cluster-cluster ini kemungkinan besar merepresentasikan spesies yang berbeda.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">k2</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">k3</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">benar_k1</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">salah_k1</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">49</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">clusters</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">k1</span><span class="p">:</span>
        <span class="n">benar_k1</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">salah_k1</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Benar K1:&quot;</span><span class="p">,</span> <span class="n">benar_k1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Salah K1:&quot;</span><span class="p">,</span> <span class="n">salah_k1</span><span class="p">)</span>

<span class="n">benar_k2</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">salah_k2</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">99</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">clusters</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">k2</span><span class="p">:</span>
        <span class="n">benar_k2</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">salah_k2</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Benar K2:&quot;</span><span class="p">,</span> <span class="n">benar_k2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Salah K2:&quot;</span><span class="p">,</span> <span class="n">salah_k2</span><span class="p">)</span>

<span class="n">benar_k3</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">salah_k3</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">149</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">clusters</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">k3</span><span class="p">:</span>
        <span class="n">benar_k3</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">salah_k3</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Benar K3:&quot;</span><span class="p">,</span> <span class="n">benar_k3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Salah K3:&quot;</span><span class="p">,</span> <span class="n">salah_k3</span><span class="p">)</span>
<span class="n">akurasi</span> <span class="o">=</span> <span class="p">(</span><span class="n">benar_k1</span> <span class="o">+</span> <span class="n">benar_k2</span> <span class="o">+</span> <span class="n">benar_k3</span><span class="p">)</span> <span class="o">/</span> <span class="mi">150</span> <span class="o">*</span> <span class="mi">100</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi:</span><span class="si">{</span><span class="n">akurasi</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Benar K1: 49
Salah K1: 0
Benar K2: 46
Salah K2: 3
Benar K3: 36
Salah K3: 13
Akurasi:87.33333333333333%
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 5. Visualisasi hasil clustering (menggunakan 2 fitur dari hasil PCA)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Plot data berdasarkan cluster</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
    <span class="n">cluster_data</span> <span class="o">=</span> <span class="n">X_pca</span><span class="p">[</span><span class="n">clusters</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cluster_data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cluster_data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Cluster </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Plot centroid</span>
<span class="n">centroids_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">centroids</span><span class="p">)</span>  <span class="c1"># Transform centroid ke dalam ruang PCA</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">centroids_pca</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">centroids_pca</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Centroids&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;K-Means Clustering (Iris Dataset) - PCA Visualization&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/269783dbe9c86b1c0ac6695df069ad1c7dff3e97a23130e3f6137b99347a4ecd.png" src="_images/269783dbe9c86b1c0ac6695df069ad1c7dff3e97a23130e3f6137b99347a4ecd.png" />
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="memahami-inertia-dalam-k-means-clustering">
<h1>ğŸ” Memahami Inertia dalam K-Means Clustering ğŸ’¡<a class="headerlink" href="#memahami-inertia-dalam-k-means-clustering" title="Link to this heading">#</a></h1>
<section id="apa-itu-inertia">
<h2>ğŸ“Œ Apa Itu Inertia?<a class="headerlink" href="#apa-itu-inertia" title="Link to this heading">#</a></h2>
<p><strong>Inertia</strong>, juga dikenal sebagai <strong>Sum of Squared Errors (SSE)</strong>, adalah metrik penting dalam K-Means Clustering yang mengukur <strong>seberapa baik</strong> data telah dikelompokkan. Semakin kecil nilai <strong>Inertia</strong>, semakin padat dan terdefinisi klaster yang terbentuk, karena titik-titik data terletak dekat dengan pusat (centroid) klaster mereka. ğŸ“Šâœ¨</p>
</section>
<section id="rumus-inertia">
<h2>ğŸ“ Rumus Inertia<a class="headerlink" href="#rumus-inertia" title="Link to this heading">#</a></h2>
<p>Inertia dihitung sebagai jumlah kuadrat jarak Euclidean antara setiap titik data dan pusat (centroid) klaster tempat titik data tersebut berada:</p>
<div class="math notranslate nohighlight">
\[
J = \sum_{i=1}^{K} \sum_{j=1}^{n_i} \| x_j^{(i)} - \mu_i \|^2
\]</div>
<p>Dengan:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(( K )\)</span> = jumlah klaster</p></li>
<li><p><span class="math notranslate nohighlight">\(( n_i )\)</span> = jumlah titik data dalam klaster ke-( i )</p></li>
<li><p><span class="math notranslate nohighlight">\(( x_j^{(i)} )\)</span> = titik data ke-( j ) dalam klaster ke-( i )</p></li>
<li><p><span class="math notranslate nohighlight">\(( \mu_i )\)</span> = pusat (centroid) dari klaster ke-( i )</p></li>
<li><p><span class="math notranslate nohighlight">\(( \| x_j^{(i)} - \mu_i \|^2 )\)</span> = kuadrat jarak Euclidean antara titik data <span class="math notranslate nohighlight">\(( x_j^{(i)} )\)</span> dan centroid <span class="math notranslate nohighlight">\(( \mu_i )\)</span></p></li>
</ul>
</section>
<section id="peran-inertia-dalam-menentukan-jumlah-klaster-optimal-k">
<h2>ğŸ¯ Peran Inertia dalam Menentukan Jumlah Klaster Optimal (K)<a class="headerlink" href="#peran-inertia-dalam-menentukan-jumlah-klaster-optimal-k" title="Link to this heading">#</a></h2>
<p>Salah satu metode populer untuk menentukan jumlah klaster ( K ) yang optimal adalah <strong>Metode Elbow</strong>, yang memanfaatkan <strong>Inertia</strong>:</p>
<ol class="arabic simple">
<li><p>Hitung nilai <strong>Inertia</strong> untuk berbagai kemungkinan jumlah klaster ( K ) (misalnya, dari 1 hingga 10).</p></li>
<li><p>Visualisasikan nilai <strong>Inertia</strong> terhadap jumlah klaster ( K ) dalam sebuah plot garis.</p></li>
<li><p>Identifikasi titik pada plot di mana penurunan <strong>Inertia</strong> mulai melambat secara signifikan, membentuk Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ â€œsikuâ€ (elbow). Jumlah klaster pada titik siku ini sering dianggap sebagai jumlah klaster yang optimal. ğŸ“‰è‚˜</p></li>
</ol>
</section>
<section id="interpretasi-nilai-inertia">
<h2>ğŸ† Interpretasi Nilai Inertia<a class="headerlink" href="#interpretasi-nilai-inertia" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Inertia rendah:</strong> Mengindikasikan klaster yang lebih baik, di mana titik-titik data cenderung berkumpul dekat dengan centroid masing-masing. âœ…</p></li>
<li><p><strong>Inertia tinggi:</strong> Menunjukkan klaster yang kurang optimal, dengan titik-titik data yang lebih tersebar jauh dari pusat klaster. ğŸ˜Ÿ</p></li>
<li><p><strong>Penurunan Inertia:</strong> Umumnya terjadi dengan penambahan jumlah klaster. Namun, penambahan klaster yang berlebihan dapat menyebabkan <strong>overfitting</strong>, di mana model terlalu cocok dengan data latih dan gagal menggeneralisasi dengan baik pada data baru. âš ï¸</p></li>
</ul>
<hr class="docutils" />
<p>ğŸ’¡ <strong>Langkah Selanjutnya:</strong> Mari kita eksplorasi implementasi <strong>Metode Elbow</strong> untuk menemukan jumlah klaster yang paling sesuai berdasarkan nilai Inertia! ğŸš€ğŸ”</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Gunakan variabel data_iris yang sudah dimiliki</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data_iris</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># Menggunakan semua fitur iris</span>

<span class="c1"># Tentukan range jumlah cluster (K) yang diuji, mulai dari 2 sampai 10</span>
<span class="n">k_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">inertias</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Hitung Inertia untuk tiap K</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_range</span><span class="p">:</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
        <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span>
        <span class="n">n_init</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
        <span class="n">copy_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;lloyd&#39;</span>
    <span class="p">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">inertias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="c1"># Tampilkan nilai Inertia per K</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Nilai Inertia per K:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">inertia</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">k_range</span><span class="p">,</span> <span class="n">inertias</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;K = </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: Inertia = </span><span class="si">{</span><span class="n">inertia</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Nilai Inertia per K:
K = 2: Inertia = 152.34795176035797
K = 3: Inertia = 78.85566582597727
K = 4: Inertia = 57.350880212954756
</pre></div>
</div>
</div>
</div>
<section id="penjelasan-kode-mencari-inertia-untuk-k-means-clustering">
<h3>Penjelasan Kode: Mencari Inertia untuk K-Means Clustering<a class="headerlink" href="#penjelasan-kode-mencari-inertia-untuk-k-means-clustering" title="Link to this heading">#</a></h3>
<p>Kode ini bertujuan untuk menghitung dan menampilkan nilai <strong>Inertia</strong> untuk berbagai jumlah klaster (K) dalam algoritma K-Means Clustering, yang diterapkan pada dataset Iris. Inertia digunakan sebagai metrik untuk mengevaluasi kualitas pengelompokan data.</p>
<p><strong>Langkah-langkah:</strong></p>
<ol class="arabic simple">
<li><p><strong>Import Library:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">numpy</span></code> untuk operasi numerik.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot</span></code> untuk visualisasi data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sklearn.cluster.KMeans</span></code> untuk algoritma K-Means.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pandas</span></code> untuk manipulasi data (walaupun tidak digunakan secara eksplisit dalam kode ini).</p></li>
</ul>
</li>
<li><p><strong>Persiapan Data:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">=</span> <span class="pre">data_iris.data</span></code>: Mengambil fitur-fitur dari dataset Iris dan menyimpannya dalam variabel <code class="docutils literal notranslate"><span class="pre">X</span></code>. Diasumsikan bahwa variabel <code class="docutils literal notranslate"><span class="pre">data_iris</span></code> sudah didefinisikan sebelumnya dan berisi data Iris.</p></li>
</ul>
</li>
<li><p><strong>Menentukan Range K:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">k_range</span> <span class="pre">=</span> <span class="pre">range(2,</span> <span class="pre">5)</span></code>: Menentukan rentang jumlah klaster (K) yang akan diuji, yaitu dari 2 hingga 4.</p></li>
</ul>
</li>
<li><p><strong>Menghitung Inertia:</strong></p>
<ul class="simple">
<li><p>Looping melalui setiap nilai K dalam <code class="docutils literal notranslate"><span class="pre">k_range</span></code>:</p>
<ul>
<li><p>Membuat objek <code class="docutils literal notranslate"><span class="pre">KMeans</span></code> dengan parameter yang telah ditentukan, termasuk jumlah klaster (<code class="docutils literal notranslate"><span class="pre">n_clusters=k</span></code>).</p></li>
<li><p>Melatih model K-Means menggunakan data <code class="docutils literal notranslate"><span class="pre">X</span></code> dengan memanggil <code class="docutils literal notranslate"><span class="pre">kmeans.fit(X)</span></code>.</p></li>
<li><p>Menyimpan nilai Inertia yang diperoleh dari model (<code class="docutils literal notranslate"><span class="pre">kmeans.inertia_</span></code>) ke dalam list <code class="docutils literal notranslate"><span class="pre">inertias</span></code>.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Menampilkan Hasil:</strong></p>
<ul class="simple">
<li><p>Mencetak judul â€œNilai Inertia per K:â€.</p></li>
<li><p>Looping melalui setiap nilai K dan Inertia yang tersimpan:</p>
<ul>
<li><p>Mencetak nilai K dan Inertia yang bersesuaian dalam format yang mudah dibaca.</p></li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>Tujuan:</strong></p>
<p>Kode ini bertujuan untuk memberikan informasi tentang bagaimana Inertia berubah seiring dengan perubahan jumlah klaster (K). Informasi ini dapat digunakan dalam <strong>Metode Elbow</strong> untuk menentukan jumlah klaster yang optimal. Pada Metode Elbow, kita mencari titik â€œsikuâ€ pada plot Inertia vs. K, di mana penurunan Inertia mulai melambat secara signifikan. Titik siku ini mengindikasikan jumlah klaster yang optimal.</p>
<p><strong>Catatan:</strong></p>
</section>
</section>
<section id="metode-elbow-menentukan-jumlah-cluster-optimal-dalam-k-means">
<h2>ğŸ“‰ Metode Elbow: Menentukan Jumlah Cluster Optimal dalam K-Means<a class="headerlink" href="#metode-elbow-menentukan-jumlah-cluster-optimal-dalam-k-means" title="Link to this heading">#</a></h2>
<p>Metode <strong>Elbow</strong> adalah teknik visual yang populer digunakan untuk menentukan jumlah cluster (( K )) yang optimal dalam algoritma K-Means. Ide dasarnya adalah untuk menjalankan K-Means dengan berbagai nilai ( K ) dan mengamati bagaimana metrik evaluasi (biasanya <strong>Inertia</strong>) berubah.</p>
<section id="cara-kerja-metode-elbow">
<h3>âš™ï¸ Cara Kerja Metode Elbow<a class="headerlink" href="#cara-kerja-metode-elbow" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Latih Model K-Means dengan Berbagai Nilai ( K ):</strong> Kita melatih beberapa model K-Means, masing-masing dengan jumlah cluster yang berbeda dalam suatu rentang tertentu (misalnya, ( K ) dari 2 hingga 14). ğŸ§ª</p></li>
<li><p><strong>Hitung Inertia untuk Setiap Model:</strong> Untuk setiap model yang dilatih, kita catat nilai <strong>Inertia</strong>-nya. Ingat, Inertia adalah jumlah kuadrat jarak antara setiap titik data dan centroid terdekatnya. Semakin rendah Inertia, semakin baik cluster-cluster tersebut (dalam hal kepadatan). ğŸ“</p></li>
<li><p><strong>Plot Nilai Inertia terhadap Jumlah Cluster (( K )):</strong> Kita kemudian membuat grafik yang menunjukkan nilai Inertia pada sumbu y dan jumlah cluster (( K )) pada sumbu x. ğŸ“Š</p></li>
<li><p><strong>Cari Titik â€œSikuâ€ (Elbow):</strong> Bentuk grafik yang dihasilkan biasanya akan menurun seiring dengan meningkatnya jumlah cluster. Tujuannya adalah untuk mengidentifikasi titik di mana penurunan Inertia mulai melambat secara signifikan, membentuk Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ â€œsikuâ€ (elbow). æ‹ï¸</p></li>
<li><p><strong>Pilih ( K ) pada Titik Siku:</strong> Jumlah cluster (( K )) yang sesuai dengan titik siku ini sering dianggap sebagai jumlah cluster yang optimal. Penambahan lebih banyak cluster setelah titik ini tidak memberikan pengurangan Inertia yang substansial, yang mengindikasikan diminishing returns. ğŸ¤”</p></li>
</ol>
</section>
</section>
<section id="code-elbow">
<h2>code elbow<a class="headerlink" href="#code-elbow" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>

<span class="c1"># Asumsi kamu sudah memiliki variabel data_iris</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data_iris</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># Fitur dataset</span>

<span class="c1"># Tentukan range jumlah cluster yang mau diuji</span>
<span class="n">k_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">inertias</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Hitung inertia untuk tiap K dengan parameter KMeans custom</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_range</span><span class="p">:</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
        <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span>
        <span class="n">n_init</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
        <span class="n">copy_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;lloyd&#39;</span>
    <span class="p">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">inertias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="c1"># Tampilkan nilai inertia per K</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Nilai Inertia per K:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">inertia</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">k_range</span><span class="p">,</span> <span class="n">inertias</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;K = </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: Inertia = </span><span class="si">{</span><span class="n">inertia</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Nilai Inertia per K:
K = 2: Inertia = 152.35
K = 3: Inertia = 78.86
K = 4: Inertia = 57.35
K = 5: Inertia = 46.47
K = 6: Inertia = 39.07
K = 7: Inertia = 34.31
K = 8: Inertia = 30.48
K = 9: Inertia = 29.91
K = 10: Inertia = 28.55
K = 11: Inertia = 26.51
K = 12: Inertia = 25.86
K = 13: Inertia = 23.42
</pre></div>
</div>
</div>
</div>
<section id="interpretasi-grafik-elbow">
<h3>ğŸ’¡ Interpretasi Grafik Elbow<a class="headerlink" href="#interpretasi-grafik-elbow" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Penurunan Curam:</strong> Bagian awal grafik biasanya menunjukkan penurunan Inertia yang curam saat kita menambahkan lebih banyak cluster. Ini karena setiap titik data menjadi lebih dekat dengan centroidnya sendiri.</p></li>
<li><p><strong>Titik Siku:</strong> Titik di mana kurva mulai melandai. Ini adalah indikasi bahwa kita telah menemukan sebagian besar struktur dalam data, dan menambahkan lebih banyak cluster tidak terlalu meningkatkan model.</p></li>
<li><p><strong>Penurunan Landai:</strong> Setelah titik siku, penambahan lebih banyak cluster hanya menghasilkan penurunan Inertia yang kecil. Ini bisa mengindikasikan bahwa kita mulai membagi cluster yang sebenarnya menjadi sub-cluster yang kurang bermakna.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot Elbow Method</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_range</span><span class="p">,</span> <span class="n">inertias</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Elbow Method - Menentukan K Optimal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Jumlah Cluster (K)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Inertia&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">k_range</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/07429b69a3f13cfd3e62e6ad264b6aa50a872033f7c8bceaadbbd12336747d1d.png" src="_images/07429b69a3f13cfd3e62e6ad264b6aa50a872033f7c8bceaadbbd12336747d1d.png" />
</div>
</div>
<p>dalam hal ini
Tentu, berikut adalah konten penjelasan metode Elbow yang diformat agar sesuai dengan cell Markdown di Jupyter Notebook atau Google Colab (.ipynb). Anda dapat menyalin seluruh teks di bawah ini dan menempelkannya ke dalam cell Markdown:</p>
<p>Markdown</p>
</section>
</section>
<section id="metode-elbow-menentukan-jumlah-cluster-optimal-k-dalam-k-means-fokus-pada-k-3">
<h2>ğŸ“‰ Metode Elbow: Menentukan Jumlah Cluster Optimal (K) dalam K-Means (Fokus pada K=3)<a class="headerlink" href="#metode-elbow-menentukan-jumlah-cluster-optimal-k-dalam-k-means-fokus-pada-k-3" title="Link to this heading">#</a></h2>
<p>Metode <strong>Elbow</strong> adalah teknik visual yang populer digunakan untuk menentukan jumlah cluster (( K )) yang optimal dalam algoritma K-Means. Kita melatih K-Means dengan berbagai nilai ( K ) dan mengamati perubahan nilai <strong>Inertia</strong>.</p>
<section id="interpretasi-grafik-elbow-dengan-siku-di-k-3">
<h3>âš™ï¸ Interpretasi Grafik Elbow dengan Siku di K=3<a class="headerlink" href="#interpretasi-grafik-elbow-dengan-siku-di-k-3" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Inertia terhadap jumlah cluster (( K )). Jika kita mengamati sebuah <strong>penurunan Inertia yang signifikan</strong> saat kita meningkatkan ( K ) dari 1 ke 2, dan kemudian penurunan yang masih cukup besar dari 2 ke <strong>3</strong>, namun setelah ( K = 3 ), penurunan Inertia menjadi jauh lebih landai, maka kita dapat menginterpretasikannya sebagai berikut:</p></li>
<li><p>Dalam skenario ini, ( K = 3 ) menjadi kandidat yang kuat untuk jumlah cluster optimal. Mengapa?</p></li>
<li><p>Sebelum ( K = 3 ): Penambahan cluster secara substansial mengurangi Inertia, yang berarti titik-titik data menjadi lebih dekat dengan centroid cluster mereka. Struktur data yang signifikan sedang terungkap. ğŸ”
Pada ( K = 3 ): Kita mencapai titik di mana penambahan cluster lebih lanjut tidak lagi memberikan pengurangan Inertia yang dramatis. Manfaat dari penambahan cluster tambahan mulai berkurang. ğŸ›‘</p></li>
<li><p>Setelah ( K = 3 ): Penurunan Inertia menjadi lebih bertahap. Ini bisa mengindikasikan bahwa kita mulai membagi cluster yang sebenarnya menjadi sub-cluster yang mungkin tidak terlalu bermakna atau hanya menangkap noise dalam data</p></li>
</ul>
<p>jadi kesimpulannya data yang clusternya optimal dalam adalah k = 3</p>
</section>
</section>
<section id="memahami-silhouette-score-dalam-clustering">
<h2>Memahami Silhouette Score dalam Clustering ğŸ§â†”ï¸ğŸ§â€â™€ï¸<a class="headerlink" href="#memahami-silhouette-score-dalam-clustering" title="Link to this heading">#</a></h2>
<p><strong>Silhouette Score</strong> adalah sebuah metrik yang digunakan untuk mengevaluasi kualitas pengelompokan (clustering) data. Metrik ini mengukur seberapa mirip suatu objek dengan cluster-nya sendiri dibandingkan dengan cluster lain. Silhouette Score memberikan nilai antara -1 dan 1, di mana nilai yang lebih tinggi menunjukkan hasil clustering yang lebih baik. ğŸ‘</p>
<section id="rumus-silhouette-score">
<h3>Rumus Silhouette Score ğŸ“<a class="headerlink" href="#rumus-silhouette-score" title="Link to this heading">#</a></h3>
<p>Untuk setiap titik data ( i ), Silhouette Score ( s(i) ) dihitung sebagai berikut:</p>
<div class="math notranslate nohighlight">
\[
s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}
\]</div>
<p>Dimana:</p>
<ul class="simple">
<li><p>( a(i) ) adalah <strong>rata-rata jarak intra-cluster</strong> untuk titik data ( i ). Ini adalah rata-rata jarak antara titik ( i ) dan semua titik lain dalam cluster yang sama. Semakin kecil nilai ( a(i) ), semakin baik titik ( i ) cocok dengan cluster-nya sendiri. ğŸ¤</p></li>
<li><p>( b(i) ) adalah <strong>rata-rata jarak nearest-cluster</strong> untuk titik data ( i ). Ini adalah jarak rata-rata antara titik ( i ) dan semua titik dalam cluster <em>terdekat</em> yang berbeda dari cluster titik ( i ). Semakin besar nilai ( b(i) ), semakin baik pemisahan antara cluster. â¡ï¸ à¦…à¦¨à§à¦¯ à¦•à§à¦²à¦¾à¦¸à§à¦Ÿà¦¾à¦°</p></li>
</ul>
<p><strong>Silhouette Score untuk seluruh clustering</strong> adalah rata-rata dari Silhouette Score untuk semua titik data dalam dataset.</p>
</section>
<section id="interpretasi-nilai-silhouette-score">
<h3>Interpretasi Nilai Silhouette Score ğŸ¤”<a class="headerlink" href="#interpretasi-nilai-silhouette-score" title="Link to this heading">#</a></h3>
<p><strong>Catatan mengenai nilai rata-rata Silhouette Score untuk keseluruhan clustering:</strong></p>
<ul class="simple">
<li><p><strong>Skor di atas 0.7:</strong> Dianggap sebagai indikasi <strong>clustering yang kuat</strong>, di mana cluster-cluster terpisah dengan baik.</p></li>
<li><p><strong>Skor antara 0.5 dan 0.7:</strong> Dianggap sebagai <strong>clustering yang wajar</strong>.</p></li>
<li><p><strong>Skor antara 0.25 dan 0.5:</strong> Dianggap sebagai <strong>clustering yang lemah</strong>, yang berarti cluster-cluster mungkin tumpang tindih.</p></li>
<li><p><strong>Skor di bawah 0.25:</strong> Menunjukkan <strong>clustering yang buruk</strong>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">silhouette_score</span><span class="p">,</span> <span class="n">silhouette_samples</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Gunakan variabel data_iris yang sudah dimiliki</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data_iris</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># Menggunakan semua fitur iris</span>

<span class="c1"># Range jumlah cluster (K) yang diuji</span>
<span class="n">k_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">silhouette_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">cluster_results</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Simpan label dan sample silhouette untuk plotting terpisah</span>

<span class="c1"># Hitung Silhouette Score dan simpan hasil untuk visualisasi nanti</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_range</span><span class="p">:</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
        <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span>
        <span class="n">n_init</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">0.00000001</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
        <span class="n">copy_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;lloyd&#39;</span>
    <span class="p">)</span>
    <span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cluster_labels</span><span class="p">)</span>
    <span class="n">silhouette_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;K = </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: Silhouette Score = </span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Simpan hasil untuk plotting nanti</span>
    <span class="n">cluster_results</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;labels&#39;</span><span class="p">:</span> <span class="n">cluster_labels</span><span class="p">,</span>
        <span class="s1">&#39;sample_silhouette_values&#39;</span><span class="p">:</span> <span class="n">silhouette_samples</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cluster_labels</span><span class="p">)</span>
    <span class="p">}</span>

<span class="c1"># ---- Silhouette Plot per Cluster ----</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_range</span><span class="p">:</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">cluster_results</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>
    <span class="n">sample_silhouette_values</span> <span class="o">=</span> <span class="n">cluster_results</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="s1">&#39;sample_silhouette_values&#39;</span><span class="p">]</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">y_lower</span> <span class="o">=</span> <span class="mi">10</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="n">ith_cluster_silhouette_values</span> <span class="o">=</span> <span class="n">sample_silhouette_values</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">ith_cluster_silhouette_values</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

        <span class="n">size_cluster_i</span> <span class="o">=</span> <span class="n">ith_cluster_silhouette_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y_upper</span> <span class="o">=</span> <span class="n">y_lower</span> <span class="o">+</span> <span class="n">size_cluster_i</span>
        <span class="n">color</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Spectral</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">/</span> <span class="n">k</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">fill_betweenx</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_lower</span><span class="p">,</span> <span class="n">y_upper</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">ith_cluster_silhouette_values</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="p">(</span><span class="n">y_lower</span> <span class="o">+</span> <span class="n">y_upper</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;Cluster </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

        <span class="n">y_lower</span> <span class="o">=</span> <span class="n">y_upper</span> <span class="o">+</span> <span class="mi">10</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Silhouette Plot for K=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Silhouette Coefficient Values&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Cluster Label&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># ---- Plot Silhouette Score per K ----</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_range</span><span class="p">,</span> <span class="n">silhouette_scores</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Silhouette Score per K (Iris Dataset)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Jumlah Cluster (K)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Silhouette Score&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">k_range</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Tampilkan K optimal berdasarkan Silhouette Score tertinggi</span>
<span class="n">optimal_k</span> <span class="o">=</span> <span class="n">k_range</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">silhouette_scores</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">K dengan Silhouette Score terbaik adalah: K = </span><span class="si">{</span><span class="n">optimal_k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>K = 2: Silhouette Score = 0.6810
K = 3: Silhouette Score = 0.5512
K = 4: Silhouette Score = 0.4976
</pre></div>
</div>
<img alt="_images/7cb84f65867395da72f17a4607c3b7cc3e8a6bdc57d3ea7285b296cc150d57a6.png" src="_images/7cb84f65867395da72f17a4607c3b7cc3e8a6bdc57d3ea7285b296cc150d57a6.png" />
<img alt="_images/4832874e38ab12cf43f170f321f8eac2a8ba54a72286ada41ef9e068d751cee7.png" src="_images/4832874e38ab12cf43f170f321f8eac2a8ba54a72286ada41ef9e068d751cee7.png" />
<img alt="_images/ba50711ee40d6d5edcca9ead688b077032dfee945a63c1d33c45d1e8905699c9.png" src="_images/ba50711ee40d6d5edcca9ead688b077032dfee945a63c1d33c45d1e8905699c9.png" />
<img alt="_images/46f3ddc852a90607ae2411442c1bd483a20895e47cf8c6773d89226d94862bcb.png" src="_images/46f3ddc852a90607ae2411442c1bd483a20895e47cf8c6773d89226d94862bcb.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>K dengan Silhouette Score terbaik adalah: K = 2
</pre></div>
</div>
</div>
</div>
<p>Berdasarkan hasil Silhouette Score yang Anda berikan:</p>
<ul class="simple">
<li><p><strong>K = 2: Silhouette Score = 0.6810</strong></p>
<ul>
<li><p>Nilai Silhouette Score sebesar 0.6810 untuk ( K = 2 ) menunjukkan kualitas clustering yang <strong>cukup baik</strong> hingga <strong>kuat</strong>.</p></li>
<li><p>Nilai ini mendekati 0.7, yang umumnya dianggap sebagai indikasi bahwa cluster-cluster terpisah dengan baik.</p></li>
<li><p>Sebagian besar titik data kemungkinan besar berada di dalam cluster yang tepat dan jauh dari batas keputusan antara dua cluster tersebut.</p></li>
<li><p>Dapat diartikan bahwa pembagian data menjadi dua cluster menghasilkan pemisahan yang jelas antar kelompok.</p></li>
</ul>
</li>
<li><p><strong>K = 3: Silhouette Score = 0.5512</strong></p>
<ul>
<li><p>Nilai Silhouette Score sebesar 0.5512 untuk ( K = 3 ) menunjukkan kualitas clustering yang <strong>wajar</strong>.</p></li>
<li><p>Skor ini lebih rendah dari saat ( K = 2 ), yang mengindikasikan bahwa menambahkan cluster ketiga mungkin membuat beberapa titik data menjadi lebih dekat dengan batas keputusan cluster lain atau cluster yang terbentuk tidak sepadat sebelumnya.</p></li>
<li><p>Meskipun masih di atas 0.5, ada kemungkinan beberapa titik data tidak sejelas penugasannya dibandingkan dengan kasus ( K = 2 ).</p></li>
</ul>
</li>
<li><p><strong>K = 4: Silhouette Score = 0.4976</strong></p>
<ul>
<li><p>Nilai Silhouette Score sebesar 0.4976 untuk ( K = 4 ) menunjukkan kualitas clustering yang <strong>lemah</strong> hingga <strong>wajar</strong>.</p></li>
<li><p>Penurunan lebih lanjut pada Silhouette Score ini mengisyaratkan bahwa dengan empat cluster, pemisahan antar cluster menjadi kurang jelas.</p></li>
<li><p>Kemungkinan ada lebih banyak titik data yang berada di dekat atau bahkan tumpang tindih dengan cluster lain.</p></li>
<li><p>Penambahan cluster keempat tampaknya tidak meningkatkan kualitas pemisahan secara keseluruhan dan justru cenderung memperburuknya dibandingkan dengan ( K = 2 ) dan ( K = 3 ).</p></li>
</ul>
</li>
</ul>
</section>
<section id="kesimpulan-sementara">
<h3>Kesimpulan Sementara ğŸ¤”<a class="headerlink" href="#kesimpulan-sementara" title="Link to this heading">#</a></h3>
<p>Berdasarkan nilai Silhouette Score ini, <strong>( K = 2 )</strong> tampaknya memberikan hasil clustering yang terbaik untuk dataset Anda (dalam hal kohesi dan pemisahan cluster) dibandingkan dengan ( K = 3 ) dan ( K = 4 ). Meskipun ( K = 3 ) masih menunjukkan clustering yang wajar, penambahan cluster menjadi 4 menghasilkan penurunan kualitas pemisahan yang lebih signifikan.</p>
<p>Penting untuk diingat bahwa Silhouette Score hanyalah salah satu metrik evaluasi. Pertimbangan lain seperti pemahaman domain dan hasil visualisasi (misalnya, dari Silhouette Plot individual) juga penting dalam menentukan jumlah cluster yang paling bermakna untuk data.</p>
</section>
<section id="penggunaan-silhouette-score-dalam-praktik">
<h3>Penggunaan Silhouette Score dalam Praktik ğŸ› ï¸<a class="headerlink" href="#penggunaan-silhouette-score-dalam-praktik" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Evaluasi Kualitas Clustering:</strong> Silhouette Score memberikan gambaran yang jelas tentang seberapa baik objek dikelompokkan. Nilai rata-rata yang lebih tinggi untuk seluruh dataset menunjukkan clustering yang lebih baik. âœ…</p></li>
<li><p><strong>Memilih Jumlah Cluster Optimal:</strong> Silhouette Score juga dapat digunakan untuk membantu menentukan jumlah cluster yang optimal dalam algoritma seperti K-Means. Caranya adalah dengan menghitung Silhouette Score untuk berbagai jumlah cluster dan memilih jumlah cluster yang menghasilkan skor tertinggi. ğŸ†</p></li>
</ol>
</section>
<section id="kelebihan-silhouette-score">
<h3>Kelebihan Silhouette Score âœ¨<a class="headerlink" href="#kelebihan-silhouette-score" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Memberikan metrik tunggal yang intuitif untuk mengevaluasi kualitas clustering.</p></li>
<li><p>Mempertimbangkan baik kohesi (seberapa dekat titik-titik dalam cluster) maupun pemisahan (seberapa jauh antar cluster).</p></li>
<li><p>Dapat memberikan wawasan tentang apakah beberapa cluster terlalu dekat atau tumpang tindih.</p></li>
</ul>
</section>
<section id="kekurangan-silhouette-score">
<h3>Kekurangan Silhouette Score âš ï¸<a class="headerlink" href="#kekurangan-silhouette-score" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Silhouette Score mengasumsikan bahwa cluster bersifat cembung (convex). Jika cluster memiliki bentuk yang kompleks, skor mungkin tidak mencerminkan kualitas clustering dengan baik.</p></li>
<li><p>Skor dapat dipengaruhi oleh kepadatan cluster. Cluster dengan kepadatan yang berbeda dapat menghasilkan skor yang tidak sebanding.</p></li>
</ul>
<p>Secara keseluruhan, Silhouette Score adalah alat yang berguna untuk mengevaluasi dan membandingkan hasil dari berbagai algoritma clustering atau jumlah cluster yang berbeda. Memahami interpretasi nilainya dapat membantu dalam memilih model clustering yang paling sesuai untuk data Anda. ğŸ‘</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="algoritma-fuzzy-c-mean-clustering-fcm">
<h1>algoritma Fuzzy C-Mean Clustering (FCM)<a class="headerlink" href="#algoritma-fuzzy-c-mean-clustering-fcm" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">hitung_Jm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Hitung fungsi objektif Jm untuk FCM:</span>
<span class="sd">    Jm = sum_{i=1}^{c} sum_{k=1}^{n} (u_ik)^m * ||x_k - v_i||^2</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_clusters</span><span class="p">,</span> <span class="n">n_samples</span> <span class="o">=</span> <span class="n">U</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
            <span class="n">dist_sq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="p">(</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">**</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">dist_sq</span>
    <span class="k">return</span> <span class="n">total</span>
<span class="k">def</span><span class="w"> </span><span class="nf">hitung_pusat_cluster</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Menghitung pusat cluster V.&quot;&quot;&quot;</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">n_samples</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">n_clusters</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">V</span> <span class="c1"># Kembali matriks kosong jika tidak ada data atau cluster</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
        <span class="n">u_ik_pangkat_m</span> <span class="o">=</span> <span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">**</span> <span class="n">m</span>
        <span class="n">pembilang</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">u_ik_pangkat_m</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">penyebut</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">u_ik_pangkat_m</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">penyebut</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">pembilang</span> <span class="o">/</span> <span class="n">penyebut</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Fallback: jika penyebut nol (tidak ada titik yang menjadi anggota cluster ini),</span>
            <span class="c1"># gunakan rata-rata seluruh data.</span>
            <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span> <span class="c1"># Jika tidak ada data, set pusat ke nol</span>
    <span class="k">return</span> <span class="n">V</span>
<span class="k">def</span><span class="w"> </span><span class="nf">update_matriks_U</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Memperbarui matriks keanggotaan U.&quot;&quot;&quot;</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">U_baru</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">))</span>
    <span class="n">epsilon_jarak</span> <span class="o">=</span> <span class="mf">1e-9</span> <span class="c1"># Nilai kecil untuk menghindari pembagian dengan nol</span>

    <span class="k">if</span> <span class="n">n_samples</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">n_clusters</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">U_baru</span> <span class="c1"># Kembali matriks kosong jika tidak ada data atau cluster</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span> <span class="c1"># Untuk setiap titik data X[k]</span>
        <span class="n">jarak_ke_pusat_kuadrat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">)</span>

        <span class="c1"># Hitung semua jarak kuadrat terlebih dahulu</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
            <span class="n">jarak_kuadrat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">jarak_ke_pusat_kuadrat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">jarak_kuadrat</span>

        <span class="c1"># Cek apakah titik data bertepatan persis dengan salah satu pusat cluster (jarak sangat kecil)</span>
        <span class="n">close_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">jarak_ke_pusat_kuadrat</span> <span class="o">&lt;</span> <span class="n">epsilon_jarak</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">close_indices</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Jika ada satu atau lebih cluster yang bertepatan/sangat dekat,</span>
            <span class="c1"># berikan keanggotaan 1 secara merata di antara mereka.</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">close_indices</span><span class="p">:</span>
                <span class="n">U_baru</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">close_indices</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Kalkulasi standar jika tidak ada titik yang bertepatan</span>
            <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">epsilon_jarak</span><span class="p">:</span> <span class="c1"># Handle hard C-Means case (m=1)</span>
                <span class="n">closest_cluster_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">jarak_ke_pusat_kuadrat</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
                    <span class="n">U_baru</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">closest_cluster_idx</span> <span class="k">else</span> <span class="mf">0.0</span>
            <span class="k">else</span><span class="p">:</span> <span class="c1"># Fuzzy C-Means case (m &gt; 1)</span>
                <span class="n">power_term</span> <span class="o">=</span> <span class="mf">2.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span> <span class="c1"># Untuk setiap cluster V[i]</span>
                    <span class="n">pembilang_uik_kuadrat</span> <span class="o">=</span> <span class="n">jarak_ke_pusat_kuadrat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

                    <span class="n">denominator_uik</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
                        <span class="n">penyebut_rasio_kuadrat</span> <span class="o">=</span> <span class="n">jarak_ke_pusat_kuadrat</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

                        <span class="k">if</span> <span class="n">penyebut_rasio_kuadrat</span> <span class="o">&lt;</span> <span class="n">epsilon_jarak</span><span class="p">:</span>
                            <span class="n">denominator_uik</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pembilang_uik_kuadrat</span> <span class="o">/</span> <span class="n">epsilon_jarak</span><span class="p">)</span><span class="o">**</span><span class="n">power_term</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">denominator_uik</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pembilang_uik_kuadrat</span> <span class="o">/</span> <span class="n">penyebut_rasio_kuadrat</span><span class="p">)</span><span class="o">**</span><span class="n">power_term</span>

                    <span class="k">if</span> <span class="n">denominator_uik</span> <span class="o">&lt;</span> <span class="n">epsilon_jarak</span><span class="p">:</span>
                        <span class="n">U_baru</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">U_baru</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">denominator_uik</span>

    <span class="c1"># Normalisasi kolom untuk memastikan setiap kolom (sampel data) berjumlah 1</span>
    <span class="n">sum_cols_U_baru</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">U_baru</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">sum_cols_U_baru</span><span class="p">[</span><span class="n">sum_cols_U_baru</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
    <span class="n">U_baru</span> <span class="o">=</span> <span class="n">U_baru</span> <span class="o">/</span> <span class="n">sum_cols_U_baru</span>

    <span class="k">return</span> <span class="n">U_baru</span>
<span class="k">def</span><span class="w"> </span><span class="nf">fcm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">,</span> <span class="n">n_iterasi</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">initial_U</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Algoritma Fuzzy C-Means dengan konvergensi fungsi objektif Jm.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">if</span> <span class="n">initial_U</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">initial_U</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Bentuk initial_U </span><span class="si">{</span><span class="n">initial_U</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> tidak sesuai dengan n_clusters=</span><span class="si">{</span><span class="n">n_clusters</span><span class="si">}</span><span class="s2"> dan n_samples=</span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">initial_U</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Kolom-kolom di initial_U harus berjumlah 1.&quot;</span><span class="p">)</span>
        <span class="n">U</span> <span class="o">=</span> <span class="n">initial_U</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Menggunakan Matriks U Awal yang Disediakan.&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">U</span> <span class="o">=</span> <span class="n">inisialisasi_matriks_U_acak</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Menggunakan Matriks U Awal Acak.&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Matriks U Awal (U_0):</span><span class="se">\n</span><span class="si">{</span><span class="n">U</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>
    <span class="n">Jm_sebelumnya</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">for</span> <span class="n">iterasi</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterasi</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--- ITERASI </span><span class="si">{</span><span class="n">iterasi</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> ---&quot;</span><span class="p">)</span>

        <span class="n">V</span> <span class="o">=</span> <span class="n">hitung_pusat_cluster</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cluster Pusat (V_</span><span class="si">{</span><span class="n">iterasi</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">):</span><span class="se">\n</span><span class="si">{</span><span class="n">V</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">U</span> <span class="o">=</span> <span class="n">update_matriks_U</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Matriks U (U_</span><span class="si">{</span><span class="n">iterasi</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">):</span><span class="se">\n</span><span class="si">{</span><span class="n">U</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">Jm_sekarang</span> <span class="o">=</span> <span class="n">hitung_Jm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fungsi Objektif (J_</span><span class="si">{</span><span class="n">iterasi</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">Jm_sekarang</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">Jm_sebelumnya</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">Jm_sebelumnya</span> <span class="o">-</span> <span class="n">Jm_sekarang</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Konvergen pada iterasi ke-</span><span class="si">{</span><span class="n">iterasi</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">break</span>

        <span class="n">Jm_sebelumnya</span> <span class="o">=</span> <span class="n">Jm_sekarang</span>

    <span class="k">return</span> <span class="n">V</span><span class="p">,</span> <span class="n">U</span>

<span class="c1"># --- Contoh Penggunaan ---</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">data_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
    <span class="p">])</span>

    <span class="n">jumlah_cluster</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">jumlah_iterasi_fcm</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">m_fuzzifier</span> <span class="o">=</span> <span class="mf">2.0</span>

    <span class="n">U_awal_kustom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]</span>
    <span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Titik Data (X):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data_points</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah Cluster (c) : </span><span class="si">{</span><span class="n">jumlah_cluster</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah Iterasi: </span><span class="si">{</span><span class="n">jumlah_iterasi_fcm</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parameter Pembobot (m): </span><span class="si">{</span><span class="n">m_fuzzifier</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">pusat_cluster_final</span><span class="p">,</span> <span class="n">matriks_keanggotaan_final</span> <span class="o">=</span> <span class="n">fcm</span><span class="p">(</span>
        <span class="n">data_points</span><span class="p">,</span>
        <span class="n">jumlah_cluster</span><span class="p">,</span>
        <span class="n">jumlah_iterasi_fcm</span><span class="p">,</span>
        <span class="n">m_fuzzifier</span><span class="p">,</span>
        <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">initial_U</span><span class="o">=</span><span class="n">U_awal_kustom</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- HASIL AKHIR ---&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cluster Tengah Final (V_final):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">pusat_cluster_final</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Matriks Keanggotaan Final (U_final):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">matriks_keanggotaan_final</span><span class="p">)</span>

    <span class="n">cluster_assignment</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">matriks_keanggotaan_final</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Cluster Penagasan (berdasarkan pengumpulan tertinggi):&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_points</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data </span><span class="si">{</span><span class="n">data</span><span class="si">}</span><span class="s2"> -&gt; Klaster </span><span class="si">{</span><span class="n">cluster_assignment</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Titik Data (X):
[[1 2]
 [2 3]
 [3 4]
 [6 7]
 [7 8]]
Jumlah Cluster (c) : 2
Jumlah Iterasi: 2
Parameter Pembobot (m): 2.0

Menggunakan Matriks U Awal yang Disediakan.
Matriks U Awal (U_0):
[[0.5 0.7 0.8 0.7 0.6]
 [0.5 0.3 0.2 0.3 0.4]]

--- ITERASI 1 ---
Cluster Pusat (V_1):
[[3.86098655 4.86098655]
 [3.50793651 4.50793651]]

Matriks U (U_1):
[[0.37125775 0.30122773 0.1080429  0.6481838  0.60499865]
 [0.62874225 0.69877227 0.8919571  0.3518162  0.39500135]]

Fungsi Objektif (J_1): 26.90665252

--- ITERASI 2 ---
Cluster Pusat (V_2):
[[5.29744344 6.29744344]
 [2.85528846 3.85528846]]

Matriks U (U_2):
[[3.35718046e-02 4.50588110e-03 1.57407903e-05 9.97515029e-01
  9.72315532e-01]
 [9.66428195e-01 9.95494119e-01 9.99984259e-01 2.48497127e-03
  2.76844678e-02]]

Fungsi Objektif (J_2): 14.45312553

--- HASIL AKHIR ---
Cluster Tengah Final (V_final):
[[5.29744344 6.29744344]
 [2.85528846 3.85528846]]

Matriks Keanggotaan Final (U_final):
[[3.35718046e-02 4.50588110e-03 1.57407903e-05 9.97515029e-01
  9.72315532e-01]
 [9.66428195e-01 9.95494119e-01 9.99984259e-01 2.48497127e-03
  2.76844678e-02]]

Cluster Penagasan (berdasarkan pengumpulan tertinggi):
Data [1 2] -&gt; Klaster 2
Data [2 3] -&gt; Klaster 2
Data [3 4] -&gt; Klaster 2
Data [6 7] -&gt; Klaster 1
Data [7 8] -&gt; Klaster 1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">data_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
    <span class="p">])</span>

    <span class="n">jumlah_cluster</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">max_iterasi</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">m_fuzzifier</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="n">epsilon_konvergen</span> <span class="o">=</span> <span class="mf">1e-5</span>

    <span class="c1"># Optional: bisa kasih U awal kustom seperti ini, atau None untuk acak</span>
    <span class="n">U_awal_kustom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]</span>
    <span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data Points (X):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">data_points</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah Cluster: </span><span class="si">{</span><span class="n">jumlah_cluster</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Max Iterasi: </span><span class="si">{</span><span class="n">max_iterasi</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parameter m (fuzzifier): </span><span class="si">{</span><span class="n">m_fuzzifier</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">pusat_cluster_final</span><span class="p">,</span> <span class="n">matriks_keanggotaan_final</span> <span class="o">=</span> <span class="n">fcm</span><span class="p">(</span>
        <span class="n">data_points</span><span class="p">,</span>
        <span class="n">jumlah_cluster</span><span class="p">,</span>
        <span class="n">max_iterasi</span><span class="p">,</span>
        <span class="n">m_fuzzifier</span><span class="p">,</span>
        <span class="n">epsilon</span><span class="o">=</span><span class="n">epsilon_konvergen</span><span class="p">,</span>
        <span class="n">initial_U</span><span class="o">=</span><span class="n">U_awal_kustom</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- HASIL AKHIR ---&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pusat Cluster Final (V):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">pusat_cluster_final</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Matriks Keanggotaan Final (U):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">matriks_keanggotaan_final</span><span class="p">)</span>

    <span class="n">cluster_assignment</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">matriks_keanggotaan_final</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Penugasan Cluster (berdasarkan keanggotaan tertinggi):&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_points</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data </span><span class="si">{</span><span class="n">data</span><span class="si">}</span><span class="s2"> -&gt; Cluster </span><span class="si">{</span><span class="n">cluster_assignment</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data Points (X):
 [[1 2]
 [2 3]
 [3 4]
 [6 7]
 [7 8]]
Jumlah Cluster: 2
Max Iterasi: 100
Parameter m (fuzzifier): 2.0

Menggunakan Matriks U Awal yang Disediakan.
Matriks U Awal (U_0):
[[0.5 0.7 0.8 0.7 0.6]
 [0.5 0.3 0.2 0.3 0.4]]

--- ITERASI 1 ---
Cluster Pusat (V_1):
[[3.86098655 4.86098655]
 [3.50793651 4.50793651]]

Matriks U (U_1):
[[0.37125775 0.30122773 0.1080429  0.6481838  0.60499865]
 [0.62874225 0.69877227 0.8919571  0.3518162  0.39500135]]

Fungsi Objektif (J_1): 26.90665252

--- ITERASI 2 ---
Cluster Pusat (V_2):
[[5.29744344 6.29744344]
 [2.85528846 3.85528846]]

Matriks U (U_2):
[[3.35718046e-02 4.50588110e-03 1.57407903e-05 9.97515029e-01
  9.72315532e-01]
 [9.66428195e-01 9.95494119e-01 9.99984259e-01 2.48497127e-03
  2.76844678e-02]]

Fungsi Objektif (J_2): 14.45312553

--- ITERASI 3 ---
Cluster Pusat (V_3):
[[6.48397718 7.48397718]
 [2.02387159 3.02387159]]

Matriks U (U_3):
[[1.21359015e-03 8.03289417e-10 6.12433102e-03 9.99780536e-01
  9.99884373e-01]
 [9.98786410e-01 9.99999999e-01 9.93875669e-01 2.19463664e-04
  1.15626954e-04]]

Fungsi Objektif (J_3): 4.97676257

--- ITERASI 4 ---
Cluster Pusat (V_4):
[[6.49998222 7.49998222]
 [1.99672228 2.99672228]]

Matriks U (U_4):
[[1.07741584e-03 2.81478182e-13 6.70654582e-03 9.99756752e-01
  9.99900258e-01]
 [9.98922584e-01 1.00000000e+00 9.93293454e-01 2.43248233e-04
  9.97424528e-05]]

Fungsi Objektif (J_4): 4.96970515

--- ITERASI 5 ---
Cluster Pusat (V_5):
[[6.49998983 7.49998983]
 [1.99624251 2.99624251]]

Matriks U (U_5):
[[1.07533915e-03 4.86123533e-13 6.71923907e-03 9.99756853e-01
  9.99900302e-01]
 [9.98924661e-01 1.00000000e+00 9.93280761e-01 2.43146504e-04
  9.96981324e-05]]

Fungsi Objektif (J_5): 4.96966525

--- ITERASI 6 ---
Cluster Pusat (V_6):
[[6.49998952 7.49998952]
 [1.99623264 2.99623264]]

Matriks U (U_6):
[[1.07529685e-03 4.91249396e-13 6.71950387e-03 9.99756857e-01
  9.99900302e-01]
 [9.98924703e-01 1.00000000e+00 9.93280496e-01 2.43143495e-04
  9.96975972e-05]]

Fungsi Objektif (J_6): 4.96966444

Konvergen pada iterasi ke-6.


--- HASIL AKHIR ---
Pusat Cluster Final (V):
 [[6.49998952 7.49998952]
 [1.99623264 2.99623264]]

Matriks Keanggotaan Final (U):
 [[1.07529685e-03 4.91249396e-13 6.71950387e-03 9.99756857e-01
  9.99900302e-01]
 [9.98924703e-01 1.00000000e+00 9.93280496e-01 2.43143495e-04
  9.96975972e-05]]

Penugasan Cluster (berdasarkan keanggotaan tertinggi):
Data [1 2] -&gt; Cluster 2
Data [2 3] -&gt; Cluster 2
Data [3 4] -&gt; Cluster 2
Data [6 7] -&gt; Cluster 1
Data [7 8] -&gt; Cluster 1
</pre></div>
</div>
</div>
</div>
<p>Tentu, mari kita lakukan perhitungan manual untuk iterasi pertama dari algoritma Fuzzy C-Means (FCM) berdasarkan kode dan output yang Anda berikan.</p>
<p><strong>Parameter Awal:</strong></p>
<ul>
<li><p><strong>Data Points (<span class="math notranslate nohighlight">\(X\)</span>)</strong>:
<span class="math notranslate nohighlight">\(X_1 = [1, 2]\)</span>
<span class="math notranslate nohighlight">\(X_2 = [2, 3]\)</span>
<span class="math notranslate nohighlight">\(X_3 = [3, 4]\)</span>
<span class="math notranslate nohighlight">\(X_4 = [6, 7]\)</span>
<span class="math notranslate nohighlight">\(X_5 = [7, 8]\)</span></p></li>
<li><p><strong>Jumlah Cluster (<span class="math notranslate nohighlight">\(c\)</span>)</strong>: 2</p></li>
<li><p><strong>Parameter Fuzzifier (<span class="math notranslate nohighlight">\(m\)</span>)</strong>: 2.0</p></li>
<li><p><strong>Matriks Keanggotaan Awal (<span class="math notranslate nohighlight">\(U^{(0)}\)</span>)</strong> (U_awal_kustom):</p>
<p><span class="math notranslate nohighlight">\(U^{(0)}= \begin{pmatrix} 0.5 &amp; 0.7 &amp; 0.8 &amp; 0.7 &amp; 0.6 \\ 0.5 &amp; 0.3 &amp; 0.2 &amp; 0.3 &amp; 0.4 \end{pmatrix}\)</span></p>
<p>Ini berarti:
<span class="math notranslate nohighlight">\(u_{11}^{(0)} = 0.5, u_{21}^{(0)} = 0.7, u_{31}^{(0)} = 0.8, u_{41}^{(0)} = 0.7, u_{51}^{(0)} = 0.6\)</span> (keanggotaan data ke-i di cluster 1)
<span class="math notranslate nohighlight">\(u_{12}^{(0)} = 0.5, u_{22}^{(0)} = 0.3, u_{32}^{(0)} = 0.2, u_{42}^{(0)} = 0.3, u_{52}^{(0)} = 0.4\)</span> (keanggotaan data ke-i di cluster 2)</p>
</li>
</ul>
<hr class="docutils" />
<section id="langkah-langkah-fcm">
<h2>Langkah-langkah FCM:<a class="headerlink" href="#langkah-langkah-fcm" title="Link to this heading">#</a></h2>
<p>Algoritma FCM bekerja secara iteratif melalui dua langkah utama:</p>
<ol class="arabic simple">
<li><p><strong>Perhitungan Pusat Cluster (<span class="math notranslate nohighlight">\(V\)</span>)</strong>:
Formula: <span class="math notranslate nohighlight">\(V_{jk} = \frac{\sum_{i=1}^{N} (u_{ij})^m \cdot X_{ik}}{\sum_{i=1}^{N} (u_{ij})^m}\)</span>
dimana <span class="math notranslate nohighlight">\(N\)</span> adalah jumlah titik data, <span class="math notranslate nohighlight">\(u_{ij}\)</span> adalah derajat keanggotaan titik data <span class="math notranslate nohighlight">\(i\)</span> ke cluster <span class="math notranslate nohighlight">\(j\)</span>, <span class="math notranslate nohighlight">\(X_{ik}\)</span> adalah fitur ke-<span class="math notranslate nohighlight">\(k\)</span> dari titik data <span class="math notranslate nohighlight">\(i\)</span>, dan <span class="math notranslate nohighlight">\(m\)</span> adalah parameter fuzzifier.</p></li>
<li><p><strong>Perhitungan Matriks Keanggotaan (<span class="math notranslate nohighlight">\(U\)</span>)</strong>:
Formula: <span class="math notranslate nohighlight">\(u_{ij} = \frac{1}{\sum_{k=1}^{c} \left(\frac{d_{ij}}{d_{ik}}\right)^{\frac{2}{m-1}}}\)</span>
dimana <span class="math notranslate nohighlight">\(d_{ij} = ||X_i - V_j||\)</span> adalah jarak Euclidean antara titik data <span class="math notranslate nohighlight">\(X_i\)</span> dan pusat cluster <span class="math notranslate nohighlight">\(V_j\)</span>.
Karena <span class="math notranslate nohighlight">\(m=2\)</span>, maka <span class="math notranslate nohighlight">\(\frac{2}{m-1} = \frac{2}{2-1} = 2\)</span>.
Sehingga formula menjadi: <span class="math notranslate nohighlight">\(u_{ij} = \frac{1}{\sum_{k=1}^{c} \left(\frac{d_{ij}}{d_{ik}}\right)^2}\)</span>.
Untuk <span class="math notranslate nohighlight">\(c=2\)</span>, ini dapat disederhanakan menjadi:
<span class="math notranslate nohighlight">\(u_{i1} = \frac{(d_{i2})^2}{(d_{i1})^2 + (d_{i2})^2}\)</span> dan <span class="math notranslate nohighlight">\(u_{i2} = \frac{(d_{i1})^2}{(d_{i1})^2 + (d_{i2})^2}\)</span>.</p></li>
</ol>
</section>
<hr class="docutils" />
<section id="iterasi-1">
<h2>Iterasi 1<a class="headerlink" href="#iterasi-1" title="Link to this heading">#</a></h2>
<section id="perhitungan-pusat-cluster-v-1">
<h3>1. Perhitungan Pusat Cluster (<span class="math notranslate nohighlight">\(V^{(1)}\)</span>)<a class="headerlink" href="#perhitungan-pusat-cluster-v-1" title="Link to this heading">#</a></h3>
<p>Menggunakan <span class="math notranslate nohighlight">\(U^{(0)}\)</span>:</p>
<p><strong>Untuk Cluster 1 (<span class="math notranslate nohighlight">\(V_1^{(1)}\)</span>):</strong>
Penyebut: <span class="math notranslate nohighlight">\(\sum_{i=1}^{5} (u_{i1}^{(0)})^m = (0.5)^2 + (0.7)^2 + (0.8)^2 + (0.7)^2 + (0.6)^2 = 0.25 + 0.49 + 0.64 + 0.49 + 0.36 = 2.23\)</span></p>
<p>Pembilang untuk fitur pertama (<span class="math notranslate nohighlight">\(V_{11}^{(1)}\)</span>):
<span class="math notranslate nohighlight">\((0.5)^2 \cdot 1 + (0.7)^2 \cdot 2 + (0.8)^2 \cdot 3 + (0.7)^2 \cdot 6 + (0.6)^2 \cdot 7\)</span>
<span class="math notranslate nohighlight">\(= 0.25 \cdot 1 + 0.49 \cdot 2 + 0.64 \cdot 3 + 0.49 \cdot 6 + 0.36 \cdot 7\)</span>
<span class="math notranslate nohighlight">\(= 0.25 + 0.98 + 1.92 + 2.94 + 2.52 = 8.61\)</span>
<span class="math notranslate nohighlight">\(V_{11}^{(1)} = \frac{8.61}{2.23} \approx 3.86098655\)</span></p>
<p>Pembilang untuk fitur kedua (<span class="math notranslate nohighlight">\(V_{12}^{(1)}\)</span>):
<span class="math notranslate nohighlight">\((0.5)^2 \cdot 2 + (0.7)^2 \cdot 3 + (0.8)^2 \cdot 4 + (0.7)^2 \cdot 7 + (0.6)^2 \cdot 8\)</span>
<span class="math notranslate nohighlight">\(= 0.25 \cdot 2 + 0.49 \cdot 3 + 0.64 \cdot 4 + 0.49 \cdot 7 + 0.36 \cdot 8\)</span>
<span class="math notranslate nohighlight">\(= 0.50 + 1.47 + 2.56 + 3.43 + 2.88 = 10.84\)</span>
<span class="math notranslate nohighlight">\(V_{12}^{(1)} = \frac{10.84}{2.23} \approx 4.86098655\)</span></p>
<p>Jadi, <span class="math notranslate nohighlight">\(V_1^{(1)} = [3.86098655, 4.86098655]\)</span></p>
<p><strong>Untuk Cluster 2 (<span class="math notranslate nohighlight">\(V_2^{(1)}\)</span>):</strong>
Penyebut: <span class="math notranslate nohighlight">\(\sum_{i=1}^{5} (u_{i2}^{(0)})^m = (0.5)^2 + (0.3)^2 + (0.2)^2 + (0.3)^2 + (0.4)^2 = 0.25 + 0.09 + 0.04 + 0.09 + 0.16 = 0.63\)</span></p>
<p>Pembilang untuk fitur pertama (<span class="math notranslate nohighlight">\(V_{21}^{(1)}\)</span>):
<span class="math notranslate nohighlight">\((0.5)^2 \cdot 1 + (0.3)^2 \cdot 2 + (0.2)^2 \cdot 3 + (0.3)^2 \cdot 6 + (0.4)^2 \cdot 7\)</span>
<span class="math notranslate nohighlight">\(= 0.25 \cdot 1 + 0.09 \cdot 2 + 0.04 \cdot 3 + 0.09 \cdot 6 + 0.16 \cdot 7\)</span>
<span class="math notranslate nohighlight">\(= 0.25 + 0.18 + 0.12 + 0.54 + 1.12 = 2.21\)</span>
<span class="math notranslate nohighlight">\(V_{21}^{(1)} = \frac{2.21}{0.63} \approx 3.50793651\)</span></p>
<p>Pembilang untuk fitur kedua (<span class="math notranslate nohighlight">\(V_{22}^{(1)}\)</span>):
<span class="math notranslate nohighlight">\((0.5)^2 \cdot 2 + (0.3)^2 \cdot 3 + (0.2)^2 \cdot 4 + (0.3)^2 \cdot 7 + (0.4)^2 \cdot 8\)</span>
<span class="math notranslate nohighlight">\(= 0.25 \cdot 2 + 0.09 \cdot 3 + 0.04 \cdot 4 + 0.09 \cdot 7 + 0.16 \cdot 8\)</span>
<span class="math notranslate nohighlight">\(= 0.50 + 0.27 + 0.16 + 0.63 + 1.28 = 2.84\)</span>
<span class="math notranslate nohighlight">\(V_{22}^{(1)} = \frac{2.84}{0.63} \approx 4.50793651\)</span></p>
<p>Jadi, <span class="math notranslate nohighlight">\(V_2^{(1)} = [3.50793651, 4.50793651]\)</span></p>
<p><strong>Pusat Cluster (<span class="math notranslate nohighlight">\(V^{(1)}\)</span>) pada Iterasi 1 adalah:</strong>
<span class="math notranslate nohighlight">\(V^{(1)} = \begin{pmatrix} 3.86098655 &amp; 4.86098655 \\ 3.50793651 &amp; 4.50793651 \end{pmatrix}\)</span>
(Ini sesuai dengan output â€œCluster Pusat (V_1)â€)</p>
</section>
<hr class="docutils" />
<section id="perhitungan-matriks-keanggotaan-u-1">
<h3>2. Perhitungan Matriks Keanggotaan (<span class="math notranslate nohighlight">\(U^{(1)}\)</span>)<a class="headerlink" href="#perhitungan-matriks-keanggotaan-u-1" title="Link to this heading">#</a></h3>
<p>Menggunakan <span class="math notranslate nohighlight">\(V^{(1)}\)</span> yang baru dihitung. Kita akan menghitung kuadrat jarak (<span class="math notranslate nohighlight">\(d^2\)</span>) terlebih dahulu.</p>
<p><strong>Untuk Titik Data <span class="math notranslate nohighlight">\(X_1 = [1, 2]\)</span>:</strong>
<span class="math notranslate nohighlight">\(d_{11}^2 = (1 - 3.86098655)^2 + (2 - 4.86098655)^2 = (-2.86098655)^2 + (-2.86098655)^2 \approx 8.185260 + 8.185260 \approx 16.370520\)</span>
<span class="math notranslate nohighlight">\(d_{12}^2 = (1 - 3.50793651)^2 + (2 - 4.50793651)^2 = (-2.50793651)^2 + (-2.50793651)^2 \approx 6.289744 + 6.289744 \approx 12.579488\)</span>
<span class="math notranslate nohighlight">\(u_{11}^{(1)} = \frac{12.579488}{16.370520 + 12.579488} = \frac{12.579488}{28.950008} \approx 0.43452505\)</span>
<span class="math notranslate nohighlight">\(u_{12}^{(1)} = \frac{16.370520}{28.950008} \approx 0.56547495\)</span></p>
<p><strong>Untuk Titik Data <span class="math notranslate nohighlight">\(X_2 = [2, 3]\)</span>:</strong>
<span class="math notranslate nohighlight">\(d_{21}^2 = (2 - 3.86098655)^2 + (3 - 4.86098655)^2 = (-1.86098655)^2 + (-1.86098655)^2 \approx 3.463271 + 3.463271 \approx 6.926542\)</span>
<span class="math notranslate nohighlight">\(d_{22}^2 = (2 - 3.50793651)^2 + (3 - 4.50793651)^2 = (-1.50793651)^2 + (-1.50793651)^2 \approx 2.273872 + 2.273872 \approx 4.547744\)</span>
<span class="math notranslate nohighlight">\(u_{21}^{(1)} = \frac{4.547744}{6.926542 + 4.547744} = \frac{4.547744}{11.474286} \approx 0.39634228\)</span>
<span class="math notranslate nohighlight">\(u_{22}^{(1)} = \frac{6.926542}{11.474286} \approx 0.60365772\)</span></p>
<p><strong>Untuk Titik Data <span class="math notranslate nohighlight">\(X_3 = [3, 4]\)</span>:</strong>
<span class="math notranslate nohighlight">\(d_{31}^2 = (3 - 3.86098655)^2 + (4 - 4.86098655)^2 = (-0.86098655)^2 + (-0.86098655)^2 \approx 0.741302 + 0.741302 \approx 1.482604\)</span>
<span class="math notranslate nohighlight">\(d_{32}^2 = (3 - 3.50793651)^2 + (4 - 4.50793651)^2 = (-0.50793651)^2 + (-0.50793651)^2 \approx 0.258000 + 0.258000 \approx 0.516000\)</span>
<span class="math notranslate nohighlight">\(u_{31}^{(1)} = \frac{0.516000}{1.482604 + 0.516000} = \frac{0.516000}{1.998604} \approx 0.25818091\)</span>
<span class="math notranslate nohighlight">\(u_{32}^{(1)} = \frac{1.482604}{1.998604} \approx 0.74181909\)</span></p>
<p><strong>Untuk Titik Data <span class="math notranslate nohighlight">\(X_4 = [6, 7]\)</span>:</strong>
<span class="math notranslate nohighlight">\(d_{41}^2 = (6 - 3.86098655)^2 + (7 - 4.86098655)^2 = (2.13901345)^2 + (2.13901345)^2 \approx 4.575338 + 4.575338 \approx 9.150676\)</span>
<span class="math notranslate nohighlight">\(d_{42}^2 = (6 - 3.50793651)^2 + (7 - 4.50793651)^2 = (2.49206349)^2 + (2.49206349)^2 \approx 6.210376 + 6.210376 \approx 12.420752\)</span>
<span class="math notranslate nohighlight">\(u_{41}^{(1)} = \frac{12.420752}{9.150676 + 12.420752} = \frac{12.420752}{21.571428} \approx 0.57579448\)</span>
<span class="math notranslate nohighlight">\(u_{42}^{(1)} = \frac{9.150676}{21.571428} \approx 0.42420552\)</span></p>
<p><strong>Untuk Titik Data <span class="math notranslate nohighlight">\(X_5 = [7, 8]\)</span>:</strong>
<span class="math notranslate nohighlight">\(d_{51}^2 = (7 - 3.86098655)^2 + (8 - 4.86098655)^2 = (3.13901345)^2 + (3.13901345)^2 \approx 9.853431 + 9.853431 \approx 19.706862\)</span>
<span class="math notranslate nohighlight">\(d_{52}^2 = (7 - 3.50793651)^2 + (8 - 4.50793651)^2 = (3.49206349)^2 + (3.49206349)^2 \approx 12.194508 + 12.194508 \approx 24.389016\)</span>
<span class="math notranslate nohighlight">\(u_{51}^{(1)} = \frac{24.389016}{19.706862 + 24.389016} = \frac{24.389016}{44.095878} \approx 0.55309124\)</span>
<span class="math notranslate nohighlight">\(u_{52}^{(1)} = \frac{19.706862}{44.095878} \approx 0.44690876\)</span></p>
<p><strong>Matriks Keanggotaan (<span class="math notranslate nohighlight">\(U^{(1)}\)</span>) pada Iterasi 1 adalah:</strong>
<span class="math notranslate nohighlight">\(U^{(1)} = \begin{pmatrix} 0.43452505 &amp; 0.39634228 &amp; 0.25818091 &amp; 0.57579448 &amp; 0.55309124 \\ 0.56547495 &amp; 0.60365772 &amp; 0.74181909 &amp; 0.42420552 &amp; 0.44690876 \end{pmatrix}\)</span>
(Ini sesuai dengan output â€œMatriks U (U_1)â€)</p>
</section>
<hr class="docutils" />
<section id="perhitungan-fungsi-objektif-j-1-opsional-untuk-verifikasi">
<h3>3. Perhitungan Fungsi Objektif (<span class="math notranslate nohighlight">\(J^{(1)}\)</span>) (Opsional, untuk verifikasi)<a class="headerlink" href="#perhitungan-fungsi-objektif-j-1-opsional-untuk-verifikasi" title="Link to this heading">#</a></h3>
<p>Formula: <span class="math notranslate nohighlight">\(J_m(U, V) = \sum_{i=1}^{N} \sum_{j=1}^{c} (u_{ij})^m \cdot (d_{ij})^2\)</span>
Karena <span class="math notranslate nohighlight">\(m=2\)</span>: <span class="math notranslate nohighlight">\(J = \sum_{i=1}^{5} \sum_{j=1}^{2} (u_{ij}^{(1)})^2 \cdot (d_{ij}^{(1)})^2\)</span></p>
<p><span class="math notranslate nohighlight">\(J^{(1)} = (0.43452505)^2 \cdot 16.370520 + (0.56547495)^2 \cdot 12.579488\)</span> (untuk <span class="math notranslate nohighlight">\(X_1\)</span>)
<span class="math notranslate nohighlight">\(+ (0.39634228)^2 \cdot 6.926542 + (0.60365772)^2 \cdot 4.547744\)</span> (untuk <span class="math notranslate nohighlight">\(X_2\)</span>)
<span class="math notranslate nohighlight">\(+ (0.25818091)^2 \cdot 1.482604 + (0.74181909)^2 \cdot 0.516000\)</span> (untuk <span class="math notranslate nohighlight">\(X_3\)</span>)
<span class="math notranslate nohighlight">\(+ (0.57579448)^2 \cdot 9.150676 + (0.42420552)^2 \cdot 12.420752\)</span> (untuk <span class="math notranslate nohighlight">\(X_4\)</span>)
<span class="math notranslate nohighlight">\(+ (0.55309124)^2 \cdot 19.706862 + (0.44690876)^2 \cdot 24.389016\)</span> (untuk <span class="math notranslate nohighlight">\(X_5\)</span>)</p>
<p><span class="math notranslate nohighlight">\(J^{(1)} \approx (0.188812 \cdot 16.370520) + (0.319762 \cdot 12.579488)\)</span>
<span class="math notranslate nohighlight">\(+ (0.157087 \cdot 6.926542) + (0.364402 \cdot 4.547744)\)</span>
<span class="math notranslate nohighlight">\(+ (0.066657 \cdot 1.482604) + (0.550295 \cdot 0.516000)\)</span>
<span class="math notranslate nohighlight">\(+ (0.331539 \cdot 9.150676) + (0.179950 \cdot 12.420752)\)</span>
<span class="math notranslate nohighlight">\(+ (0.305910 \cdot 19.706862) + (0.199727 \cdot 24.389016)\)</span></p>
<p><span class="math notranslate nohighlight">\(J^{(1)} \approx 3.09099 + 4.02245\)</span>
<span class="math notranslate nohighlight">\(+ 1.08838 + 1.65722\)</span>
<span class="math notranslate nohighlight">\(+ 0.09882 + 0.28395\)</span>
<span class="math notranslate nohighlight">\(+ 3.03292 + 2.23517\)</span>
<span class="math notranslate nohighlight">\(+ 6.02838 + 4.87119\)</span></p>
<p><span class="math notranslate nohighlight">\(J^{(1)} \approx 7.11344 + 2.74560 + 0.38277 + 5.26809 + 10.89957 \approx 26.40947\)</span>
(Output menunjukkan <span class="math notranslate nohighlight">\(J_1 = 26.41006623\)</span>. Perbedaan kecil disebabkan oleh pembulatan dalam perhitungan manual.)</p>
<hr class="docutils" />
<p>Iterasi selanjutnya (Iterasi 2, 3, dst.) akan mengulangi langkah 1 dan 2 menggunakan matriks keanggotaan <span class="math notranslate nohighlight">\(U\)</span> dari iterasi sebelumnya untuk menghitung pusat cluster <span class="math notranslate nohighlight">\(V\)</span> yang baru, dan kemudian menggunakan pusat cluster <span class="math notranslate nohighlight">\(V\)</span> yang baru tersebut untuk menghitung matriks keanggotaan <span class="math notranslate nohighlight">\(U\)</span> yang baru. Proses ini berlanjut hingga kriteria konvergensi terpenuhi (perubahan <span class="math notranslate nohighlight">\(U\)</span> atau <span class="math notranslate nohighlight">\(V\)</span> atau <span class="math notranslate nohighlight">\(J\)</span> sangat kecil) atau jumlah maksimum iterasi tercapai.</p>
<p><strong>Penugasan Cluster Akhir:</strong>
Setelah algoritma konvergen pada iterasi ke-7, penugasan cluster dilakukan dengan memilih cluster dengan nilai keanggotaan tertinggi untuk setiap titik data dari Matriks Keanggotaan Final (<span class="math notranslate nohighlight">\(U_{final}\)</span>).
Misalnya, untuk Data [1 2] (kolom pertama <span class="math notranslate nohighlight">\(U_{final}\)</span>):
<span class="math notranslate nohighlight">\(u_{11} \approx 0.030\)</span> (keanggotaan di Cluster 1)
<span class="math notranslate nohighlight">\(u_{12} \approx 0.970\)</span> (keanggotaan di Cluster 2)
Karena <span class="math notranslate nohighlight">\(u_{12} &gt; u_{11}\)</span>, maka Data [1 2] ditugaskan ke Cluster 2. Proses serupa dilakukan untuk semua titik data lainnya.</p>
</section>
</section>
<section id="normalisasi-data">
<h2>normalisasi data<a class="headerlink" href="#normalisasi-data" title="Link to this heading">#</a></h2>
<section id="penjelasan-normalisasi-min-max-scaling">
<h3>Penjelasan Normalisasi (Min-Max Scaling)<a class="headerlink" href="#penjelasan-normalisasi-min-max-scaling" title="Link to this heading">#</a></h3>
<p>Normalisasi, dalam konteks kode yang Anda berikan menggunakan <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code>, adalah sebuah teknik pra-pemrosesan data yang bertujuan untuk <strong>mengubah skala nilai fitur-fitur numerik ke dalam rentang tertentu, biasanya antara 0 dan 1.</strong></p>
</section>
<hr class="docutils" />
<section id="mengapa-normalisasi-penting">
<h3>Mengapa Normalisasi Penting?<a class="headerlink" href="#mengapa-normalisasi-penting" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Skala Fitur yang Berbeda</strong>: Seringkali, dataset memiliki fitur-fitur dengan satuan dan rentang nilai yang sangat berbeda. Misalnya, satu fitur mungkin memiliki rentang 0-1000, sementara fitur lain hanya 0-1. Algoritma machine learning tertentu, terutama yang berbasis jarak (seperti K-Nearest Neighbors, SVM, PCA) atau yang menggunakan gradient descent (seperti regresi linear, neural networks), bisa sangat sensitif terhadap perbedaan skala ini. Fitur dengan rentang nilai yang lebih besar dapat mendominasi perhitungan jarak atau pembaruan bobot, sehingga fitur dengan rentang nilai yang lebih kecil seolah-olah kurang penting, padahal belum tentu demikian.</p></li>
<li><p><strong>Konvergensi Lebih Cepat</strong>: Untuk algoritma yang menggunakan gradient descent, normalisasi dapat membantu mempercepat proses konvergensi menuju solusi optimal. Ketika fitur-fitur memiliki skala yang serupa, <em>contour plot</em> dari fungsi <em>loss</em> menjadi lebih bulat, memungkinkan algoritma untuk mengambil langkah yang lebih langsung menuju minimum.</p></li>
<li><p><strong>Peningkatan Kinerja Model</strong>: Dengan mengatasi masalah skala fitur yang berbeda, normalisasi seringkali dapat meningkatkan kinerja dan akurasi model machine learning.</p></li>
<li><p><strong>Mencegah Masalah Numerik</strong>: Pada beberapa kasus, rentang nilai yang sangat besar atau sangat kecil dapat menyebabkan masalah stabilitas numerik dalam perhitungan.</p></li>
</ol>
</section>
<hr class="docutils" />
<section id="bagaimana-minmaxscaler-bekerja">
<h3>Bagaimana <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code> Bekerja?<a class="headerlink" href="#bagaimana-minmaxscaler-bekerja" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code> mentransformasi setiap fitur secara individual dengan rumus berikut:</p>
<div class="math notranslate nohighlight">
\[X_{scaled} = \frac{X - X_{min}}{X_{max} - X_{min}}\]</div>
<p>Dimana:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X\)</span> adalah nilai asli dari data pada suatu fitur.</p></li>
<li><p><span class="math notranslate nohighlight">\(X_{min}\)</span> adalah nilai minimum dari fitur tersebut di seluruh dataset.</p></li>
<li><p><span class="math notranslate nohighlight">\(X_{max}\)</span> adalah nilai maksimum dari fitur tersebut di seluruh dataset.</p></li>
<li><p><span class="math notranslate nohighlight">\(X_{scaled}\)</span> adalah nilai yang telah dinormalisasi, yang akan berada dalam rentang [0, 1].</p></li>
</ul>
<p>Jadi, untuk setiap kolom (fitur) dalam data Anda:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code> pertama-tama akan menemukan nilai minimum dan maksimum pada kolom tersebut dari data training (<code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> melakukan ini).</p></li>
<li><p>Kemudian, setiap nilai dalam kolom tersebut akan diubah menggunakan rumus di atas. Nilai minimum asli akan menjadi 0, nilai maksimum asli akan menjadi 1, dan nilai-nilai lainnya akan diskalakan secara proporsional di antara 0 dan 1.</p></li>
</ol>
</section>
<hr class="docutils" />
<section id="implementasi-dalam-kode-anda">
<h3>Implementasi dalam Kode Anda:<a class="headerlink" href="#implementasi-dalam-kode-anda" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">=</span> <span class="pre">data_iris.drop(columns=['species'])</span></code></strong>: Anda memisahkan fitur-fitur (sepal length, sepal width, petal length, petal width) dari kolom target (<code class="docutils literal notranslate"><span class="pre">species</span></code>). Normalisasi biasanya hanya dilakukan pada fitur input.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">scaler</span> <span class="pre">=</span> <span class="pre">MinMaxScaler()</span></code></strong>: Anda membuat instance dari <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code>.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">X_scaled</span> <span class="pre">=</span> <span class="pre">scaler.fit_transform(X)</span></code></strong>:</p>
<ul class="simple">
<li><p>Metode <code class="docutils literal notranslate"><span class="pre">.fit(X)</span></code>: <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code> mempelajari (menghitung) nilai minimum dan maksimum untuk setiap fitur (kolom) dalam <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p></li>
<li><p>Metode <code class="docutils literal notranslate"><span class="pre">.transform(X)</span></code>: <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code> kemudian menggunakan nilai minimum dan maksimum yang telah dipelajari untuk menerapkan transformasi skala ke setiap nilai dalam <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fit_transform(X)</span></code> adalah pintasan yang menggabungkan kedua langkah tersebut.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">X_scaled_df</span> <span class="pre">=</span> <span class="pre">pd.DataFrame(X_scaled,</span> <span class="pre">columns=X.columns)</span></code></strong>: Hasil normalisasi (<code class="docutils literal notranslate"><span class="pre">X_scaled</span></code>) adalah array NumPy. Anda mengubahnya kembali menjadi DataFrame Pandas agar lebih mudah dibaca dan mempertahankan nama kolom aslinya.</p></li>
</ol>
<p>Setelah langkah-langkah ini, <code class="docutils literal notranslate"><span class="pre">X_scaled_df</span></code> akan berisi data fitur Iris Anda, tetapi sekarang setiap nilai dalam setiap kolom akan berada dalam rentang 0 hingga 1. Ini membuat semua fitur memiliki skala yang sebanding, yang dapat bermanfaat untuk analisis data lebih lanjut atau pelatihan model machine learning.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sqlalchemy</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_engine</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="c1"># # Info koneksi MySQL</span>
<span class="c1"># DB_HOST = &quot;mysql-34425cbd-irismysqlaldi.h.aivencloud.com&quot;</span>
<span class="c1"># DB_PORT = 22476</span>
<span class="c1"># DB_NAME = &quot;iris_baru&quot;</span>
<span class="c1"># DB_USER = &quot;avnadmin&quot;</span>
<span class="c1"># DB_PASS = &quot;AVNS_QsQ7Yf7zzcmrk83yFgg&quot;</span>

<span class="c1"># # Buat koneksi ke database via SQLAlchemy</span>
<span class="c1"># engine = create_engine(f&quot;mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}&quot;)</span>

<span class="c1"># # Query: ambil semua data dari tabel iris</span>
<span class="c1"># query = &quot;SELECT * FROM iris&quot;</span>

<span class="c1"># Load hasil query ke DataFrame</span>
<span class="n">data_iris</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">engine</span><span class="p">)</span>

<span class="c1"># Pisahkan fitur dan label</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data_iris</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">])</span>

<span class="c1"># Normalisasi pakai MinMaxScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Konversi kembali ke DataFrame biar tetap readable</span>
<span class="n">X_scaled_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># Tampilkan hasil normalisasi</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_scaled_df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>         id  sepal_length_cm  sepal_width_cm  petal_length_cm  petal_width_cm
0  0.000000         0.222222        0.625000         0.067797        0.041667
1  0.006711         0.166667        0.416667         0.067797        0.041667
2  0.013423         0.111111        0.500000         0.050847        0.041667
3  0.020134         0.083333        0.458333         0.084746        0.041667
4  0.026846         0.194444        0.666667         0.067797        0.041667
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sqlalchemy</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_engine</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">itertools</span><span class="w"> </span><span class="kn">import</span> <span class="n">permutations</span>

<span class="c1"># Fungsi-fungsi FCM modular</span>

<span class="k">def</span><span class="w"> </span><span class="nf">hitung_jarak_euclidean</span><span class="p">(</span><span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Menghitung jarak Euclidean antara dua titik.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">point1</span> <span class="o">-</span> <span class="n">point2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">inisialisasi_matriks_U_acak</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Inisialisasi matriks keanggotaan U secara acak.</span>
<span class="sd">    Setiap baris mewakili cluster, setiap kolom mewakili sampel data.</span>
<span class="sd">    Jumlah keanggotaan untuk setiap sampel data di semua cluster harus 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">n_samples</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">n_clusters</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">))</span> <span class="c1"># Kembali matriks kosong jika tidak ada data atau cluster</span>

    <span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="c1"># Normalisasi kolom sehingga jumlahnya menjadi 1</span>
    <span class="n">sum_cols_U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># Ganti 0 dengan epsilon untuk menghindari pembagian dengan nol</span>
    <span class="n">sum_cols_U</span><span class="p">[</span><span class="n">sum_cols_U</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
    <span class="n">U</span> <span class="o">=</span> <span class="n">U</span> <span class="o">/</span> <span class="n">sum_cols_U</span>
    <span class="k">return</span> <span class="n">U</span>

<span class="k">def</span><span class="w"> </span><span class="nf">hitung_pusat_cluster</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Menghitung pusat cluster V.&quot;&quot;&quot;</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">n_samples</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">n_clusters</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">V</span> <span class="c1"># Kembali matriks kosong jika tidak ada data atau cluster</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
        <span class="n">u_ik_pangkat_m</span> <span class="o">=</span> <span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">**</span> <span class="n">m</span>
        <span class="n">pembilang</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">u_ik_pangkat_m</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">penyebut</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">u_ik_pangkat_m</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">penyebut</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">pembilang</span> <span class="o">/</span> <span class="n">penyebut</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Fallback: jika penyebut nol (tidak ada titik yang menjadi anggota cluster ini),</span>
            <span class="c1"># gunakan rata-rata seluruh data.</span>
            <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span> <span class="c1"># Jika tidak ada data, set pusat ke nol</span>
    <span class="k">return</span> <span class="n">V</span>

<span class="k">def</span><span class="w"> </span><span class="nf">update_matriks_U</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Memperbarui matriks keanggotaan U.&quot;&quot;&quot;</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">U_baru</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">))</span>
    <span class="n">epsilon_jarak</span> <span class="o">=</span> <span class="mf">1e-9</span> <span class="c1"># Nilai kecil untuk menghindari pembagian dengan nol</span>

    <span class="k">if</span> <span class="n">n_samples</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">n_clusters</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">U_baru</span> <span class="c1"># Kembali matriks kosong jika tidak ada data atau cluster</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span> <span class="c1"># Untuk setiap titik data X[k]</span>
        <span class="n">jarak_ke_pusat_kuadrat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">)</span>

        <span class="c1"># Hitung semua jarak kuadrat terlebih dahulu</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
            <span class="n">jarak_kuadrat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">jarak_ke_pusat_kuadrat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">jarak_kuadrat</span>

        <span class="c1"># Cek apakah titik data bertepatan persis dengan salah satu pusat cluster (jarak sangat kecil)</span>
        <span class="n">close_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">jarak_ke_pusat_kuadrat</span> <span class="o">&lt;</span> <span class="n">epsilon_jarak</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">close_indices</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Jika ada satu atau lebih cluster yang bertepatan/sangat dekat,</span>
            <span class="c1"># berikan keanggotaan 1 secara merata di antara mereka.</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">close_indices</span><span class="p">:</span>
                <span class="n">U_baru</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">close_indices</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Kalkulasi standar jika tidak ada titik yang bertepatan</span>
            <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">epsilon_jarak</span><span class="p">:</span> <span class="c1"># Handle hard C-Means case (m=1)</span>
                <span class="n">closest_cluster_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">jarak_ke_pusat_kuadrat</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
                    <span class="n">U_baru</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">closest_cluster_idx</span> <span class="k">else</span> <span class="mf">0.0</span>
            <span class="k">else</span><span class="p">:</span> <span class="c1"># Fuzzy C-Means case (m &gt; 1)</span>
                <span class="n">power_term</span> <span class="o">=</span> <span class="mf">2.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span> <span class="c1"># Untuk setiap cluster V[i]</span>
                    <span class="n">pembilang_uik_kuadrat</span> <span class="o">=</span> <span class="n">jarak_ke_pusat_kuadrat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

                    <span class="n">denominator_uik</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
                        <span class="n">penyebut_rasio_kuadrat</span> <span class="o">=</span> <span class="n">jarak_ke_pusat_kuadrat</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

                        <span class="k">if</span> <span class="n">penyebut_rasio_kuadrat</span> <span class="o">&lt;</span> <span class="n">epsilon_jarak</span><span class="p">:</span>
                            <span class="n">denominator_uik</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pembilang_uik_kuadrat</span> <span class="o">/</span> <span class="n">epsilon_jarak</span><span class="p">)</span><span class="o">**</span><span class="n">power_term</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">denominator_uik</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pembilang_uik_kuadrat</span> <span class="o">/</span> <span class="n">penyebut_rasio_kuadrat</span><span class="p">)</span><span class="o">**</span><span class="n">power_term</span>

                    <span class="k">if</span> <span class="n">denominator_uik</span> <span class="o">&lt;</span> <span class="n">epsilon_jarak</span><span class="p">:</span>
                        <span class="n">U_baru</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">U_baru</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">denominator_uik</span>

    <span class="c1"># Normalisasi kolom untuk memastikan setiap kolom (sampel data) berjumlah 1</span>
    <span class="n">sum_cols_U_baru</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">U_baru</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">sum_cols_U_baru</span><span class="p">[</span><span class="n">sum_cols_U_baru</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
    <span class="n">U_baru</span> <span class="o">=</span> <span class="n">U_baru</span> <span class="o">/</span> <span class="n">sum_cols_U_baru</span>

    <span class="k">return</span> <span class="n">U_baru</span>


<span class="k">def</span><span class="w"> </span><span class="nf">hitung_fungsi_objektif</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Menghitung nilai fungsi objektif Jm.&quot;&quot;&quot;</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">n_clusters</span> <span class="o">=</span> <span class="n">V</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">Jm</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">if</span> <span class="n">n_samples</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">n_clusters</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">m</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
            <span class="n">dist_sq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dist_sq</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">dist_sq</span><span class="p">):</span>
                <span class="n">dist_sq</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">Jm</span> <span class="o">+=</span> <span class="p">(</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">**</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">dist_sq</span>

    <span class="k">return</span> <span class="n">Jm</span>

<span class="k">def</span><span class="w"> </span><span class="nf">fcm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">true_labels_pseudo</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Implementasi Fuzzy C-Means.&quot;&quot;&quot;</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">if</span> <span class="n">n_samples</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">n_clusters</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dataset kosong atau jumlah cluster adalah 0. FCM tidak dapat dijalankan.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)),</span> <span class="p">[]</span>

    <span class="n">U</span> <span class="o">=</span> <span class="n">inisialisasi_matriks_U_acak</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">)</span>
    <span class="n">fungsi_objektif_history</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">akurasi_history</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># Untuk menyimpan akurasi per iterasi</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Matriks U Awal (U_0):</span><span class="se">\n</span><span class="si">{</span><span class="n">U</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">iter_count</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--- ITERASI </span><span class="si">{</span><span class="n">iter_count</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> ---&quot;</span><span class="p">)</span>
        <span class="n">V</span> <span class="o">=</span> <span class="n">hitung_pusat_cluster</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cluster Pusat (V_</span><span class="si">{</span><span class="n">iter_count</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">):</span><span class="se">\n</span><span class="si">{</span><span class="n">V</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">U_baru</span> <span class="o">=</span> <span class="n">update_matriks_U</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Matriks U (U_</span><span class="si">{</span><span class="n">iter_count</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">):</span><span class="se">\n</span><span class="si">{</span><span class="n">U_baru</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">Jm</span> <span class="o">=</span> <span class="n">hitung_fungsi_objektif</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">U_baru</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
        <span class="n">fungsi_objektif_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Jm</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fungsi Objektif (J_</span><span class="si">{</span><span class="n">iter_count</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">Jm</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Hitung akurasi per iterasi jika pseudo-true-labels disediakan</span>
        <span class="k">if</span> <span class="n">true_labels_pseudo</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">true_labels_pseudo</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">predicted_labels_iter</span> <span class="o">=</span> <span class="n">get_hard_labels</span><span class="p">(</span><span class="n">U_baru</span><span class="p">)</span>
            <span class="n">min_len_iter</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">true_labels_pseudo</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted_labels_iter</span><span class="p">))</span>

            <span class="c1"># Pastikan panjang kedua array sama sebelum menghitung akurasi</span>
            <span class="k">if</span> <span class="n">min_len_iter</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">acc_iter</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">hitung_akurasi</span><span class="p">(</span>
                    <span class="n">true_labels_pseudo</span><span class="p">[:</span><span class="n">min_len_iter</span><span class="p">],</span>
                    <span class="n">predicted_labels_iter</span><span class="p">[:</span><span class="n">min_len_iter</span><span class="p">],</span>
                    <span class="n">n_clusters</span>
                <span class="p">)</span>
                <span class="n">akurasi_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_iter</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi Iterasi </span><span class="si">{</span><span class="n">iter_count</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">acc_iter</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">akurasi_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span> <span class="c1"># Jika tidak ada data untuk dihitung</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tidak dapat menghitung akurasi untuk iterasi ini (data kosong).</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>


        <span class="n">norm_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">U_baru</span> <span class="o">-</span> <span class="n">U</span><span class="p">,</span> <span class="s1">&#39;fro&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">norm_diff</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Konvergen pada iterasi </span><span class="si">{</span><span class="n">iter_count</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="n">U</span> <span class="o">=</span> <span class="n">U_baru</span>
            <span class="k">break</span>
        <span class="n">U</span> <span class="o">=</span> <span class="n">U_baru</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iterasi maksimum </span><span class="si">{</span><span class="n">max_iter</span><span class="si">}</span><span class="s2"> tercapai.&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">U</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">fungsi_objektif_history</span><span class="p">,</span> <span class="n">akurasi_history</span> <span class="c1"># Mengembalikan akurasi history</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_hard_labels</span><span class="p">(</span><span class="n">U</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mengembalikan label cluster (hard assignment) dari matriks U.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">U</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">hitung_akurasi</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="p">,</span> <span class="n">n_clusters_expected</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Menghitung akurasi dengan mencari permutasi terbaik dari label prediksi.</span>
<span class="sd">    Ini diperlukan karena FCM tidak menjamin urutan label cluster.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">true_labels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted_labels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span><span class="p">,</span> <span class="p">{}</span>

    <span class="c1"># Pastikan label-label ini adalah integer untuk pemetaan</span>
    <span class="n">true_labels_int</span> <span class="o">=</span> <span class="n">true_labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">predicted_labels_int</span> <span class="o">=</span> <span class="n">predicted_labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="n">true_unique</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">true_labels_int</span><span class="p">)</span>
    <span class="n">predicted_unique</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">predicted_labels_int</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">true_unique</span><span class="p">)</span> <span class="o">!=</span> <span class="n">n_clusters_expected</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Peringatan: Jumlah label asli unik (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">true_unique</span><span class="p">)</span><span class="si">}</span><span class="s2">) tidak sama dengan jumlah cluster yang diharapkan (</span><span class="si">{</span><span class="n">n_clusters_expected</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>

    <span class="n">best_accuracy</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">best_mapping</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="n">predicted_cluster_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predicted_unique</span><span class="p">)))</span>
    <span class="n">true_label_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">true_unique</span><span class="p">)))</span>

    <span class="n">predicted_to_temp_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">val</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">predicted_unique</span><span class="p">)}</span>
    <span class="n">temp_idx_predicted_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">predicted_to_temp_idx</span><span class="p">[</span><span class="n">val</span><span class="p">]</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">predicted_labels_int</span><span class="p">])</span>

    <span class="n">true_to_temp_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">val</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">true_unique</span><span class="p">)}</span>
    <span class="n">temp_idx_true_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">true_to_temp_idx</span><span class="p">[</span><span class="n">val</span><span class="p">]</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">true_labels_int</span><span class="p">])</span>

    <span class="n">perm_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predicted_unique</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">true_unique</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">perm_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span><span class="p">,</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">permutations</span><span class="p">(</span><span class="n">true_label_indices</span><span class="p">,</span> <span class="n">perm_size</span><span class="p">):</span>
        <span class="n">current_mapping_temp_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">predicted_cluster_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">perm_size</span><span class="p">)}</span>

        <span class="n">mapped_labels_for_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">temp_idx_predicted_labels</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">pred_idx_temp</span> <span class="ow">in</span> <span class="n">predicted_cluster_indices</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">pred_idx_temp</span> <span class="ow">in</span> <span class="n">current_mapping_temp_idx</span><span class="p">:</span>
                <span class="n">mapped_labels_for_perm</span><span class="p">[</span><span class="n">temp_idx_predicted_labels</span> <span class="o">==</span> <span class="n">pred_idx_temp</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_mapping_temp_idx</span><span class="p">[</span><span class="n">pred_idx_temp</span><span class="p">]</span>

        <span class="n">valid_comparison_indices</span> <span class="o">=</span> <span class="p">(</span><span class="n">mapped_labels_for_perm</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">valid_comparison_indices</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">current_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">temp_idx_true_labels</span><span class="p">[</span><span class="n">valid_comparison_indices</span><span class="p">],</span> <span class="n">mapped_labels_for_perm</span><span class="p">[</span><span class="n">valid_comparison_indices</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">current_accuracy</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
                <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">current_accuracy</span>
                <span class="n">best_mapping</span> <span class="o">=</span> <span class="p">{</span><span class="n">predicted_unique</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span> <span class="n">true_unique</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">current_mapping_temp_idx</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="k">return</span> <span class="n">best_accuracy</span><span class="p">,</span> <span class="n">best_mapping</span>

<span class="c1"># Mengambil dan Memproses Data Iris dari MySQL</span>

<span class="c1"># Info koneksi MySQL</span>
<span class="n">DB_HOST</span> <span class="o">=</span> <span class="s2">&quot;mysql-34425cbd-irismysqlaldi.h.aivencloud.com&quot;</span>
<span class="n">DB_PORT</span> <span class="o">=</span> <span class="mi">22476</span>
<span class="n">DB_NAME</span> <span class="o">=</span> <span class="s2">&quot;iris_baru&quot;</span>
<span class="n">DB_USER</span> <span class="o">=</span> <span class="s2">&quot;avnadmin&quot;</span>
<span class="n">DB_PASS</span> <span class="o">=</span> <span class="s2">&quot;AVNS_QsQ7Yf7zzcmrk83yFgg&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">### Mengambil dan Memproses Data Iris dari MySQL ###&quot;</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">engine</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mysql+pymysql://</span><span class="si">{</span><span class="n">DB_USER</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">DB_PASS</span><span class="si">}</span><span class="s2">@</span><span class="si">{</span><span class="n">DB_HOST</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">DB_PORT</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">DB_NAME</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># Query: ambil semua data dari tabel iris. Tanpa kolom &#39;species&#39;</span>
    <span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;SELECT * FROM iris&quot;</span>
    <span class="n">data_iris</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">engine</span><span class="p">)</span>

    <span class="c1"># Pastikan data tidak kosong</span>
    <span class="k">if</span> <span class="n">data_iris</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Tidak ada data yang diambil dari database. Tabel &#39;iris&#39; mungkin kosong atau query salah.&quot;</span><span class="p">)</span>

    <span class="c1"># Jika kolom &#39;species&#39; tidak ada di data_iris, lewati bagian pemetaan label asli</span>
    <span class="c1"># dan buat pseudo-true-labels.</span>
    <span class="k">if</span> <span class="s1">&#39;species&#39;</span> <span class="ow">in</span> <span class="n">data_iris</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Peringatan: Kolom &#39;species&#39; ditemukan di database. Akan dihapus untuk tujuan klastering.&quot;</span><span class="p">)</span>
        <span class="n">X_iris</span> <span class="o">=</span> <span class="n">data_iris</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">values</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Kolom &#39;species&#39; tidak ditemukan di database. Melanjutkan tanpa label asli.&quot;</span><span class="p">)</span>
        <span class="n">X_iris</span> <span class="o">=</span> <span class="n">data_iris</span><span class="o">.</span><span class="n">values</span>

    <span class="c1"># Buat &quot;Pseudo-True-Labels&quot; berdasarkan pola setiap 50 data</span>
    <span class="c1"># Asumsi: dataset memiliki 150 baris total, 50 untuk setiap klaster</span>
    <span class="n">n_samples_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_iris</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_samples_total</span> <span class="o">&gt;=</span> <span class="mi">150</span><span class="p">:</span>
        <span class="n">true_labels_iris_pseudo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">50</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">50</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
        <span class="c1"># Jika data lebih dari 150, sisanya akan diberi label 2 (sesuaikan jika perlu)</span>
        <span class="k">if</span> <span class="n">n_samples_total</span> <span class="o">&gt;</span> <span class="mi">150</span><span class="p">:</span>
            <span class="n">true_labels_iris_pseudo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">true_labels_iris_pseudo</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_samples_total</span> <span class="o">-</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dibuat pseudo-true-labels dengan </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">true_labels_iris_pseudo</span><span class="p">)</span><span class="si">}</span><span class="s2"> data.&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Jika data kurang dari 150, sesuaikan pseudo-true-labels</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Peringatan: Jumlah data (</span><span class="si">{</span><span class="n">n_samples_total</span><span class="si">}</span><span class="s2">) kurang dari 150. Pseudo-true-labels mungkin tidak akurat.&quot;</span><span class="p">)</span>
        <span class="c1"># Buat label pseudo berdasarkan jumlah data yang ada, dibagi rata ke 3 klaster</span>
        <span class="n">labels_per_cluster</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_samples_total</span> <span class="o">/</span> <span class="n">n_clusters_iris</span><span class="p">))</span>
        <span class="n">true_labels_iris_pseudo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_clusters_iris</span><span class="p">),</span> <span class="n">labels_per_cluster</span><span class="p">)[:</span><span class="n">n_samples_total</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pseudo-true-labels dibuat berdasarkan </span><span class="si">{</span><span class="n">n_samples_total</span><span class="si">}</span><span class="s2"> data yang tersedia.&quot;</span><span class="p">)</span>


    <span class="c1"># Normalisasi pakai MinMaxScaler</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
    <span class="n">X_scaled_iris</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_iris</span><span class="p">)</span>

    <span class="c1"># Konversi kembali ke DataFrame biar tetap readable (opsional, hanya untuk tampilan)</span>
    <span class="n">X_scaled_df_iris</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_scaled_iris</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data_iris</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="s1">&#39;species&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data_iris</span><span class="o">.</span><span class="n">columns</span> <span class="k">else</span> <span class="n">data_iris</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data Iris (fitur yang sudah dinormalisasi - 5 baris pertama):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">X_scaled_df_iris</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah data yang diambil dan digunakan: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_scaled_iris</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Terjadi kesalahan saat mengambil atau memproses data dari MySQL: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pastikan informasi koneksi database Anda benar, database dapat diakses, dan tabel &#39;iris&#39; tidak kosong.&quot;</span><span class="p">)</span>
    <span class="n">exit</span><span class="p">()</span>

<span class="c1"># Eksekusi FCM dengan Data Iris</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">### Eksekusi FCM dengan Data Iris ###&quot;</span><span class="p">)</span>

<span class="c1"># Parameter FCM untuk data Iris</span>
<span class="n">n_clusters_iris</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1"># Kita tahu ada 3 kelompok</span>
<span class="n">n_iterasi_iris</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># Jumlah iterasi maksimum</span>
<span class="n">m_iris</span> <span class="o">=</span> <span class="mf">2.0</span> <span class="c1"># Parameter fuzzifier umum</span>
<span class="n">epsilon_konvergensi</span> <span class="o">=</span> <span class="mf">1e-5</span> <span class="c1"># Ambang batas konvergensi</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah Cluster (c) : </span><span class="si">{</span><span class="n">n_clusters_iris</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah Iterasi Maksimum: </span><span class="si">{</span><span class="n">n_iterasi_iris</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parameter Pembobot (m): </span><span class="si">{</span><span class="n">m_iris</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ambang Batas Konvergensi (epsilon): </span><span class="si">{</span><span class="n">epsilon_konvergensi</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Hanya jalankan FCM jika ada data yang cukup</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_scaled_iris</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tidak ada data yang valid untuk clustering. Menghentikan eksekusi FCM.&quot;</span><span class="p">)</span>
    <span class="n">U_final_iris</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
    <span class="n">V_final_iris</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
    <span class="n">predicted_labels_iris</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span> <span class="c1"># Pastikan ini juga kosong</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">U_final_iris</span><span class="p">,</span> <span class="n">V_final_iris</span><span class="p">,</span> <span class="n">Jm_history</span><span class="p">,</span> <span class="n">akurasi_per_iterasi</span> <span class="o">=</span> <span class="n">fcm</span><span class="p">(</span> <span class="c1"># Tangkap akurasi_per_iterasi</span>
        <span class="n">X_scaled_iris</span><span class="p">,</span>
        <span class="n">n_clusters_iris</span><span class="p">,</span>
        <span class="n">m_iris</span><span class="p">,</span>
        <span class="n">n_iterasi_iris</span><span class="p">,</span>
        <span class="n">epsilon_konvergensi</span><span class="p">,</span>
        <span class="n">true_labels_pseudo</span><span class="o">=</span><span class="n">true_labels_iris_pseudo</span> <span class="c1"># Kirim pseudo-true-labels ke fungsi FCM</span>
    <span class="p">)</span>
    <span class="n">predicted_labels_iris</span> <span class="o">=</span> <span class="n">get_hard_labels</span><span class="p">(</span><span class="n">U_final_iris</span><span class="p">)</span>

<span class="c1"># Hasil Akhir untuk Data Iris</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">### HASIL AKHIR UNTUK DATA IRIS ###&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">U_final_iris</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cluster Tengah Final (V_final):&quot;</span><span class="p">)</span>
    <span class="n">V_final_iris_formatted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">val</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">row</span><span class="p">]</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">V_final_iris</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">V_final_iris_formatted</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Matriks Keanggotaan Final (U_final):&quot;</span><span class="p">)</span>
    <span class="n">U_final_iris_formatted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">val</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">row</span><span class="p">]</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">U_final_iris</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">U_final_iris_formatted</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Cluster Penugasan (berdasarkan keanggotaan tertinggi):&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_scaled_iris</span><span class="p">))):</span>
        <span class="n">data_point</span> <span class="o">=</span> <span class="n">X_scaled_iris</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">cluster_assigned</span> <span class="o">=</span> <span class="n">predicted_labels_iris</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data </span><span class="si">{</span><span class="n">data_point</span><span class="si">}</span><span class="s2"> -&gt; Klaster </span><span class="si">{</span><span class="n">cluster_assigned</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tidak ada hasil FCM karena data tidak valid.&quot;</span><span class="p">)</span>

<span class="c1"># Evaluasi Akurasi Clustering</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">### EVALUASI AKURASI DENGAN PSEUDO-TRUE-LABELS ###&quot;</span><span class="p">)</span>

<span class="c1"># Gunakan true_labels_iris_pseudo yang sudah dibuat</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">true_labels_iris_pseudo</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted_labels_iris</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># Penting: Pastikan panjang true_labels_iris_pseudo dan predicted_labels_iris sama</span>
    <span class="c1"># Jika tidak, sesuaikan salah satunya atau hanya ambil bagian yang sama panjang</span>
    <span class="n">min_len</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">true_labels_iris_pseudo</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted_labels_iris</span><span class="p">))</span>

    <span class="n">accuracy</span><span class="p">,</span> <span class="n">best_mapping_found</span> <span class="o">=</span> <span class="n">hitung_akurasi</span><span class="p">(</span>
        <span class="n">true_labels_iris_pseudo</span><span class="p">[:</span><span class="n">min_len</span><span class="p">],</span>
        <span class="n">predicted_labels_iris</span><span class="p">[:</span><span class="n">min_len</span><span class="p">],</span>
        <span class="n">n_clusters_iris</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi Clustering (setelah optimal mapping dengan pseudo-true-labels): </span><span class="si">{</span><span class="n">accuracy</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">best_mapping_found</span><span class="p">:</span>
        <span class="c1"># Mapping ini sekarang mencocokkan Cluster ID FCM dengan Pseudo-True Label ID (0, 1, 2)</span>
        <span class="n">readable_mapping</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;Klaster </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Pseudo-Label </span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">best_mapping_found</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mapping Klaster ID ke Pseudo-True-Label ID terbaik: </span><span class="si">{</span><span class="n">readable_mapping</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tidak ada mapping yang ditemukan.&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Catatan: Akurasi dihitung dengan mencoba semua permutasi pemetaan antara cluster hasil FCM dan label yang diasumsikan (pseudo-true-labels).&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Distribusi Pseudo-True-Labels (diasumsikan setiap 50 data sama):&quot;</span><span class="p">)</span>
    <span class="n">unique_true</span><span class="p">,</span> <span class="n">counts_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">true_labels_iris_pseudo</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">label_idx</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unique_true</span><span class="p">,</span> <span class="n">counts_true</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pseudo-Label </span><span class="si">{</span><span class="n">label_idx</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> data&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Distribusi Predicted Clusters:&quot;</span><span class="p">)</span>
    <span class="n">unique_pred</span><span class="p">,</span> <span class="n">counts_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">predicted_labels_iris</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">cluster_idx</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unique_pred</span><span class="p">,</span> <span class="n">counts_pred</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Klaster </span><span class="si">{</span><span class="n">cluster_idx</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> data&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tidak dapat menghitung akurasi karena data pseudo-label atau prediksi tidak ada.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>### Mengambil dan Memproses Data Iris dari MySQL ###
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Peringatan: Kolom &#39;species&#39; ditemukan di database. Akan dihapus untuk tujuan klastering.
Dibuat pseudo-true-labels dengan 150 data.

Data Iris (fitur yang sudah dinormalisasi - 5 baris pertama):
         id  sepal_length_cm  sepal_width_cm  petal_length_cm  petal_width_cm
0  0.000000         0.222222        0.625000         0.067797        0.041667
1  0.006711         0.166667        0.416667         0.067797        0.041667
2  0.013423         0.111111        0.500000         0.050847        0.041667
3  0.020134         0.083333        0.458333         0.084746        0.041667
4  0.026846         0.194444        0.666667         0.067797        0.041667

Jumlah data yang diambil dan digunakan: 150

### Eksekusi FCM dengan Data Iris ###

Jumlah Cluster (c) : 3
Jumlah Iterasi Maksimum: 100
Parameter Pembobot (m): 2.0
Ambang Batas Konvergensi (epsilon): 1e-05
Matriks U Awal (U_0):
[[0.44474066 0.69903977 0.53332798 0.03534339 0.47016554 0.52202853
  0.49991654 0.10816666 0.51045126 0.29537838 0.21086509 0.38763574
  0.07770248 0.65196959 0.24345052 0.34868718 0.41940228 0.48850849
  0.61277188 0.31616194 0.39623648 0.28043099 0.70206679 0.18537676
  0.30635641 0.40044444 0.32588681 0.10449191 0.38081554 0.4554495
  0.3589383  0.24188359 0.4120339  0.43259913 0.2145454  0.28681081
  0.46647991 0.13119984 0.34875694 0.39376971 0.24299989 0.08977496
  0.41442685 0.43259046 0.29207231 0.25847555 0.19129449 0.73188935
  0.16560523 0.50007302 0.37525638 0.24678241 0.23398209 0.11356555
  0.20858916 0.43893821 0.33103223 0.52555279 0.2772696  0.44977213
  0.52677772 0.09982972 0.38543744 0.29913285 0.41472642 0.24493813
  0.29024882 0.37085776 0.05625176 0.57385201 0.53735934 0.32343409
  0.48283073 0.55801999 0.04739153 0.43525457 0.40723676 0.15618283
  0.22219837 0.0777789  0.32679469 0.32246459 0.40990872 0.25832549
  0.1429983  0.53890085 0.34782829 0.29634525 0.40385116 0.43931042
  0.43291368 0.28744498 0.69702988 0.40291826 0.36555506 0.51241006
  0.33514405 0.34992742 0.42400395 0.19671805 0.60186574 0.46072752
  0.19252168 0.34021997 0.27187825 0.52400665 0.40188583 0.22926458
  0.455007   0.34353003 0.19274456 0.48866529 0.26317562 0.2900696
  0.40483103 0.46479697 0.38618507 0.35692839 0.31062206 0.2255123
  0.41240625 0.42845448 0.62145239 0.32350872 0.6248879  0.23337673
  0.35571593 0.44504472 0.34488621 0.14056412 0.44107254 0.39552104
  0.09273456 0.45368959 0.20964788 0.32764916 0.23113197 0.17856874
  0.7525732  0.29704427 0.06557641 0.45533264 0.46326244 0.321372
  0.43606904 0.33811869 0.70851058 0.56777968 0.16305557 0.26028472]
 [0.23893578 0.10880875 0.17250272 0.47548727 0.220531   0.11594797
  0.45247928 0.23983633 0.28985397 0.35709661 0.08781889 0.37512382
  0.45166942 0.26167418 0.61740674 0.43064687 0.32615047 0.10191253
  0.24262857 0.14787916 0.37143576 0.31436626 0.20505292 0.31329918
  0.53972379 0.49324507 0.1794894  0.47736296 0.20275896 0.09296634
  0.49572847 0.33904025 0.01906624 0.23040918 0.49105398 0.3876281
  0.05480047 0.69998661 0.22454617 0.1465751  0.16699883 0.41863179
  0.5666048  0.29120268 0.36130981 0.34700218 0.75957345 0.20529975
  0.27744911 0.11282968 0.17782978 0.01082279 0.33816927 0.25876631
  0.35565828 0.2949417  0.32220802 0.3313196  0.19704172 0.11725495
  0.12414295 0.42575294 0.27796634 0.27542668 0.2415032  0.46440587
  0.42579537 0.47455949 0.36629276 0.10121952 0.40456758 0.49354045
  0.45322398 0.31602954 0.28335799 0.41148234 0.30994596 0.73895188
  0.2475092  0.48602787 0.12520127 0.55779022 0.15848708 0.22103447
  0.39920557 0.09605596 0.46238335 0.40138807 0.39036229 0.34690624
  0.52199513 0.23771334 0.00811702 0.21951712 0.09132632 0.16621827
  0.32106891 0.1540385  0.25275129 0.3617126  0.31878643 0.41563234
  0.67633943 0.35414078 0.32752687 0.23377791 0.35949108 0.50326321
  0.35736676 0.11407783 0.51384232 0.38297741 0.55753633 0.38970772
  0.07222122 0.0248044  0.08264164 0.25587879 0.32240668 0.7587946
  0.05690141 0.34181574 0.01705984 0.14897323 0.09732844 0.4251084
  0.19426352 0.45195548 0.35572566 0.40693796 0.32131689 0.5062446
  0.80603356 0.31090056 0.39091304 0.59642019 0.3376181  0.64091961
  0.13348787 0.68349831 0.45943613 0.30678858 0.27486151 0.19151471
  0.48045486 0.60874164 0.08690721 0.03815294 0.50652769 0.26466999]
 [0.31632356 0.19215149 0.2941693  0.48916933 0.30930345 0.3620235
  0.04760418 0.65199701 0.19969477 0.34752501 0.70131601 0.23724044
  0.4706281  0.08635623 0.13914274 0.22066595 0.25444725 0.40957899
  0.14459955 0.5359589  0.23232775 0.40520275 0.09288029 0.50132406
  0.1539198  0.10631049 0.49462379 0.41814513 0.4164255  0.45158416
  0.14533323 0.41907615 0.56889985 0.33699169 0.29440063 0.32556109
  0.47871962 0.16881355 0.42669689 0.45965519 0.59000128 0.49159325
  0.01896835 0.27620686 0.34661788 0.39452227 0.04913205 0.0628109
  0.55694566 0.38709729 0.44691385 0.74239479 0.42784864 0.62766814
  0.43575256 0.26612009 0.34675975 0.14312761 0.52568868 0.43297292
  0.34907933 0.47441734 0.33659622 0.42544047 0.34377038 0.29065599
  0.28395581 0.15458275 0.57745548 0.32492847 0.05807308 0.18302546
  0.06394528 0.12595047 0.66925048 0.15326309 0.28281729 0.10486529
  0.53029243 0.43619324 0.54800403 0.11974519 0.4316042  0.52064004
  0.45779612 0.36504319 0.18978836 0.30226667 0.20578655 0.21378334
  0.04509119 0.47484168 0.2948531  0.37756461 0.54311861 0.32137168
  0.34378704 0.49603408 0.32324476 0.44156935 0.07934782 0.12364014
  0.13113888 0.30563925 0.40059488 0.24221543 0.2386231  0.26747221
  0.18762623 0.54239215 0.29341312 0.1283573  0.17928804 0.32022269
  0.52294775 0.51039863 0.5311733  0.38719281 0.36697125 0.01569311
  0.53069234 0.22972978 0.36148777 0.52751805 0.27778366 0.34151487
  0.45002055 0.1029998  0.29938813 0.45249792 0.23761057 0.09823437
  0.10123188 0.23540986 0.39943908 0.07593065 0.43124992 0.18051165
  0.11393892 0.01945742 0.47498746 0.23787877 0.26187604 0.48711329
  0.0834761  0.05313968 0.20458221 0.39406738 0.33041673 0.47504529]]

--- ITERASI 1 ---
Cluster Pusat (V_1):
[[0.4981765  0.40916945 0.43826386 0.45467304 0.44895816]
 [0.53864461 0.45657147 0.43236404 0.49809051 0.48665858]
 [0.46843683 0.42227322 0.44816643 0.44832376 0.43954167]]

Matriks U (U_1):
[[0.35416179 0.35792727 0.35859567 0.35986951 0.35505201 0.34981873
  0.35956824 0.35688179 0.3621021  0.35897945 0.35204207 0.35925162
  0.36048058 0.36205105 0.34723504 0.34531707 0.35187947 0.35791534
  0.34913655 0.35586519 0.35580315 0.35748736 0.36043677 0.36219736
  0.36275215 0.36355924 0.36273815 0.35884148 0.35980336 0.36576997
  0.36604382 0.35926345 0.35365964 0.35053133 0.3651036  0.36436696
  0.35733314 0.36587363 0.36894407 0.36370303 0.36427715 0.36800033
  0.36902922 0.3686841  0.36212679 0.37154064 0.36077475 0.37024474
  0.36030587 0.3678377  0.27289122 0.26644139 0.26745884 0.35995639
  0.26387054 0.33879342 0.26486215 0.39401931 0.25367298 0.40141504
  0.37129616 0.27794927 0.34190384 0.23947188 0.45881485 0.23406336
  0.31248518 0.3818219  0.30188374 0.39067197 0.26460449 0.22527489
  0.26461684 0.23118261 0.17704392 0.19718988 0.23646663 0.23737289
  0.16538749 0.41978174 0.38432866 0.39003477 0.34338983 0.24521497
  0.31026171 0.23617245 0.21127861 0.28549823 0.28215091 0.35328711
  0.34002614 0.13692264 0.31005831 0.38839951 0.30282116 0.24343676
  0.22608028 0.15222403 0.40061025 0.26259617 0.29228002 0.27412553
  0.27677129 0.25648754 0.27732588 0.28783501 0.33806804 0.27860785
  0.27522278 0.29380642 0.26309711 0.2652279  0.2724958  0.29349285
  0.29588529 0.28200592 0.26090613 0.29687401 0.29564237 0.29657154
  0.28416339 0.29206744 0.29088789 0.26744861 0.28056415 0.27943334
  0.26817976 0.26863864 0.28211592 0.27726436 0.28540343 0.29708329
  0.28665059 0.27155061 0.28710491 0.29300658 0.29518853 0.27830187
  0.28274882 0.28429424 0.29196876 0.28911948 0.29558575 0.29194895
  0.29616739 0.2909224  0.29262749 0.28662786 0.29783621 0.29378798]
 [0.24270061 0.24147791 0.24288148 0.24205985 0.24302758 0.24395965
  0.24056354 0.23808223 0.24500935 0.23970171 0.24199145 0.237187
  0.24085772 0.24863487 0.25463039 0.2629371  0.24358193 0.23334997
  0.24014892 0.23944958 0.22991229 0.23324783 0.24489909 0.21662644
  0.2301257  0.22947709 0.2229921  0.23193167 0.23116668 0.23149603
  0.2298049  0.22060259 0.25256336 0.25591875 0.23315011 0.23212874
  0.23355246 0.23283101 0.23964219 0.22836663 0.23023009 0.25273502
  0.2389816  0.21457173 0.2284552  0.22772757 0.23857831 0.23433005
  0.23593588 0.22937856 0.40534729 0.40525615 0.42926806 0.2943345
  0.44441973 0.30750746 0.43595422 0.23110535 0.45072132 0.24589071
  0.28009172 0.43023642 0.32117726 0.51769517 0.11361034 0.49727357
  0.42560583 0.24955914 0.41854632 0.27611763 0.49237588 0.57154915
  0.49368224 0.56233502 0.64716797 0.6019087  0.52961185 0.53369986
  0.70859606 0.25190159 0.31390293 0.29614415 0.45369982 0.55411138
  0.48768306 0.55993094 0.58936172 0.46882148 0.59973528 0.4045298
  0.43272012 0.76473305 0.48902577 0.29541265 0.51747185 0.63599309
  0.65582526 0.74145764 0.29227741 0.59008965 0.43774402 0.50566716
  0.46382102 0.52421583 0.47272702 0.43578392 0.40059549 0.45890996
  0.47984869 0.42464289 0.50575862 0.50914231 0.48158044 0.4674399
  0.45011777 0.46687554 0.51442073 0.41435843 0.42360143 0.45999452
  0.45500511 0.47470043 0.4335315  0.51356598 0.46631308 0.46208366
  0.51545285 0.51502583 0.4735003  0.46958316 0.45080616 0.41502707
  0.46345877 0.50737368 0.47626864 0.43128764 0.44053652 0.48374808
  0.48892845 0.46109951 0.44543125 0.45071951 0.46257021 0.44378535
  0.43464031 0.45070842 0.46000171 0.4657764  0.43899213 0.46424629]
 [0.4031376  0.40059481 0.39852284 0.39807064 0.40192041 0.40622162
  0.39986822 0.40503598 0.39288855 0.40131884 0.40596648 0.40356137
  0.3986617  0.38931408 0.39813456 0.39174583 0.4045386  0.40873469
  0.41071453 0.40468523 0.41428456 0.40926481 0.39466414 0.4211762
  0.40712216 0.40696367 0.41426975 0.40922685 0.40902997 0.40273401
  0.40415128 0.42013396 0.39377699 0.39354992 0.40174629 0.4035043
  0.4091144  0.40129536 0.39141374 0.40793034 0.40549276 0.37926465
  0.39198918 0.41674417 0.40941801 0.40073179 0.40064694 0.39542521
  0.40375825 0.40278373 0.3217615  0.32830246 0.3032731  0.34570911
  0.29170973 0.35369912 0.29918363 0.37487534 0.2956057  0.35269426
  0.34861212 0.29181431 0.33691889 0.24283295 0.42757481 0.26866307
  0.26190899 0.36861896 0.27956994 0.3332104  0.24301963 0.20317596
  0.24170093 0.20648237 0.17578812 0.20090143 0.23392152 0.22892725
  0.12601644 0.32831667 0.30176842 0.31382108 0.20291034 0.20067364
  0.20205523 0.20389661 0.19935968 0.24568029 0.1181138  0.2421831
  0.22725374 0.09834431 0.20091591 0.31618784 0.17970699 0.12057016
  0.11809446 0.10631833 0.30711234 0.14731419 0.26997596 0.22020731
  0.2594077  0.21929663 0.2499471  0.27638106 0.26133647 0.26248219
  0.24492853 0.28155069 0.23114428 0.22562978 0.24592376 0.23906725
  0.25399694 0.25111854 0.22467314 0.28876756 0.28075621 0.24343393
  0.26083149 0.23323213 0.27558061 0.21898542 0.25312277 0.258483
  0.21636739 0.21633552 0.24438378 0.25315248 0.26379041 0.28788963
  0.24989064 0.22107572 0.23662646 0.27570579 0.26427495 0.23795005
  0.22832274 0.25460625 0.2626     0.26016101 0.24184404 0.2642657
  0.2691923  0.25836918 0.2473708  0.24759574 0.26317166 0.24196573]]

Fungsi Objektif (J_1): 18.03416842

Akurasi Iterasi 1: 75.33%

--- ITERASI 2 ---
Cluster Pusat (V_2):
[[0.44588461 0.37649421 0.44722102 0.39956177 0.38940664]
 [0.61872468 0.51522503 0.40213218 0.60145562 0.59157371]
 [0.37919529 0.35127248 0.48410556 0.33750218 0.32474517]]

Matriks U (U_2):
[[3.0178890e-01 3.1224871e-01 3.1156158e-01 3.1434808e-01 3.0168484e-01
  3.0121698e-01 3.0590641e-01 2.9418203e-01 3.2707787e-01 3.0471921e-01
  2.9444904e-01 2.9491721e-01 3.1077476e-01 3.2934423e-01 3.1510233e-01
  3.3022611e-01 2.9851148e-01 2.8031572e-01 2.8908112e-01 2.9148481e-01
  2.6938173e-01 2.7942118e-01 3.0937813e-01 2.4626861e-01 2.7975692e-01
  2.8680082e-01 2.5932283e-01 2.7375981e-01 2.7363358e-01 2.8948511e-01
  2.8736879e-01 2.4580043e-01 3.1456094e-01 3.1898888e-01 2.9218985e-01
  2.8518019e-01 2.7511291e-01 2.9214061e-01 3.1975471e-01 2.6912745e-01
  2.7510541e-01 3.6713613e-01 3.1327429e-01 2.4371068e-01 2.7131629e-01
  2.9331658e-01 2.9102388e-01 3.0206120e-01 2.8304218e-01 2.7953569e-01
  2.4879685e-01 2.7887181e-01 1.9012181e-01 4.9437661e-01 1.8761500e-01
  5.2867523e-01 2.0041379e-01 5.0619193e-01 2.2422538e-01 6.0568070e-01
  4.6909040e-01 3.5712909e-01 4.6586375e-01 1.5551111e-01 8.5714050e-01
  1.5677126e-01 3.1081620e-01 7.0795630e-01 2.1199265e-01 6.2235834e-01
  8.3579370e-02 3.5610605e-01 8.5107290e-02 1.6655124e-01 1.0280457e-01
  5.7751910e-02 6.2987670e-02 3.2297520e-02 1.4946770e-02 7.0496832e-01
  5.4445982e-01 5.7053451e-01 5.0480039e-01 2.0985560e-02 1.8769027e-01
  7.0852980e-02 2.1653780e-02 1.5519779e-01 3.5063318e-01 3.6006087e-01
  3.1583007e-01 7.6726000e-04 2.9275239e-01 5.0383552e-01 2.0418214e-01
  2.4961669e-01 1.2119479e-01 1.2359650e-02 5.3571748e-01 1.4153802e-01
  1.1586489e-01 3.7640480e-02 8.1688760e-02 2.2983630e-02 6.4452990e-02
  1.2920198e-01 2.3665166e-01 9.4844370e-02 6.3314550e-02 1.4934696e-01
  4.0795860e-02 3.3447320e-02 5.9608630e-02 8.0044010e-02 9.7764200e-02
  7.7222110e-02 3.2991310e-02 1.7643919e-01 1.5039643e-01 1.1446442e-01
  9.5636830e-02 7.4653480e-02 1.3644274e-01 3.7442610e-02 8.2908890e-02
  9.5717600e-02 3.8154020e-02 3.9706100e-02 6.8539030e-02 9.0796950e-02
  1.0943155e-01 1.8129659e-01 8.1741280e-02 5.4695380e-02 8.8109820e-02
  1.4098370e-01 1.2189219e-01 6.7828260e-02 6.9398580e-02 9.3911720e-02
  1.1249537e-01 1.0920395e-01 9.5583390e-02 1.1696703e-01 1.3250371e-01
  1.0772736e-01 1.0021823e-01 9.0104630e-02 1.2988352e-01 1.0036948e-01]
 [5.8132680e-02 5.8465820e-02 6.0086380e-02 5.9800950e-02 5.8241840e-02
  6.0313530e-02 5.6802290e-02 5.1268350e-02 6.5328380e-02 5.4019670e-02
  5.4899560e-02 5.0384220e-02 5.5990950e-02 6.9457210e-02 7.3518810e-02
  9.1794590e-02 5.7641050e-02 4.3877880e-02 5.1563540e-02 5.1613300e-02
  3.8573700e-02 4.3950170e-02 6.0107070e-02 2.7668930e-02 4.0556810e-02
  4.0101610e-02 3.2628160e-02 4.0237870e-02 3.9322850e-02 4.2320610e-02
  4.0249520e-02 2.8620840e-02 6.9030510e-02 7.4389200e-02 4.2821500e-02
  4.0943620e-02 4.0261010e-02 4.2181410e-02 5.4145810e-02 3.5519560e-02
  3.8130170e-02 7.9849560e-02 5.2041960e-02 2.5045970e-02 3.6794590e-02
  3.7785320e-02 4.7079020e-02 4.4707490e-02 4.2600350e-02 3.6496860e-02
  5.9768750e-01 5.8447308e-01 7.0111577e-01 2.4453087e-01 7.2633625e-01
  2.9881594e-01 7.0162029e-01 7.7643110e-02 6.7511983e-01 1.5540541e-01
  1.7168840e-01 5.4345968e-01 2.7789341e-01 7.9304881e-01 3.7014990e-02
  7.7302687e-01 5.9815291e-01 1.1659559e-01 6.8455326e-01 1.6895033e-01
  8.8043204e-01 5.6654611e-01 8.7841536e-01 7.8382972e-01 8.6565496e-01
  9.2028655e-01 9.0844150e-01 9.5244369e-01 9.8082655e-01 9.8771980e-02
  2.4517231e-01 1.9145863e-01 3.9517706e-01 9.7079846e-01 7.5572111e-01
  9.0112505e-01 9.6896321e-01 7.7707162e-01 5.8301482e-01 5.2040912e-01
  5.8385455e-01 9.9900074e-01 6.2461772e-01 1.9545547e-01 7.3907778e-01
  6.9402307e-01 8.4910794e-01 9.8392500e-01 1.8019791e-01 8.2039573e-01
  8.1256158e-01 9.4515226e-01 8.6987460e-01 9.6587702e-01 8.9937440e-01
  7.8645404e-01 6.4406178e-01 8.4776412e-01 9.0239089e-01 7.4959543e-01
  9.3786102e-01 9.4984207e-01 9.0697734e-01 8.7960149e-01 8.4754208e-01
  8.7862220e-01 9.5012598e-01 6.9756528e-01 7.4858735e-01 8.2721814e-01
  8.4612681e-01 8.8788813e-01 7.7389081e-01 9.4424871e-01 8.6818887e-01
  8.4603855e-01 9.4332175e-01 9.4085640e-01 8.9327873e-01 8.5544349e-01
  8.2259030e-01 6.8852838e-01 8.7140091e-01 9.1797829e-01 8.6565258e-01
  7.6522095e-01 8.0214206e-01 8.9476704e-01 8.9472450e-01 8.4978985e-01
  8.1774576e-01 8.2368782e-01 8.5255871e-01 8.0944307e-01 7.8211153e-01
  8.2677247e-01 8.4335189e-01 8.5779487e-01 7.8902383e-01 8.4397256e-01]
 [6.4007842e-01 6.2928548e-01 6.2835203e-01 6.2585098e-01 6.4007331e-01
  6.3846949e-01 6.3729130e-01 6.5454962e-01 6.0759375e-01 6.4126112e-01
  6.5065140e-01 6.5469857e-01 6.3323430e-01 6.0119856e-01 6.1137885e-01
  5.7797930e-01 6.4384747e-01 6.7580639e-01 6.5935535e-01 6.5690189e-01
  6.9204457e-01 6.7662865e-01 6.3051481e-01 7.2606246e-01 6.7968627e-01
  6.7309758e-01 7.0804900e-01 6.8600232e-01 6.8704357e-01 6.6819428e-01
  6.7238169e-01 7.2557873e-01 6.1640855e-01 6.0662193e-01 6.6498865e-01
  6.7387619e-01 6.8462608e-01 6.6567798e-01 6.2609948e-01 6.9535299e-01
  6.8676443e-01 5.5301430e-01 6.3468375e-01 7.3124335e-01 6.9188913e-01
  6.6889810e-01 6.6189710e-01 6.5323131e-01 6.7435747e-01 6.8396745e-01
  1.5351566e-01 1.3665511e-01 1.0876241e-01 2.6109252e-01 8.6048760e-02
  1.7250883e-01 9.7965920e-02 4.1616496e-01 1.0065479e-01 2.3891389e-01
  3.5922120e-01 9.9411240e-02 2.5624284e-01 5.1440080e-02 1.0584451e-01
  7.0201870e-02 9.1030890e-02 1.7544812e-01 1.0345409e-01 2.0869133e-01
  3.5988590e-02 7.7347850e-02 3.6477350e-02 4.9619030e-02 3.1540470e-02
  2.1961550e-02 2.8570830e-02 1.5258790e-02 4.2266800e-03 1.9625970e-01
  2.1036787e-01 2.3800685e-01 1.0002254e-01 8.2159900e-03 5.6588620e-02
  2.8021970e-02 9.3830000e-03 6.7730590e-02 6.6352000e-02 1.1953001e-01
  1.0031538e-01 2.3200000e-04 8.2629890e-02 3.0070901e-01 5.6740080e-02
  5.6360240e-02 2.9697270e-02 3.7153500e-03 2.8408461e-01 3.8066250e-02
  7.1573530e-02 1.7207260e-02 4.8436640e-02 1.1139350e-02 3.6172610e-02
  8.4343980e-02 1.1928657e-01 5.7391510e-02 3.4294560e-02 1.0105761e-01
  2.1343110e-02 1.6710610e-02 3.3414030e-02 4.0354490e-02 5.4693720e-02
  4.4155690e-02 1.6882710e-02 1.2599553e-01 1.0101622e-01 5.8317440e-02
  5.8236360e-02 3.7458390e-02 8.9666450e-02 1.8308680e-02 4.8902240e-02
  5.8243850e-02 1.8524230e-02 1.9437490e-02 3.8182240e-02 5.3759560e-02
  6.7978160e-02 1.3017503e-01 4.6857810e-02 2.7326330e-02 4.6237600e-02
  9.3795350e-02 7.5965750e-02 3.7404700e-02 3.5876930e-02 5.6298430e-02
  6.9758860e-02 6.7108240e-02 5.1857900e-02 7.3589910e-02 8.5384760e-02
  6.5500180e-02 5.6429870e-02 5.2100500e-02 8.1092650e-02 5.5657960e-02]]

Fungsi Objektif (J_2): 17.08621318

Akurasi Iterasi 2: 76.67%

--- ITERASI 3 ---
Cluster Pusat (V_3):
[[0.37438635 0.31074886 0.39139143 0.34466025 0.31909873]
 [0.71399635 0.58346772 0.38834654 0.69927418 0.70174577]
 [0.18841567 0.20867397 0.57107523 0.10520299 0.08657902]]

Matriks U (U_3):
[[1.3707780e-02 3.8397170e-02 2.0656010e-02 3.1812110e-02 1.1280360e-02
  4.9721300e-02 1.3717470e-02 5.6590600e-03 7.0243220e-02 1.7178270e-02
  1.7540250e-02 4.7296800e-03 2.7082150e-02 5.3843850e-02 7.1813380e-02
  1.3884448e-01 3.6251180e-02 1.4573800e-03 4.8678220e-02 1.2679210e-02
  4.3241500e-03 7.4169700e-03 1.1038110e-02 3.2926600e-03 1.9682600e-03
  1.8523300e-02 1.1837000e-04 8.7442000e-04 5.3061000e-04 5.6880600e-03
  9.6850400e-03 4.8210300e-03 5.3133980e-02 8.5691980e-02 1.2163070e-02
  4.4010300e-03 1.2213420e-02 1.4994420e-02 6.1133860e-02 1.6255300e-03
  3.1727900e-03 3.8863264e-01 3.6659610e-02 3.5049600e-02 4.5234760e-02
  6.1713340e-02 2.9991040e-02 3.2279710e-02 3.0200190e-02 1.5673030e-02
  2.7551096e-01 3.7622183e-01 1.9496902e-01 8.3080355e-01 2.8147491e-01
  7.8147121e-01 2.4709640e-01 9.4000937e-01 3.4496637e-01 8.9472224e-01
  8.3797468e-01 5.6425556e-01 7.8830556e-01 3.4103082e-01 9.4847380e-01
  2.2309863e-01 5.1782307e-01 9.2140573e-01 3.0061110e-01 9.0811234e-01
  1.0112796e-01 6.1837840e-01 1.1927553e-01 3.9419241e-01 2.8497228e-01
  1.3044207e-01 7.1021600e-02 1.5907340e-02 1.4336540e-01 9.3770377e-01
  8.4825974e-01 8.8317269e-01 7.4473705e-01 3.2294670e-02 3.5099164e-01
  1.0412126e-01 2.3275140e-02 2.2568904e-01 5.6886508e-01 6.0817677e-01
  5.5346750e-01 5.6309880e-02 5.3937065e-01 8.3346613e-01 4.2300682e-01
  4.6508877e-01 3.3293216e-01 9.9160420e-02 8.4338957e-01 3.3403706e-01
  2.3171270e-02 9.2768900e-03 8.1439000e-03 2.5321000e-04 3.8234000e-03
  2.8876040e-02 2.7047907e-01 1.4239590e-02 6.3998400e-03 4.0125530e-02
  1.4243700e-03 5.9227000e-04 2.4122200e-03 2.3344390e-02 1.9733190e-02
  6.9912200e-03 2.8482000e-04 6.3407820e-02 4.2195600e-02 6.4376960e-02
  1.0496860e-02 1.8506760e-02 3.2601200e-02 2.0966000e-03 7.3332200e-03
  1.2648850e-02 2.6626300e-03 3.0165300e-03 3.8808900e-03 1.3030610e-02
  1.7421650e-02 6.8257150e-02 6.7418400e-03 8.9082800e-03 2.5554200e-02
  3.2420950e-02 2.2722090e-02 5.2791900e-03 1.1312960e-02 9.9696200e-03
  1.6239490e-02 1.5752360e-02 2.0641990e-02 1.7993470e-02 2.6273040e-02
  1.5081500e-02 1.9392910e-02 1.0291930e-02 2.7877540e-02 2.1642630e-02]
 [7.4222000e-04 1.6221000e-03 9.8304000e-04 1.4094200e-03 6.3294000e-04
  3.5188500e-03 6.5333000e-04 2.4643000e-04 3.1942200e-03 6.7797000e-04
  1.0143500e-03 1.9590000e-04 1.0602500e-03 2.8438900e-03 6.8181200e-03
  1.9161790e-02 2.4739700e-03 5.6940000e-05 2.9576900e-03 6.9877000e-04
  1.4296000e-04 3.2951000e-04 6.2618000e-04 6.4930000e-05 6.1610000e-05
  4.4567000e-04 3.0200000e-06 3.1530000e-05 1.7500000e-05 1.6332000e-04
  2.4464000e-04 1.1879000e-04 4.6145000e-03 8.7529500e-03 3.4380000e-04
  1.2970000e-04 4.7409000e-04 4.1487000e-04 2.1521700e-03 4.7070000e-05
  1.0628000e-04 1.7839160e-02 1.3701100e-03 7.7202000e-04 1.8716700e-03
  1.3130000e-03 1.5474800e-03 9.9600000e-04 1.3826900e-03 4.3025000e-04
  6.7592302e-01 5.8169781e-01 7.7362302e-01 1.2597924e-01 6.9115145e-01
  1.8851476e-01 7.2157598e-01 1.9198940e-02 6.2263608e-01 7.6990180e-02
  7.7475520e-02 4.0660804e-01 1.6149446e-01 6.3678828e-01 3.8206400e-02
  7.5200132e-01 4.5389249e-01 6.0694350e-02 6.6999341e-01 7.0476900e-02
  8.8699394e-01 3.5794365e-01 8.6943602e-01 5.8385788e-01 6.9597403e-01
  8.5706416e-01 9.2052785e-01 9.8182898e-01 8.4727336e-01 4.4767260e-02
  1.2106084e-01 8.6153420e-02 2.3311742e-01 9.6459954e-01 6.2616464e-01
  8.8346938e-01 9.7369918e-01 7.5390588e-01 4.0669005e-01 3.6207783e-01
  4.1863318e-01 9.3916606e-01 4.3540487e-01 1.0358784e-01 5.5506054e-01
  5.1052810e-01 6.4856995e-01 8.9322396e-01 1.0202523e-01 6.4675607e-01
  9.7080371e-01 9.8947354e-01 9.8993188e-01 9.9970626e-01 9.9536128e-01
  9.6280176e-01 6.9504207e-01 9.8230596e-01 9.9241002e-01 9.4680685e-01
  9.9829782e-01 9.9930876e-01 9.9706514e-01 9.7297948e-01 9.7620695e-01
  9.9140603e-01 9.9966276e-01 9.1313738e-01 9.4488457e-01 9.2612482e-01
  9.8676240e-01 9.7840341e-01 9.5780016e-01 9.9756139e-01 9.9084595e-01
  9.8407231e-01 9.9689984e-01 9.9646434e-01 9.9529141e-01 9.8382987e-01
  9.7798183e-01 9.0593235e-01 9.9173109e-01 9.8956655e-01 9.6992402e-01
  9.5743441e-01 9.7091260e-01 9.9357383e-01 9.8654256e-01 9.8747262e-01
  9.7930464e-01 9.7999623e-01 9.7527558e-01 9.7688014e-01 9.6581876e-01
  9.8095169e-01 9.7650972e-01 9.8725694e-01 9.6421317e-01 9.7368583e-01]
 [9.8555000e-01 9.5998073e-01 9.7836094e-01 9.6677847e-01 9.8808670e-01
  9.4675984e-01 9.8562920e-01 9.9409451e-01 9.2656256e-01 9.8214376e-01
  9.8144539e-01 9.9507443e-01 9.7185760e-01 9.4331227e-01 9.2136850e-01
  8.4199373e-01 9.6127485e-01 9.9848568e-01 9.4836409e-01 9.8662202e-01
  9.9553289e-01 9.9225352e-01 9.8833571e-01 9.9664242e-01 9.9797013e-01
  9.8103103e-01 9.9987861e-01 9.9909405e-01 9.9945189e-01 9.9414862e-01
  9.9007033e-01 9.9506019e-01 9.4225151e-01 9.0555508e-01 9.8749313e-01
  9.9546927e-01 9.8731249e-01 9.8459071e-01 9.3671397e-01 9.9832740e-01
  9.9672093e-01 5.9352821e-01 9.6197028e-01 9.6417838e-01 9.5289357e-01
  9.3697366e-01 9.6846148e-01 9.6672429e-01 9.6841712e-01 9.8389672e-01
  4.8566010e-02 4.2080360e-02 3.1407960e-02 4.3217200e-02 2.7373640e-02
  3.0014030e-02 3.1327620e-02 4.0791690e-02 3.2397550e-02 2.8287580e-02
  8.4549800e-02 2.9136400e-02 5.0199970e-02 2.2180900e-02 1.3319800e-02
  2.4900060e-02 2.8284440e-02 1.7899920e-02 2.9395490e-02 2.1410760e-02
  1.1878110e-02 2.3677950e-02 1.1288450e-02 2.1949700e-02 1.9053690e-02
  1.2493760e-02 8.4505500e-03 2.2636800e-03 9.3612400e-03 1.7528970e-02
  3.0679420e-02 3.0673890e-02 2.2145530e-02 3.1058000e-03 2.2843730e-02
  1.2409360e-02 3.0256800e-03 2.0405080e-02 2.4444870e-02 2.9745390e-02
  2.7899320e-02 4.5240600e-03 2.5224480e-02 6.2946030e-02 2.1932640e-02
  2.4383130e-02 1.8497900e-02 7.6156200e-03 5.4585190e-02 1.9206870e-02
  6.0250200e-03 1.2495700e-03 1.9242200e-03 4.0530000e-05 8.1532000e-04
  8.3222100e-03 3.4478850e-02 3.4544500e-03 1.1901400e-03 1.3067620e-02
  2.7781000e-04 9.8980000e-05 5.2264000e-04 3.6761300e-03 4.0598500e-03
  1.6027500e-03 5.2430000e-05 2.3454800e-02 1.2919830e-02 9.4982200e-03
  2.7407400e-03 3.0898300e-03 9.5986500e-03 3.4201000e-04 1.8208300e-03
  3.2788400e-03 4.3753000e-04 5.1912000e-04 8.2770000e-04 3.1395200e-03
  4.5965200e-03 2.5810510e-02 1.5270700e-03 1.5251700e-03 4.5217800e-03
  1.0144630e-02 6.3653200e-03 1.1469900e-03 2.1444800e-03 2.5577600e-03
  4.4558700e-03 4.2514100e-03 4.0824300e-03 5.1263900e-03 7.9081900e-03
  3.9668100e-03 4.0973700e-03 2.4511200e-03 7.9092800e-03 4.6715400e-03]]

Fungsi Objektif (J_3): 11.07790093

Akurasi Iterasi 3: 81.33%

--- ITERASI 4 ---
Cluster Pusat (V_4):
[[0.48385886 0.349147   0.24717297 0.48182438 0.44567138]
 [0.74774621 0.6108296  0.39896443 0.72616457 0.73724279]
 [0.16356207 0.19700655 0.59303987 0.07967095 0.05991588]]

Matriks U (U_4):
[[1.5728500e-03 8.2865600e-03 3.2962800e-03 6.3300900e-03 1.0929400e-03
  9.9582900e-03 1.7867500e-03 4.6892000e-04 1.8849180e-02 2.9405300e-03
  2.3925000e-03 3.7996000e-04 5.5127100e-03 1.3076210e-02 1.6813030e-02
  4.3827560e-02 6.6036400e-03 6.4190000e-05 1.0002240e-02 1.5679900e-03
  7.5067000e-04 9.4860000e-04 1.1191800e-03 1.4907700e-03 2.9271000e-04
  4.7926600e-03 1.0598000e-04 6.3410000e-05 5.3040000e-05 1.2096400e-03
  2.4831200e-03 1.6075800e-03 1.1147220e-02 2.1643400e-02 2.8813700e-03
  9.9099000e-04 2.3730800e-03 3.7048100e-03 1.6559080e-02 4.6140000e-04
  6.3944000e-04 2.2579455e-01 8.7824800e-03 9.2280800e-03 1.0110250e-02
  1.7341280e-02 5.9868000e-03 8.1462300e-03 6.3907100e-03 4.1875700e-03
  4.2524688e-01 5.9837175e-01 3.8052126e-01 9.8976468e-01 6.8280038e-01
  9.7746521e-01 4.6026253e-01 9.6861853e-01 6.9277554e-01 9.9086415e-01
  9.5469524e-01 8.9328566e-01 9.7814968e-01 8.3137072e-01 9.9108857e-01
  4.8516896e-01 9.0313744e-01 9.9699200e-01 8.6150476e-01 9.9989115e-01
  3.4242388e-01 9.6764931e-01 6.7126423e-01 9.1234404e-01 7.6659510e-01
  4.5648990e-01 3.2122635e-01 7.9327740e-02 7.4583250e-01 9.9817571e-01
  9.9878600e-01 9.9748929e-01 9.9710497e-01 3.9246704e-01 8.5270364e-01
  2.8507695e-01 1.1229266e-01 8.3778997e-01 9.3875078e-01 9.9359067e-01
  9.8744366e-01 4.3994192e-01 9.8586055e-01 9.6778749e-01 9.7004820e-01
  8.9391760e-01 8.9582679e-01 5.8065524e-01 9.6375662e-01 9.1630387e-01
  3.3573420e-02 8.4027600e-02 9.8324800e-03 1.6373900e-03 4.4939800e-03
  3.8763850e-02 7.4180291e-01 2.1553660e-02 1.9955470e-02 4.5879790e-02
  1.5409000e-03 1.9914200e-03 1.5857000e-03 1.2836794e-01 5.0432560e-02
  8.0794300e-03 1.0681000e-04 7.1486300e-02 6.2016250e-02 3.5288559e-01
  1.0000920e-02 7.8361600e-02 4.5420420e-02 9.4936800e-03 6.3981100e-03
  1.4124010e-02 1.1276620e-02 9.7484600e-03 4.4477700e-03 1.8623480e-02
  2.3207750e-02 7.6251110e-02 8.4873800e-03 3.4211630e-02 1.0106164e-01
  3.9072400e-02 2.7319310e-02 6.7125100e-03 3.0002690e-02 9.6639900e-03
  1.7888600e-02 1.7387630e-02 6.0250450e-02 1.9106500e-02 2.9844790e-02
  1.7760820e-02 4.9008100e-02 1.3213520e-02 3.5467820e-02 4.7306250e-02]
 [2.9556000e-04 1.1665500e-03 5.2021000e-04 9.2178000e-04 2.1350000e-04
  2.3922300e-03 2.9763000e-04 7.7690000e-05 2.5459500e-03 4.1748000e-04
  5.0246000e-04 6.0640000e-05 7.4709000e-04 1.9820100e-03 4.8011400e-03
  1.5986390e-02 1.5828400e-03 1.0710000e-05 2.2732300e-03 3.2778000e-04
  1.1558000e-04 1.7794000e-04 2.1537000e-04 1.7820000e-04 4.1610000e-05
  5.3022000e-04 1.4430000e-05 1.0370000e-05 8.1000000e-06 1.5297000e-04
  2.8802000e-04 2.2577000e-04 3.0351300e-03 6.6303800e-03 3.5376000e-04
  1.3160000e-04 4.1038000e-04 4.4988000e-04 2.0308500e-03 6.6380000e-05
  1.0040000e-04 2.1669780e-02 1.1994800e-03 1.2435900e-03 1.9222200e-03
  1.7604400e-03 1.2284100e-03 1.0399600e-03 1.2384700e-03 5.5731000e-04
  5.3224117e-01 3.6889333e-01 5.9192650e-01 7.3413600e-03 3.0155522e-01
  1.8760680e-02 5.1227285e-01 9.8737200e-03 2.8782357e-01 6.4044700e-03
  2.0991000e-02 9.7247150e-02 1.6109130e-02 1.6046946e-01 6.3013300e-03
  4.9355405e-01 8.9239310e-02 2.2183900e-03 1.3127613e-01 7.9960000e-05
  6.4564172e-01 2.9591190e-02 3.2254027e-01 8.3044440e-02 2.2416551e-01
  5.3183993e-01 6.7000058e-01 9.1757268e-01 2.4921512e-01 1.2543600e-03
  9.3352000e-04 1.7802900e-03 2.5658000e-03 6.0375131e-01 1.4003166e-01
  7.0130150e-01 8.8332984e-01 1.5653198e-01 5.6476560e-02 5.7892900e-03
  1.1524550e-02 5.5458709e-01 1.3092650e-02 1.9437990e-02 2.8336770e-02
  9.9346450e-02 9.9844050e-02 4.1305817e-01 2.2907410e-02 8.0156200e-02
  9.6287811e-01 9.1421074e-01 9.8933400e-01 9.9830336e-01 9.9520516e-01
  9.5649194e-01 2.4432180e-01 9.7655564e-01 9.7919243e-01 9.4643976e-01
  9.9835937e-01 9.9793759e-01 9.9830233e-01 8.6812687e-01 9.4666056e-01
  9.9125116e-01 9.9988772e-01 9.1328550e-01 9.3019959e-01 6.3971411e-01
  9.8895786e-01 9.1873773e-01 9.4906376e-01 9.9018027e-01 9.9297429e-01
  9.8437746e-01 9.8830653e-01 9.8981050e-01 9.9528057e-01 9.7970444e-01
  9.7450975e-01 9.0675172e-01 9.9092762e-01 9.6436516e-01 8.9493092e-01
  9.5548620e-01 9.6937620e-01 9.9280234e-01 9.6834644e-01 9.8938304e-01
  9.8016851e-01 9.8072721e-01 9.3668535e-01 9.7862992e-01 9.6618049e-01
  9.8047218e-01 9.4823844e-01 9.8569063e-01 9.6013122e-01 9.4941857e-01]
 [9.9813158e-01 9.9054689e-01 9.9618351e-01 9.9274813e-01 9.9869356e-01
  9.8764948e-01 9.9791562e-01 9.9945339e-01 9.7860487e-01 9.9664199e-01
  9.9710503e-01 9.9955940e-01 9.9374020e-01 9.8494177e-01 9.7838583e-01
  9.4018605e-01 9.9181353e-01 9.9992510e-01 9.8772452e-01 9.9810423e-01
  9.9913375e-01 9.9887345e-01 9.9866545e-01 9.9833104e-01 9.9966568e-01
  9.9467712e-01 9.9987959e-01 9.9992622e-01 9.9993886e-01 9.9863740e-01
  9.9722886e-01 9.9816665e-01 9.8581765e-01 9.7172622e-01 9.9676487e-01
  9.9887741e-01 9.9721653e-01 9.9584531e-01 9.8141006e-01 9.9947222e-01
  9.9926017e-01 7.5253567e-01 9.9001804e-01 9.8952833e-01 9.8796752e-01
  9.8089828e-01 9.9278480e-01 9.9081381e-01 9.9237083e-01 9.9525511e-01
  4.2511950e-02 3.2734920e-02 2.7552240e-02 2.8939600e-03 1.5644400e-02
  3.7741100e-03 2.7464610e-02 2.1507760e-02 1.9400880e-02 2.7313900e-03
  2.4313760e-02 9.4671800e-03 5.7411900e-03 8.1598200e-03 2.6101000e-03
  2.1276990e-02 7.6232500e-03 7.8961000e-04 7.2191200e-03 2.8890000e-05
  1.1934410e-02 2.7595000e-03 6.1955000e-03 4.6115200e-03 9.2393900e-03
  1.1670170e-02 8.7730800e-03 3.0995900e-03 4.9523800e-03 5.6993000e-04
  2.8048000e-04 7.3042000e-04 3.2924000e-04 3.7816500e-03 7.2647000e-03
  1.3621550e-02 4.3775000e-03 5.6780500e-03 4.7726600e-03 6.2004000e-04
  1.0317900e-03 5.4710000e-03 1.0468000e-03 1.2774520e-02 1.6150300e-03
  6.7359400e-03 4.3291600e-03 6.2865900e-03 1.3335980e-02 3.5399300e-03
  3.5484800e-03 1.7616600e-03 8.3351000e-04 5.9250000e-05 3.0086000e-04
  4.7442100e-03 1.3875290e-02 1.8906900e-03 8.5210000e-04 7.6804500e-03
  9.9740000e-05 7.0990000e-05 1.1197000e-04 3.5051900e-03 2.9068800e-03
  6.6941000e-04 5.4700000e-06 1.5228200e-02 7.7841600e-03 7.4002900e-03
  1.0412100e-03 2.9006700e-03 5.5158200e-03 3.2605000e-04 6.2760000e-04
  1.4985300e-03 4.1685000e-04 4.4104000e-04 2.7167000e-04 1.6720700e-03
  2.2825000e-03 1.6997170e-02 5.8500000e-04 1.4232100e-03 4.0074400e-03
  5.4414100e-03 3.3044900e-03 4.8515000e-04 1.6508800e-03 9.5297000e-04
  1.9428900e-03 1.8851700e-03 3.0642000e-03 2.2635900e-03 3.9747200e-03
  1.7670000e-03 2.7534600e-03 1.0958500e-03 4.4009600e-03 3.2751800e-03]]

Fungsi Objektif (J_4): 8.80544426

Akurasi Iterasi 4: 91.33%

--- ITERASI 5 ---
Cluster Pusat (V_5):
[[0.51063598 0.39456276 0.27614957 0.52407637 0.4833439 ]
 [0.79917987 0.64155782 0.41615087 0.75850716 0.78338426]
 [0.16351629 0.19697498 0.59367497 0.07903714 0.05977824]]

Matriks U (U_5):
[[1.2465300e-03 6.1347500e-03 2.4881700e-03 4.6986800e-03 8.6836000e-04
  8.5250300e-03 1.3675400e-03 3.6305000e-04 1.3617440e-02 2.1895800e-03
  1.9644600e-03 2.9165000e-04 4.0287100e-03 9.6157800e-03 1.4782460e-02
  4.0685840e-02 5.5942900e-03 4.9090000e-05 8.5675500e-03 1.2762500e-03
  5.8913000e-04 7.5795000e-04 8.6716000e-04 1.1133600e-03 2.2457000e-04
  3.4038500e-03 8.1420000e-05 4.8820000e-05 4.0620000e-05 8.8360000e-04
  1.7782100e-03 1.2413200e-03 9.6199000e-03 1.9300360e-02 2.0822000e-03
  7.2847000e-04 1.8829600e-03 2.6681200e-03 1.1671720e-02 3.5073000e-04
  4.8766000e-04 1.5870038e-01 6.3666700e-03 7.0519800e-03 8.3583100e-03
  1.1902990e-02 4.9145300e-03 5.8688200e-03 5.2139100e-03 3.1004300e-03
  6.3521725e-01 8.1064913e-01 6.2266241e-01 9.8443343e-01 8.8528185e-01
  9.9176217e-01 7.2166193e-01 9.1981570e-01 8.8626599e-01 9.8812524e-01
  9.1645341e-01 9.7252416e-01 9.7630455e-01 9.6608780e-01 9.9343648e-01
  7.6934802e-01 9.7534381e-01 9.9747354e-01 9.4271234e-01 9.9849118e-01
  6.7012880e-01 9.9593260e-01 9.1426503e-01 9.8759394e-01 9.5105056e-01
  8.0693968e-01 6.8189926e-01 3.0487982e-01 9.6820814e-01 9.9530747e-01
  9.9582620e-01 9.9219416e-01 9.9978711e-01 8.3728936e-01 9.6096337e-01
  6.0172729e-01 4.0138851e-01 9.4796875e-01 9.8678811e-01 9.9691842e-01
  9.9647522e-01 8.7082102e-01 9.9733610e-01 9.4569294e-01 9.9520091e-01
  9.7448163e-01 9.8175813e-01 9.0872485e-01 9.4738415e-01 9.8408498e-01
  3.5170880e-02 3.0652135e-01 8.9915900e-03 2.0727900e-02 4.4224300e-03
  3.6511040e-02 8.3528486e-01 2.5245150e-02 4.7732960e-02 3.9154510e-02
  3.3289300e-03 1.3474000e-02 4.7463000e-04 2.7881566e-01 7.6572300e-02
  6.0018600e-03 8.1022000e-04 6.6318890e-02 5.6527900e-02 5.7061096e-01
  4.1748000e-03 1.7120943e-01 4.0455600e-02 3.8032120e-02 2.3147600e-03
  1.0242970e-02 4.0389100e-02 2.9733870e-02 2.3169700e-03 1.9742080e-02
  1.7890780e-02 7.0875290e-02 4.4398000e-03 8.8987220e-02 2.0105869e-01
  2.7680720e-02 1.8768990e-02 5.3881200e-03 5.4849160e-02 3.4400700e-03
  8.2705700e-03 8.8521300e-03 9.2503520e-02 8.7387400e-03 1.7538060e-02
  9.0859500e-03 6.4498950e-02 8.1049000e-03 2.6697240e-02 6.3221950e-02]
 [2.3317000e-04 9.2142000e-04 4.1248000e-04 7.3041000e-04 1.6806000e-04
  1.8978200e-03 2.3514000e-04 6.1090000e-05 2.0250400e-03 3.2987000e-04
  3.9504000e-04 4.7810000e-05 5.9026000e-04 1.5856700e-03 3.8732000e-03
  1.3188890e-02 1.2524900e-03 8.2000000e-06 1.7864200e-03 2.5635000e-04
  9.0150000e-05 1.3783000e-04 1.6953000e-04 1.3795000e-04 3.2970000e-05
  4.1364000e-04 1.1370000e-05 7.9600000e-06 6.2900000e-06 1.2044000e-04
  2.2572000e-04 1.7363000e-04 2.4440300e-03 5.3790800e-03 2.7729000e-04
  1.0290000e-04 3.1824000e-04 3.5200000e-04 1.6021000e-03 5.1600000e-05
  7.7490000e-05 1.8431510e-02 9.4547000e-04 9.5124000e-04 1.4926400e-03
  1.3652800e-03 9.6398000e-04 8.1389000e-04 9.6657000e-04 4.3255000e-04
  3.2438834e-01 1.6398520e-01 3.5050415e-01 9.5408600e-03 1.0453920e-01
  6.0551700e-03 2.5431559e-01 1.9096550e-02 1.0111170e-01 6.9778900e-03
  3.1396570e-02 2.3147970e-02 1.5109030e-02 3.0703210e-02 3.8207100e-03
  2.1334832e-01 2.1191150e-02 1.5598200e-03 5.2253550e-02 9.3540000e-04
  3.1819613e-01 3.4309200e-03 8.2388710e-02 1.1131540e-02 4.5014120e-02
  1.8429647e-01 3.0947344e-01 6.8940571e-01 3.0331410e-02 2.6654100e-03
  2.7835100e-03 4.6860600e-03 1.7122000e-04 1.6003658e-01 3.5458090e-02
  3.8361374e-01 5.9136633e-01 4.8715170e-02 1.1348590e-02 2.5842600e-03
  3.0248300e-03 1.2586085e-01 2.3116400e-03 2.7580810e-02 4.3151900e-03
  2.2538350e-02 1.6745030e-02 8.8059480e-02 2.8099040e-02 1.4612530e-02
  9.6236051e-01 6.9026524e-01 9.9053620e-01 9.7889517e-01 9.9540025e-01
  9.6045814e-01 1.5167397e-01 9.7335591e-01 9.5108334e-01 9.5625536e-01
  9.9654894e-01 9.8626951e-01 9.9950535e-01 7.1655323e-01 9.2053923e-01
  9.9368684e-01 9.9916707e-01 9.2344734e-01 9.3838193e-01 4.2164880e-01
  9.9554246e-01 8.2491555e-01 9.5612917e-01 9.6125039e-01 9.9754135e-01
  9.8905904e-01 9.5878013e-01 9.6950574e-01 9.9759541e-01 9.7913306e-01
  9.8093674e-01 9.1758561e-01 9.9536378e-01 9.0887144e-01 7.9398028e-01
  9.6959408e-01 9.7967271e-01 9.9437169e-01 9.4328538e-01 9.9633753e-01
  9.9111705e-01 9.9049834e-01 9.0438735e-01 9.9055264e-01 9.8082057e-01
  9.9030036e-01 9.3306751e-01 9.9145455e-01 9.7098893e-01 9.3386939e-01]
 [9.9852030e-01 9.9294383e-01 9.9709936e-01 9.9457092e-01 9.9896358e-01
  9.8957716e-01 9.9839732e-01 9.9957586e-01 9.8435752e-01 9.9748054e-01
  9.9764051e-01 9.9966054e-01 9.9538103e-01 9.8879855e-01 9.8134434e-01
  9.4612527e-01 9.9315322e-01 9.9994271e-01 9.8964603e-01 9.9846740e-01
  9.9932072e-01 9.9910422e-01 9.9896330e-01 9.9874869e-01 9.9974246e-01
  9.9618252e-01 9.9990720e-01 9.9994321e-01 9.9995309e-01 9.9899596e-01
  9.9799607e-01 9.9858505e-01 9.8793607e-01 9.7532056e-01 9.9764051e-01
  9.9916863e-01 9.9779880e-01 9.9697987e-01 9.8672618e-01 9.9959766e-01
  9.9943485e-01 8.2286811e-01 9.9268785e-01 9.9199678e-01 9.9014905e-01
  9.8673173e-01 9.9412150e-01 9.9331729e-01 9.9381953e-01 9.9646702e-01
  4.0394410e-02 2.5365660e-02 2.6833440e-02 6.0257200e-03 1.0178940e-02
  2.1826600e-03 2.4022480e-02 6.1087760e-02 1.2622310e-02 4.8968700e-03
  5.2150010e-02 4.3278700e-03 8.5864100e-03 3.2089900e-03 2.7428000e-03
  1.7303660e-02 3.4650400e-03 9.6664000e-04 5.0341100e-03 5.7342000e-04
  1.1675060e-02 6.3647000e-04 3.3462600e-03 1.2745200e-03 3.9353200e-03
  8.7638500e-03 8.6273000e-03 5.7144700e-03 1.4604400e-03 2.0271300e-03
  1.3903000e-03 3.1197800e-03 4.1670000e-05 2.6740600e-03 3.5785400e-03
  1.4658960e-02 7.2451500e-03 3.3160800e-03 1.8633000e-03 4.9732000e-04
  4.9994000e-04 3.3181300e-03 3.5226000e-04 2.6726250e-02 4.8390000e-04
  2.9800200e-03 1.4968400e-03 3.2156700e-03 2.4516810e-02 1.3025000e-03
  2.4686100e-03 3.2134100e-03 4.7221000e-04 3.7693000e-04 1.7733000e-04
  3.0308200e-03 1.3041160e-02 1.3989500e-03 1.1837100e-03 4.5901400e-03
  1.2214000e-04 2.5649000e-04 2.0020000e-05 4.6311200e-03 2.8884700e-03
  3.1130000e-04 2.2710000e-05 1.0233780e-02 5.0901700e-03 7.7402400e-03
  2.8274000e-04 3.8750200e-03 3.4152300e-03 7.1749000e-04 1.4388000e-04
  6.9799000e-04 8.3077000e-04 7.6040000e-04 8.7620000e-05 1.1248600e-03
  1.1724800e-03 1.1539100e-02 1.9642000e-04 2.1413400e-03 4.9610300e-03
  2.7251900e-03 1.5583000e-03 2.4019000e-04 1.8654600e-03 2.2240000e-04
  6.1238000e-04 6.4952000e-04 3.1091300e-03 7.0862000e-04 1.6413700e-03
  6.1369000e-04 2.4335400e-03 4.4056000e-04 2.3138300e-03 2.9086500e-03]]

Fungsi Objektif (J_5): 8.06272842

Akurasi Iterasi 5: 97.33%

--- ITERASI 6 ---
Cluster Pusat (V_6):
[[0.51235516 0.42446375 0.29782413 0.54307192 0.5018041 ]
 [0.82795637 0.65487601 0.42186819 0.7738743  0.80550108]
 [0.16381494 0.19659573 0.59257413 0.07897176 0.05985025]]

Matriks U (U_6):
[[1.1676400e-03 5.3870300e-03 2.2080600e-03 4.1176900e-03 8.2042000e-04
  8.3410600e-03 1.2311100e-03 3.3298000e-04 1.1717590e-02 1.9153600e-03
  1.8956300e-03 2.6310000e-04 3.4802900e-03 8.3315300e-03 1.4570510e-02
  4.0948130e-02 5.4517300e-03 4.7110000e-05 8.3843600e-03 1.2312400e-03
  5.4602000e-04 7.2636000e-04 7.9385000e-04 9.8038000e-04 1.9839000e-04
  2.8751400e-03 7.1930000e-05 4.6670000e-05 3.6830000e-05 7.4662000e-04
  1.4921700e-03 1.1323000e-03 9.3358000e-03 1.9018780e-02 1.7620800e-03
  6.2037000e-04 1.7513700e-03 2.2569200e-03 9.8064300e-03 3.1040000e-04
  4.3911000e-04 1.3234910e-01 5.4278200e-03 6.3256200e-03 7.8916000e-03
  9.8734400e-03 4.6252200e-03 4.9800100e-03 4.8855200e-03 2.6853200e-03
  7.5068208e-01 8.9228814e-01 7.5467916e-01 9.7865314e-01 9.4333889e-01
  9.9445183e-01 8.3713762e-01 8.8010173e-01 9.4313485e-01 9.8383235e-01
  8.8489969e-01 9.8798505e-01 9.7177585e-01 9.8853179e-01 9.9300565e-01
  8.7873138e-01 9.8759478e-01 9.9652823e-01 9.5833239e-01 9.9572722e-01
  8.1274578e-01 9.9890252e-01 9.6055154e-01 9.9625236e-01 9.8312432e-01
  9.1580444e-01 8.3466612e-01 5.2669038e-01 9.9261851e-01 9.9079686e-01
  9.9043072e-01 9.8433733e-01 9.9960210e-01 9.3433091e-01 9.7624914e-01
  7.5887117e-01 6.3158185e-01 9.6449513e-01 9.9174908e-01 9.9432490e-01
  9.9501458e-01 9.5517990e-01 9.9685203e-01 9.2056525e-01 9.9550597e-01
  9.8406184e-01 9.8951699e-01 9.6296200e-01 9.2587494e-01 9.8897167e-01
  4.1346000e-02 4.6794951e-01 1.1919820e-02 6.3965200e-02 7.2235500e-03
  3.9412830e-02 8.4246009e-01 3.2985950e-02 8.0449380e-02 3.9294730e-02
  9.1663000e-03 3.6302720e-02 7.5443000e-04 3.6363221e-01 9.8298550e-02
  7.1021300e-03 4.3652300e-03 6.7834170e-02 5.5735670e-02 6.3607866e-01
  2.8194900e-03 2.3501710e-01 4.0257870e-02 7.5108320e-02 1.6004300e-03
  1.0348720e-02 7.6348130e-02 5.5994950e-02 2.2161500e-03 2.3885150e-02
  1.6805760e-02 7.1773470e-02 3.4240100e-03 1.3872078e-01 2.6047163e-01
  2.3302930e-02 1.5876060e-02 6.2438300e-03 7.6551320e-02 1.7353200e-03
  4.9082800e-03 5.9305000e-03 1.1080708e-01 5.0701700e-03 1.2615440e-02
  5.9080200e-03 7.2852920e-02 6.4521800e-03 2.3159240e-02 7.3296810e-02]
 [2.1080000e-04 8.1075000e-04 3.6483000e-04 6.4380000e-04 1.5316000e-04
  1.7202600e-03 2.0924000e-04 5.4720000e-05 1.7879800e-03 2.8893000e-04
  3.6024000e-04 4.2470000e-05 5.1656000e-04 1.4064600e-03 3.5280000e-03
  1.2059210e-02 1.1391800e-03 7.6300000e-06 1.6114100e-03 2.3510000e-04
  8.0490000e-05 1.2601000e-04 1.5304000e-04 1.1942000e-04 2.8840000e-05
  3.5605000e-04 9.8700000e-06 7.3800000e-06 5.5800000e-06 1.0331000e-04
  1.9352000e-04 1.5289000e-04 2.2327000e-03 4.9091300e-03 2.3918000e-04
  8.8320000e-05 2.8445000e-04 3.0411000e-04 1.4045400e-03 4.5120000e-05
  6.8650000e-05 1.6764180e-02 8.3003000e-04 8.3340000e-04 1.3338800e-03
  1.1826300e-03 8.6890000e-04 7.1059000e-04 8.6676000e-04 3.7712000e-04
  2.1527233e-01 8.9455000e-02 2.2306423e-01 1.1953070e-02 5.0077600e-02
  3.7705400e-03 1.4462642e-01 2.4785560e-02 4.8705630e-02 8.5810000e-03
  3.8778470e-02 9.5912800e-03 1.6551400e-02 1.0015640e-02 3.6336700e-03
  1.0919578e-01 1.0165670e-02 1.9311200e-03 3.7044490e-02 2.4013700e-03
  1.7808975e-01 8.7634000e-04 3.7325860e-02 3.2362500e-03 1.5031530e-02
  7.8828570e-02 1.5899780e-01 4.6726877e-01 6.8945600e-03 4.6920700e-03
  5.8761200e-03 8.5605900e-03 3.0069000e-04 6.4042950e-02 2.0898560e-02
  2.2887578e-01 3.6159157e-01 3.2564990e-02 6.7571500e-03 4.5414800e-03
  4.0972400e-03 4.3092410e-02 2.6181800e-03 3.6791810e-02 3.9051000e-03
  1.3527080e-02 9.3363700e-03 3.5164140e-02 3.6132210e-02 9.8359200e-03
  9.5631994e-01 5.2833703e-01 9.8760194e-01 9.3522399e-01 9.9255564e-01
  9.5795217e-01 1.4263718e-01 9.6559341e-01 9.1800728e-01 9.5694065e-01
  9.9058702e-01 9.6318443e-01 9.9922141e-01 6.3112384e-01 8.9857615e-01
  9.9260836e-01 9.9554492e-01 9.2346050e-01 9.4002631e-01 3.5578249e-01
  9.9702848e-01 7.6044257e-01 9.5692990e-01 9.2378624e-01 9.9832123e-01
  9.8909499e-01 9.2241485e-01 9.4288318e-01 9.9771622e-01 9.7503644e-01
  9.8229599e-01 9.1843256e-01 9.9645135e-01 8.5857546e-01 7.3396721e-01
  9.7477973e-01 9.8302352e-01 9.9353284e-01 9.2127716e-01 9.9817343e-01
  9.9478885e-01 9.9370923e-01 8.8589760e-01 9.9458765e-01 9.8638884e-01
  9.9375758e-01 9.2473320e-01 9.9325571e-01 9.7513332e-01 9.2377625e-01]
 [9.9862157e-01 9.9380222e-01 9.9742711e-01 9.9523851e-01 9.9902642e-01
  9.8993868e-01 9.9855965e-01 9.9961230e-01 9.8649443e-01 9.9779572e-01
  9.9774413e-01 9.9969442e-01 9.9600316e-01 9.9026201e-01 9.8190149e-01
  9.4699265e-01 9.9340909e-01 9.9994526e-01 9.9000423e-01 9.9853366e-01
  9.9937349e-01 9.9914763e-01 9.9905310e-01 9.9890020e-01 9.9977277e-01
  9.9676881e-01 9.9991819e-01 9.9994595e-01 9.9995759e-01 9.9915007e-01
  9.9831431e-01 9.9871481e-01 9.8843150e-01 9.7607209e-01 9.9799874e-01
  9.9929131e-01 9.9796419e-01 9.9743897e-01 9.8878903e-01 9.9964448e-01
  9.9949224e-01 8.5088672e-01 9.9374216e-01 9.9284098e-01 9.9077453e-01
  9.8894394e-01 9.9450587e-01 9.9430940e-01 9.9424772e-01 9.9693756e-01
  3.4045580e-02 1.8256860e-02 2.2256610e-02 9.3937900e-03 6.5835100e-03
  1.7776400e-03 1.8235960e-02 9.5112710e-02 8.1595300e-03 7.5866400e-03
  7.6321840e-02 2.4236700e-03 1.1672750e-02 1.4525700e-03 3.3606800e-03
  1.2072840e-02 2.2395500e-03 1.5406500e-03 4.6231100e-03 1.8714000e-03
  9.1644700e-03 2.2114000e-04 2.1226100e-03 5.1139000e-04 1.8441600e-03
  5.3669900e-03 6.3360700e-03 6.0408600e-03 4.8693000e-04 4.5110600e-03
  3.6931500e-03 7.1020800e-03 9.7210000e-05 1.6261400e-03 2.8523000e-03
  1.2253050e-02 6.8265800e-03 2.9398800e-03 1.4937700e-03 1.1336200e-03
  8.8818000e-04 1.7276900e-03 5.2979000e-04 4.2642930e-02 5.8893000e-04
  2.4110800e-03 1.1466300e-03 1.8738600e-03 3.7992840e-02 1.1924100e-03
  2.3340600e-03 3.7134600e-03 4.7824000e-04 8.1081000e-04 2.2081000e-04
  2.6350000e-03 1.4902730e-02 1.4206400e-03 1.5433500e-03 3.7646300e-03
  2.4668000e-04 5.1285000e-04 2.4160000e-05 5.2439500e-03 3.1253100e-03
  2.8951000e-04 8.9850000e-05 8.7053300e-03 4.2380200e-03 8.1388500e-03
  1.5203000e-04 4.5403300e-03 2.8122300e-03 1.1054300e-03 7.8350000e-05
  5.5629000e-04 1.2370200e-03 1.1218700e-03 6.7630000e-05 1.0784100e-03
  8.9824000e-04 9.7939700e-03 1.2464000e-04 2.7037700e-03 5.5611600e-03
  1.9173400e-03 1.1004300e-03 2.2333000e-04 2.1715200e-03 9.1250000e-05
  3.0287000e-04 3.6027000e-04 3.2953300e-03 3.4219000e-04 9.9571000e-04
  3.3440000e-04 2.4138700e-03 2.9211000e-04 1.7074400e-03 2.9269400e-03]]

Fungsi Objektif (J_6): 7.90647301

Akurasi Iterasi 6: 98.67%

--- ITERASI 7 ---
Cluster Pusat (V_7):
[[0.51240259 0.43717201 0.30720848 0.55057279 0.50974643]
 [0.83706428 0.66028909 0.42471893 0.7790546  0.81289049]
 [0.16398716 0.19640048 0.59198593 0.07898586 0.05991789]]

Matriks U (U_7):
[[1.1388500e-03 5.1022800e-03 2.1013300e-03 3.8966400e-03 8.0365000e-04
  8.2783100e-03 1.1791400e-03 3.2178000e-04 1.1006170e-02 1.8102600e-03
  1.8724900e-03 2.5223000e-04 3.2721200e-03 7.8491500e-03 1.4503370e-02
  4.1095300e-02 5.4035700e-03 4.6590000e-05 8.3181400e-03 1.2164900e-03
  5.2936000e-04 7.1556000e-04 7.6670000e-04 9.2742000e-04 1.8798000e-04
  2.6739800e-03 6.8050000e-05 4.6030000e-05 3.5400000e-05 6.9372000e-04
  1.3828600e-03 1.0888700e-03 9.2302600e-03 1.8918170e-02 1.6397000e-03
  5.7856000e-04 1.7002600e-03 2.1000800e-03 9.1139700e-03 2.9446000e-04
  4.2022000e-04 1.2266503e-01 5.0738000e-03 6.0362600e-03 7.7006100e-03
  9.1208400e-03 4.5109000e-03 4.6437600e-03 4.7545500e-03 2.5244000e-03
  7.8861936e-01 9.1502562e-01 7.9723939e-01 9.7517271e-01 9.5760403e-01
  9.9480230e-01 8.7083307e-01 8.6012738e-01 9.5722026e-01 9.8106145e-01
  8.6917298e-01 9.9123940e-01 9.6868296e-01 9.9278816e-01 9.9221887e-01
  9.0823610e-01 9.9007881e-01 9.9564519e-01 9.6155861e-01 9.9374005e-01
  8.5330676e-01 9.9931051e-01 9.7042832e-01 9.9763016e-01 9.8930407e-01
  9.4151953e-01 8.7604351e-01 6.1478173e-01 9.9625509e-01 9.8780408e-01
  9.8692906e-01 9.7949416e-01 9.9932124e-01 9.5412444e-01 9.7912407e-01
  8.0619415e-01 7.1174838e-01 9.6755394e-01 9.9234708e-01 9.9240924e-01
  9.9365512e-01 9.7117017e-01 9.9607089e-01 9.0739217e-01 9.9485095e-01
  9.8553744e-01 9.9054762e-01 9.7348822e-01 9.1438033e-01 9.8922426e-01
  4.5003200e-02 5.2906641e-01 1.3717320e-02 9.2869810e-02 9.1742500e-03
  4.1251210e-02 8.4157377e-01 3.7271780e-02 9.8649120e-02 3.9875250e-02
  1.3277590e-02 5.1711570e-02 1.0415900e-03 3.9746583e-01 1.1004271e-01
  8.0626000e-03 7.4483200e-03 6.9032560e-02 5.6305760e-02 6.5537482e-01
  2.5089100e-03 2.6375382e-01 4.0875260e-02 9.6695560e-02 1.4847400e-03
  1.0719170e-02 9.6981070e-02 7.1507480e-02 2.5622600e-03 2.6394990e-02
  1.6907980e-02 7.2714850e-02 3.4745600e-03 1.6357365e-01 2.8578421e-01
  2.2122540e-02 1.5359270e-02 7.1840600e-03 8.8408640e-02 1.3664400e-03
  4.1001800e-03 5.2383000e-03 1.2081645e-01 4.1396500e-03 1.1311460e-02
  5.2092500e-03 7.8384540e-02 6.3561900e-03 2.2577510e-02 7.9410200e-02]
 [2.0463000e-04 7.7573000e-04 3.4989000e-04 6.1624000e-04 1.4928000e-04
  1.6720800e-03 2.0133000e-04 5.2890000e-05 1.7115500e-03 2.7585000e-04
  3.5134000e-04 4.0870000e-05 4.9277000e-04 1.3486500e-03 3.4336100e-03
  1.1743880e-02 1.1090000e-03 7.5300000e-06 1.5637700e-03 2.2989000e-04
  7.7740000e-05 1.2308000e-04 1.4830000e-04 1.1350000e-04 2.7510000e-05
  3.3714000e-04 9.3800000e-06 7.2700000e-06 5.3800000e-06 9.7540000e-05
  1.8274000e-04 1.4667000e-04 2.1747800e-03 4.7789600e-03 2.2657000e-04
  8.3470000e-05 2.7478000e-04 2.8832000e-04 1.3397200e-03 4.3060000e-05
  6.5970000e-05 1.6211810e-02 7.9233000e-04 7.9724000e-04 1.2880600e-03
  1.1229000e-03 8.4181000e-04 6.7684000e-04 8.3801000e-04 3.5934000e-04
  1.8062356e-01 6.9504330e-02 1.8294333e-01 1.3446840e-02 3.7040120e-02
  3.4316100e-03 1.1350373e-01 2.7497450e-02 3.6137670e-02 9.6840300e-03
  4.2355470e-02 6.8531500e-03 1.7808440e-02 6.2118900e-03 3.8802700e-03
  8.1805220e-02 7.9832100e-03 2.3323200e-03 3.3833320e-02 3.3932700e-03
  1.3873805e-01 5.3922000e-04 2.7806690e-02 2.0163700e-03 9.4106800e-03
  5.4342690e-02 1.1866538e-01 3.7959440e-01 3.4681400e-03 5.9773900e-03
  7.7806800e-03 1.0823140e-02 5.0086000e-04 4.4578930e-02 1.8138280e-02
  1.8290511e-01 2.8216940e-01 2.9514640e-02 6.1523200e-03 5.9633500e-03
  5.1261200e-03 2.7567300e-02 3.2136400e-03 4.1433650e-02 4.4133600e-03
  1.2084430e-02 8.3170600e-03 2.5006210e-02 4.0327620e-02 9.4986600e-03
  9.5268042e-01 4.6713731e-01 9.8579270e-01 9.0611844e-01 9.9057581e-01
  9.5623462e-01 1.4241843e-01 9.6128604e-01 8.9964305e-01 9.5662293e-01
  9.8640955e-01 9.4764072e-01 9.9892875e-01 5.9704079e-01 8.8668033e-01
  9.9164042e-01 9.9241692e-01 9.2278280e-01 9.3970377e-01 3.3624753e-01
  9.9736830e-01 7.3141179e-01 9.5648679e-01 9.0200856e-01 9.9844955e-01
  9.8875963e-01 9.0158198e-01 9.2718825e-01 9.9736596e-01 9.7252281e-01
  9.8226146e-01 9.1808298e-01 9.9640840e-01 8.3347099e-01 7.0838231e-01
  9.7618941e-01 9.8365237e-01 9.9258060e-01 9.0924421e-01 9.9856759e-01
  9.9566509e-01 9.9446734e-01 8.7573008e-01 9.9560136e-01 9.8785649e-01
  9.9451628e-01 9.1913211e-01 9.9337609e-01 9.7586300e-01 9.1757386e-01]
 [9.9865651e-01 9.9412199e-01 9.9754878e-01 9.9548712e-01 9.9904707e-01
  9.9004960e-01 9.9861953e-01 9.9962533e-01 9.8728228e-01 9.9791388e-01
  9.9777616e-01 9.9970690e-01 9.9623511e-01 9.9080220e-01 9.8206302e-01
  9.4716082e-01 9.9348744e-01 9.9994589e-01 9.9011810e-01 9.9855362e-01
  9.9939290e-01 9.9916135e-01 9.9908500e-01 9.9895908e-01 9.9978451e-01
  9.9698888e-01 9.9992257e-01 9.9994670e-01 9.9995922e-01 9.9920873e-01
  9.9843440e-01 9.9876446e-01 9.8859496e-01 9.7630287e-01 9.9813373e-01
  9.9933797e-01 9.9802495e-01 9.9761160e-01 9.8954630e-01 9.9966248e-01
  9.9951382e-01 8.6112316e-01 9.9413387e-01 9.9316650e-01 9.9101133e-01
  9.8975626e-01 9.9464730e-01 9.9467940e-01 9.9440744e-01 9.9711626e-01
  3.0757080e-02 1.5470050e-02 1.9817280e-02 1.1380450e-02 5.3558500e-03
  1.7660900e-03 1.5663200e-02 1.1237517e-01 6.6420800e-03 9.2545300e-03
  8.8471550e-02 1.9074600e-03 1.3508600e-02 9.9995000e-04 3.9008600e-03
  9.9586800e-03 1.9379900e-03 2.0224900e-03 4.6080700e-03 2.8666800e-03
  7.9551900e-03 1.5027000e-04 1.7649900e-03 3.5347000e-04 1.2852400e-03
  4.1377800e-03 5.2911100e-03 5.6238700e-03 2.7678000e-04 6.2185300e-03
  5.2902600e-03 9.6827000e-03 1.7790000e-04 1.2966300e-03 2.7376500e-03
  1.0900740e-02 6.0822300e-03 2.9314200e-03 1.5006000e-03 1.6274100e-03
  1.2187500e-03 1.2625300e-03 7.1546000e-04 5.1174180e-02 7.3570000e-04
  2.3781300e-03 1.1353200e-03 1.5055600e-03 4.5292060e-02 1.2770800e-03
  2.3163800e-03 3.7962800e-03 4.8999000e-04 1.0117400e-03 2.4994000e-04
  2.5141700e-03 1.6007800e-02 1.4421800e-03 1.7078300e-03 3.5018200e-03
  3.1285000e-04 6.4771000e-04 2.9660000e-05 5.4933800e-03 3.2769500e-03
  2.9697000e-04 1.3476000e-04 8.1846400e-03 3.9904700e-03 8.3776500e-03
  1.2280000e-04 4.8343900e-03 2.6379600e-03 1.2958800e-03 6.5710000e-05
  5.2120000e-04 1.4369500e-03 1.3042600e-03 7.1780000e-05 1.0822100e-03
  8.3056000e-04 9.2021700e-03 1.1704000e-04 2.9553600e-03 5.8334800e-03
  1.6880600e-03 9.8836000e-04 2.3534000e-04 2.3471500e-03 6.5970000e-05
  2.3473000e-04 2.9435000e-04 3.4534800e-03 2.5899000e-04 8.3205000e-04
  2.7447000e-04 2.4833400e-03 2.6772000e-04 1.5594900e-03 3.0159400e-03]]

Fungsi Objektif (J_7): 7.88712709

Akurasi Iterasi 7: 98.00%

--- ITERASI 8 ---
Cluster Pusat (V_8):
[[0.51272026 0.44137269 0.31029109 0.55316187 0.51258096]
 [0.8394212  0.66248019 0.42609549 0.78067913 0.81522418]
 [0.16407088 0.19632528 0.59173156 0.07901254 0.05996434]]

Matriks U (U_8):
[[1.1287200e-03 5.0010600e-03 2.0637000e-03 3.8187600e-03 7.9800000e-04
  8.2495200e-03 1.1608500e-03 3.1788000e-04 1.0760040e-02 1.7729400e-03
  1.8639500e-03 2.4843000e-04 3.1989500e-03 7.6831500e-03 1.4468740e-02
  4.1108210e-02 5.3836400e-03 4.6450000e-05 8.2864300e-03 1.2113800e-03
  5.2308000e-04 7.1169000e-04 7.5759000e-04 9.0735000e-04 1.8416000e-04
  2.6024300e-03 6.6540000e-05 4.5830000e-05 3.4880000e-05 6.7485000e-04
  1.3440400e-03 1.0721600e-03 9.1896900e-03 1.8869970e-02 1.5964400e-03
  5.6358000e-04 1.6812500e-03 2.0448100e-03 8.8775600e-03 2.8860000e-04
  4.1338000e-04 1.1944006e-01 4.9519500e-03 5.9291600e-03 7.6268400e-03
  8.8614600e-03 4.4688800e-03 4.5273200e-03 4.7058200e-03 2.4671900e-03
  7.9944106e-01 9.2117957e-01 8.0935890e-01 9.7379374e-01 9.6132794e-01
  9.9480461e-01 8.8017753e-01 8.5280083e-01 9.6088814e-01 9.7994107e-01
  8.6351410e-01 9.9202466e-01 9.6741788e-01 9.9379618e-01 9.9181621e-01
  9.1619487e-01 9.9068015e-01 9.9523423e-01 9.6236690e-01 9.9291150e-01
  8.6476196e-01 9.9938551e-01 9.7302177e-01 9.9793406e-01 9.9079230e-01
  9.4822021e-01 8.8740619e-01 6.4194534e-01 9.9706399e-01 9.8659507e-01
  9.8557073e-01 9.7763755e-01 9.9918533e-01 9.5936988e-01 9.7987306e-01
  8.1984839e-01 7.3543829e-01 9.6834627e-01 9.9244367e-01 9.9168341e-01
  9.9313191e-01 9.7521142e-01 9.9575241e-01 9.0274074e-01 9.9458702e-01
  9.8587533e-01 9.9078428e-01 9.7623443e-01 9.1031886e-01 9.8923685e-01
  4.6271390e-02 5.4991570e-01 1.4269800e-02 1.0449525e-01 9.9164900e-03
  4.1752620e-02 8.4162047e-01 3.8702360e-02 1.0576815e-01 3.9918910e-02
  1.4861460e-02 5.8198930e-02 1.1462900e-03 4.1032095e-01 1.1490857e-01
  8.4338200e-03 8.7974200e-03 6.9234510e-02 5.6553740e-02 6.6251915e-01
  2.3961000e-03 2.7511847e-01 4.1084950e-02 1.0566961e-01 1.4427000e-03
  1.0808100e-02 1.0556849e-01 7.7977150e-02 2.7860300e-03 2.7312550e-02
  1.6988930e-02 7.2859660e-02 3.6033800e-03 1.7350029e-01 2.9582007e-01
  2.1735140e-02 1.5279380e-02 7.6596900e-03 9.3503710e-02 1.2716300e-03
  3.8944800e-03 5.0606300e-03 1.2556761e-01 3.8850700e-03 1.0953630e-02
  5.0681400e-03 8.1240570e-02 6.4669700e-03 2.2562040e-02 8.2382700e-02]
 [2.0309000e-04 7.6497000e-04 3.4539000e-04 6.0774000e-04 1.4841000e-04
  1.6602600e-03 1.9903000e-04 5.2410000e-05 1.6875200e-03 2.7180000e-04
  3.4937000e-04 4.0410000e-05 4.8529000e-04 1.3305500e-03 3.4105300e-03
  1.1666130e-02 1.1017900e-03 7.5200000e-06 1.5518500e-03 2.2883000e-04
  7.6980000e-05 1.2245000e-04 1.4704000e-04 1.1159000e-04 2.7090000e-05
  3.3100000e-04 9.2100000e-06 7.2600000e-06 5.3200000e-06 9.5640000e-05
  1.7918000e-04 1.4479000e-04 2.1603800e-03 4.7463300e-03 2.2245000e-04
  8.1880000e-05 2.7210000e-04 2.8317000e-04 1.3187800e-03 4.2410000e-05
  6.5160000e-05 1.6030990e-02 7.8023000e-04 7.8615000e-04 1.2752100e-03
  1.1034500e-03 8.3442000e-04 6.6593000e-04 8.3000000e-04 3.5366000e-04
  1.7088330e-01 6.4183150e-02 1.7163319e-01 1.4038700e-02 3.3667480e-02
  3.3985400e-03 1.0496885e-01 2.8458680e-02 3.2900940e-02 1.0132340e-02
  4.3594720e-02 6.1992000e-03 1.8341200e-02 5.3203200e-03 4.0279900e-03
  7.4489160e-02 7.4553300e-03 2.5214100e-03 3.3010180e-02 3.7967300e-03
  1.2768119e-01 4.7736000e-04 2.5315920e-02 1.7493900e-03 8.0699300e-03
  4.8004990e-02 1.0763606e-01 3.5262953e-01 2.7114200e-03 6.4849000e-03
  8.4991600e-03 1.1664570e-02 5.9640000e-04 3.9433450e-02 1.7413200e-02
  1.6971579e-01 2.5877249e-01 2.8712700e-02 6.0372600e-03 6.4918800e-03
  5.5161400e-03 2.3660140e-02 3.4543000e-03 4.2992340e-02 4.6176200e-03
  1.1740330e-02 8.0753700e-03 2.2366910e-02 4.1740160e-02 9.4492100e-03
  9.5142268e-01 4.4627632e-01 9.8524077e-01 8.9442581e-01 9.8982409e-01
  9.5578303e-01 1.4199484e-01 9.5985487e-01 8.9246555e-01 9.5667991e-01
  9.8480442e-01 9.4110259e-01 9.9882240e-01 5.8409621e-01 8.8174885e-01
  9.9126645e-01 9.9105053e-01 9.2277852e-01 9.3953523e-01 3.2902119e-01
  9.9749055e-01 7.1993488e-01 9.5633562e-01 8.9296084e-01 9.9849569e-01
  9.8868448e-01 8.9291657e-01 9.2064743e-01 9.9713827e-01 9.7160470e-01
  9.8220084e-01 9.1815691e-01 9.9627857e-01 8.2344834e-01 6.9823870e-01
  9.7664953e-01 9.8376294e-01 9.9209710e-01 9.0407238e-01 9.9866880e-01
  9.9588842e-01 9.9466274e-01 8.7089598e-01 9.9587830e-01 9.8826048e-01
  9.9467154e-01 9.1622768e-01 9.9326757e-01 9.7591528e-01 9.1454516e-01]
 [9.9866819e-01 9.9423397e-01 9.9759091e-01 9.9557350e-01 9.9905359e-01
  9.9009022e-01 9.9864012e-01 9.9962971e-01 9.8755244e-01 9.9795525e-01
  9.9778668e-01 9.9971116e-01 9.9631576e-01 9.9098630e-01 9.8212073e-01
  9.4722566e-01 9.9351457e-01 9.9994602e-01 9.9016172e-01 9.9855980e-01
  9.9939994e-01 9.9916586e-01 9.9909536e-01 9.9898106e-01 9.9978875e-01
  9.9706658e-01 9.9992425e-01 9.9994691e-01 9.9995980e-01 9.9922951e-01
  9.9847678e-01 9.9878304e-01 9.8864993e-01 9.7638370e-01 9.9818110e-01
  9.9935453e-01 9.9804664e-01 9.9767202e-01 9.8980366e-01 9.9966899e-01
  9.9952146e-01 8.6452896e-01 9.9426782e-01 9.9328469e-01 9.9109794e-01
  9.9003508e-01 9.9469670e-01 9.9480675e-01 9.9446417e-01 9.9717915e-01
  2.9675640e-02 1.4637280e-02 1.9007910e-02 1.2167560e-02 5.0045800e-03
  1.7968500e-03 1.4853620e-02 1.1874048e-01 6.2109200e-03 9.9265900e-03
  9.2891180e-02 1.7761400e-03 1.4240920e-02 8.8349000e-04 4.1558000e-03
  9.3159700e-03 1.8645200e-03 2.2443600e-03 4.6229200e-03 3.2917700e-03
  7.5568500e-03 1.3713000e-04 1.6623100e-03 3.1655000e-04 1.1377800e-03
  3.7748000e-03 4.9577500e-03 5.4251300e-03 2.2459000e-04 6.9200300e-03
  5.9301100e-03 1.0697880e-02 2.1826000e-04 1.1966600e-03 2.7137400e-03
  1.0435810e-02 5.7892200e-03 2.9410300e-03 1.5190700e-03 1.8247100e-03
  1.3519500e-03 1.1284400e-03 7.9329000e-04 5.4266910e-02 7.9537000e-04
  2.3843400e-03 1.1403500e-03 1.3986700e-03 4.7940990e-02 1.3139400e-03
  2.3059300e-03 3.8079800e-03 4.8943000e-04 1.0789400e-03 2.5942000e-04
  2.4643500e-03 1.6384700e-02 1.4427800e-03 1.7663000e-03 3.4011800e-03
  3.3413000e-04 6.9848000e-04 3.1310000e-05 5.5828400e-03 3.3425800e-03
  2.9973000e-04 1.5206000e-04 7.9869700e-03 3.9110300e-03 8.4596600e-03
  1.1335000e-04 4.9466500e-03 2.5794300e-03 1.3695600e-03 6.1620000e-05
  5.0742000e-04 1.5149400e-03 1.3754200e-03 7.5700000e-05 1.0827500e-03
  8.1023000e-04 8.9834400e-03 1.1806000e-04 3.0513700e-03 5.9412300e-03
  1.6153300e-03 9.5769000e-04 2.4321000e-04 2.4239100e-03 5.9570000e-05
  2.1710000e-04 2.7663000e-04 3.5364100e-03 2.3663000e-04 7.8589000e-04
  2.6032000e-04 2.5317500e-03 2.6545000e-04 1.5226800e-03 3.0721400e-03]]

Fungsi Objektif (J_8): 7.88482006

Akurasi Iterasi 8: 98.00%

--- ITERASI 9 ---
Cluster Pusat (V_9):
[[0.51294704 0.44262844 0.31119612 0.55399839 0.51351324]
 [0.84005995 0.66334542 0.42666611 0.7812379  0.81600397]
 [0.16410214 0.19630033 0.59164128 0.07902528 0.05998375]]

Matriks U (U_9):
[[1.1252100e-03 4.9672200e-03 2.0511700e-03 3.7929300e-03 7.9606000e-04
  8.2368900e-03 1.1547400e-03 3.1656000e-04 1.0679670e-02 1.7605000e-03
  1.8606700e-03 2.4716000e-04 3.1747600e-03 7.6291800e-03 1.4452050e-02
  4.1095640e-02 5.3753800e-03 4.6410000e-05 8.2724100e-03 1.2094800e-03
  5.2085000e-04 7.1027000e-04 7.5462000e-04 9.0039000e-04 1.8287000e-04
  2.5786400e-03 6.6010000e-05 4.5760000e-05 3.4710000e-05 6.6859000e-04
  1.3311800e-03 1.0662500e-03 9.1742500e-03 1.8848190e-02 1.5821500e-03
  5.5859000e-04 1.6745600e-03 2.0265800e-03 8.8013100e-03 2.8661000e-04
  4.1107000e-04 1.1842257e-01 4.9124600e-03 5.8924700e-03 7.6003600e-03
  8.7771400e-03 4.4542200e-03 4.4894200e-03 4.6887500e-03 2.4482000e-03
  8.0248363e-01 9.2288761e-01 8.1279878e-01 9.7334646e-01 9.6236014e-01
  9.9478651e-01 8.8283104e-01 8.5046183e-01 9.6189441e-01 9.7957515e-01
  8.6175341e-01 9.9223192e-01 9.6700266e-01 9.9406618e-01 9.9166695e-01
  9.1843068e-01 9.9084637e-01 9.9508758e-01 9.6262706e-01 9.9263723e-01
  8.6816574e-01 9.9940154e-01 9.7379064e-01 9.9801360e-01 9.9119638e-01
  9.5011209e-01 8.9070677e-01 6.5013725e-01 9.9728542e-01 9.8619987e-01
  9.8514600e-01 9.7705530e-01 9.9913937e-01 9.6096949e-01 9.8012211e-01
  8.2394516e-01 7.4250780e-01 9.6862190e-01 9.9247572e-01 9.9147295e-01
  9.9298321e-01 9.7639444e-01 9.9566023e-01 9.0135205e-01 9.9452113e-01
  9.8598991e-01 9.9087363e-01 9.7706292e-01 9.0911566e-01 9.8926795e-01
  4.6646920e-02 5.5715404e-01 1.4403420e-02 1.0858525e-01 1.0158930e-02
  4.1825210e-02 8.4196302e-01 3.9103390e-02 1.0827136e-01 3.9842050e-02
  1.5392450e-02 6.0584140e-02 1.1770800e-03 4.1518190e-01 1.1674317e-01
  8.5565100e-03 9.2902800e-03 6.9173630e-02 5.6589360e-02 6.6537251e-01
  2.3492200e-03 2.7944849e-01 4.1102340e-02 1.0904754e-01 1.4236100e-03
  1.0807860e-02 1.0881962e-01 8.0416200e-02 2.8850200e-03 2.7597920e-02
  1.7001410e-02 7.2790040e-02 3.6705900e-03 1.7720461e-01 2.9965281e-01
  2.1576510e-02 1.5261250e-02 7.8533600e-03 9.5495710e-02 1.2422900e-03
  3.8325500e-03 5.0058800e-03 1.2755415e-01 3.8036400e-03 1.0837810e-02
  5.0360800e-03 8.2459420e-02 6.5359100e-03 2.2587530e-02 8.3623890e-02]
 [2.0264000e-04 7.6146000e-04 3.4394000e-04 6.0497000e-04 1.4817000e-04
  1.6568000e-03 1.9829000e-04 5.2260000e-05 1.6795800e-03 2.7048000e-04
  3.4882000e-04 4.0270000e-05 4.8283000e-04 1.3245800e-03 3.4038600e-03
  1.1643930e-02 1.0997000e-03 7.5300000e-06 1.5483100e-03 2.2853000e-04
  7.6740000e-05 1.2227000e-04 1.4666000e-04 1.1095000e-04 2.6950000e-05
  3.2895000e-04 9.1500000e-06 7.2600000e-06 5.3000000e-06 9.5000000e-05
  1.7799000e-04 1.4418000e-04 2.1560900e-03 4.7366700e-03 2.2108000e-04
  8.1360000e-05 2.7126000e-04 2.8145000e-04 1.3117500e-03 4.2190000e-05
  6.4900000e-05 1.5967880e-02 7.7618000e-04 7.8248000e-04 1.2711100e-03
  1.0969100e-03 8.3208000e-04 6.6228000e-04 8.2745000e-04 3.5176000e-04
  1.6815155e-01 6.2706350e-02 1.6842899e-01 1.4225070e-02 3.2732250e-02
  3.3999600e-03 1.0254806e-01 2.8745420e-02 3.2012230e-02 1.0274410e-02
  4.3950160e-02 6.0255300e-03 1.8511310e-02 5.0815300e-03 4.0835500e-03
  7.2435900e-02 7.3080200e-03 2.5883600e-03 3.2744300e-02 3.9275700e-03
  1.2439768e-01 4.6387000e-04 2.4577510e-02 1.6793600e-03 7.7060400e-03
  4.6217110e-02 1.0443421e-01 3.4450258e-01 2.5045900e-03 6.6463900e-03
  8.7173200e-03 1.1919320e-02 6.2834000e-04 3.7865120e-02 1.7172520e-02
  1.6576093e-01 2.5179492e-01 2.8434910e-02 5.9989300e-03 6.6411900e-03
  5.6239000e-03 2.2517230e-02 3.5222300e-03 4.3419330e-02 4.6660500e-03
  1.1624050e-02 7.9855800e-03 2.1571060e-02 4.2121420e-02 9.4085200e-03
  9.5105249e-01 4.3903527e-01 9.8510894e-01 8.9031314e-01 9.8957878e-01
  9.5573116e-01 1.4154672e-01 9.5945609e-01 8.8994191e-01 9.5679572e-01
  9.8426670e-01 9.3869905e-01 9.9879120e-01 5.7920317e-01 8.7988806e-01
  9.9114292e-01 9.9055153e-01 9.2291489e-01 9.3952790e-01 3.2614410e-01
  9.9754086e-01 7.1556239e-01 9.5633984e-01 8.8955527e-01 9.9851629e-01
  9.8869041e-01 8.8963591e-01 9.1818142e-01 9.9703739e-01 9.7131984e-01
  9.8219550e-01 9.1830852e-01 9.9621027e-01 8.1970780e-01 6.9436495e-01
  9.7683351e-01 9.8379044e-01 9.9189987e-01 9.0204926e-01 9.9870009e-01
  9.9595567e-01 9.9472295e-01 8.6887351e-01 9.9596672e-01 9.8839094e-01
  9.9470743e-01 9.1498616e-01 9.9319813e-01 9.7589979e-01 9.1327791e-01]
 [9.9867216e-01 9.9427132e-01 9.9760489e-01 9.9560210e-01 9.9905577e-01
  9.9010632e-01 9.9864696e-01 9.9963118e-01 9.8764076e-01 9.9796902e-01
  9.9779051e-01 9.9971257e-01 9.9634241e-01 9.9104624e-01 9.8214409e-01
  9.4726043e-01 9.9352493e-01 9.9994606e-01 9.9017927e-01 9.9856199e-01
  9.9940242e-01 9.9916746e-01 9.9909872e-01 9.9898866e-01 9.9979018e-01
  9.9709241e-01 9.9992484e-01 9.9994698e-01 9.9995999e-01 9.9923641e-01
  9.9849083e-01 9.9878957e-01 9.8866966e-01 9.7641514e-01 9.9819677e-01
  9.9936005e-01 9.9805418e-01 9.9769197e-01 9.8988694e-01 9.9967120e-01
  9.9952403e-01 8.6560954e-01 9.9431136e-01 9.9332505e-01 9.9112853e-01
  9.9012594e-01 9.9471370e-01 9.9484830e-01 9.9448380e-01 9.9720004e-01
  2.9364820e-02 1.4406050e-02 1.8772230e-02 1.2428470e-02 4.9076100e-03
  1.8135300e-03 1.4620900e-02 1.2079275e-01 6.0933600e-03 1.0150450e-02
  9.4296430e-02 1.7425600e-03 1.4486030e-02 8.5228000e-04 4.2495000e-03
  9.1334200e-03 1.8456200e-03 2.3240600e-03 4.6286400e-03 3.4352000e-03
  7.4365800e-03 1.3459000e-04 1.6318600e-03 3.0704000e-04 1.0975800e-03
  3.6708000e-03 4.8590200e-03 5.3601700e-03 2.0999000e-04 7.1537400e-03
  6.1366700e-03 1.1025380e-02 2.3229000e-04 1.1653900e-03 2.7053700e-03
  1.0293910e-02 5.6972800e-03 2.9431900e-03 1.5253400e-03 1.8858600e-03
  1.3929000e-03 1.0883300e-03 8.1753000e-04 5.5228620e-02 8.1283000e-04
  2.3860400e-03 1.1407900e-03 1.3660200e-03 4.8762920e-02 1.3235200e-03
  2.3005900e-03 3.8106900e-03 4.8764000e-04 1.1016100e-03 2.6229000e-04
  2.4436300e-03 1.6490260e-02 1.4405200e-03 1.7867300e-03 3.3622400e-03
  3.4086000e-04 7.1681000e-04 3.1730000e-05 5.6149300e-03 3.3687700e-03
  3.0056000e-04 1.5819000e-04 7.9114800e-03 3.8827400e-03 8.4833900e-03
  1.0991000e-04 4.9891300e-03 2.5578200e-03 1.3971900e-03 6.0110000e-05
  5.0173000e-04 1.5444700e-03 1.4023800e-03 7.7590000e-05 1.0822400e-03
  8.0309000e-04 8.9014400e-03 1.1914000e-04 3.0875900e-03 5.9822400e-03
  1.5899800e-03 9.4831000e-04 2.4678000e-04 2.4550400e-03 5.7620000e-05
  2.1178000e-04 2.7117000e-04 3.5723400e-03 2.2964000e-04 7.7124000e-04
  2.5648000e-04 2.5544200e-03 2.6596000e-04 1.5126800e-03 3.0982000e-03]]

Fungsi Objektif (J_9): 7.88437833

Akurasi Iterasi 9: 98.00%

--- ITERASI 10 ---
Cluster Pusat (V_10):
[[0.5130587  0.44299515 0.31145413 0.55426505 0.51381656]
 [0.84024501 0.66367954 0.42688812 0.78143944 0.81627341]
 [0.16411228 0.19629264 0.59161257 0.07902965 0.05999029]]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matriks U (U_10):
[[1.1239600e-03 4.9560900e-03 2.0470400e-03 3.7844900e-03 7.9536000e-04
  8.2315700e-03 1.1527100e-03 3.1611000e-04 1.0653780e-02 1.7564100e-03
  1.8593600e-03 2.4673000e-04 3.1668900e-03 7.6118400e-03 1.4444590e-02
  4.1085600e-02 5.3719700e-03 4.6390000e-05 8.2665400e-03 1.2087200e-03
  5.2006000e-04 7.0972000e-04 7.5363000e-04 8.9807000e-04 1.8244000e-04
  2.5709200e-03 6.5830000e-05 4.5730000e-05 3.4650000e-05 6.6657000e-04
  1.3270300e-03 1.0642100e-03 9.1683000e-03 1.8838830e-02 1.5775300e-03
  5.5698000e-04 1.6722200e-03 2.0207000e-03 8.7770700e-03 2.8595000e-04
  4.1030000e-04 1.1810463e-01 4.8998600e-03 5.8802100e-03 7.5910100e-03
  8.7502000e-03 4.4491100e-03 4.4772900e-03 4.6828000e-03 2.4420300e-03
  8.0334850e-01 9.2337345e-01 8.1379126e-01 9.7320981e-01 9.6265710e-01
  9.9477704e-01 8.8360487e-01 8.4974169e-01 9.6217936e-01 9.7946314e-01
  8.6122731e-01 9.9228934e-01 9.6687464e-01 9.9414269e-01 9.9161641e-01
  9.1907798e-01 9.9089596e-01 9.9503894e-01 9.6272053e-01 9.9255219e-01
  8.6921738e-01 9.9940508e-01 9.7403250e-01 9.9803598e-01 9.9131226e-01
  9.5067020e-01 8.9170219e-01 6.5264878e-01 9.9735170e-01 9.8607812e-01
  9.8502146e-01 9.7688302e-01 9.9912537e-01 9.6148829e-01 9.8021250e-01
  8.2521762e-01 7.4467178e-01 9.6872653e-01 9.9248980e-01 9.9141792e-01
  9.9294589e-01 9.7676394e-01 9.9563689e-01 9.0095888e-01 9.9450929e-01
  9.8603396e-01 9.9091098e-01 9.7732886e-01 9.0877962e-01 9.8929125e-01
  4.6754420e-02 5.5970701e-01 1.4430980e-02 1.0998797e-01 1.0236530e-02
  4.1815600e-02 8.4219866e-01 3.9208700e-02 1.0913207e-01 3.9784970e-02
  1.5567790e-02 6.1432470e-02 1.1858300e-03 4.1700358e-01 1.1741606e-01
  8.5964000e-03 9.4632100e-03 6.9108030e-02 5.6578970e-02 6.6649830e-01
  2.3301300e-03 2.8106906e-01 4.1085780e-02 1.1028140e-01 1.4153800e-03
  1.0796950e-02 1.1001402e-01 8.1308180e-02 2.9241300e-03 2.7682610e-02
  1.6997380e-02 7.2724140e-02 3.6988500e-03 1.7855501e-01 3.0108299e-01
  2.1510070e-02 1.5255100e-02 7.9266900e-03 9.6245110e-02 1.2323200e-03
  3.8120100e-03 4.9872300e-03 1.2833455e-01 3.7754700e-03 1.0797060e-02
  5.0278900e-03 8.2939650e-02 6.5665900e-03 2.2601560e-02 8.4108340e-02]
 [2.0248000e-04 7.6028000e-04 3.4345000e-04 6.0403000e-04 1.4808000e-04
  1.6556200e-03 1.9804000e-04 5.2210000e-05 1.6768800e-03 2.7004000e-04
  3.4862000e-04 4.0220000e-05 4.8201000e-04 1.3225500e-03 3.4016100e-03
  1.1636670e-02 1.0989700e-03 7.5300000e-06 1.5471100e-03 2.2842000e-04
  7.6650000e-05 1.2220000e-04 1.4652000e-04 1.1073000e-04 2.6900000e-05
  3.2826000e-04 9.1300000e-06 7.2500000e-06 5.2900000e-06 9.4790000e-05
  1.7759000e-04 1.4397000e-04 2.1546000e-03 4.7333900e-03 2.2062000e-04
  8.1180000e-05 2.7096000e-04 2.8088000e-04 1.3093500e-03 4.2120000e-05
  6.4800000e-05 1.5945380e-02 7.7481000e-04 7.8122000e-04 1.2696900e-03
  1.0946900e-03 8.3127000e-04 6.6104000e-04 8.2657000e-04 3.5112000e-04
  1.6737296e-01 6.2283680e-02 1.6750313e-01 1.4279400e-02 3.2462020e-02
  3.4025600e-03 1.0184005e-01 2.8825740e-02 3.1759080e-02 1.0315770e-02
  4.4044240e-02 5.9767500e-03 1.8560990e-02 5.0136000e-03 4.1021100e-03
  7.1839920e-02 7.2635100e-03 2.6102800e-03 3.2649340e-02 3.9672600e-03
  1.2338205e-01 4.6078000e-04 2.4344950e-02 1.6595400e-03 7.6013600e-03
  4.5688950e-02 1.0346782e-01 3.4201069e-01 2.4426500e-03 6.6945600e-03
  8.7790200e-03 1.1991420e-02 6.3796000e-04 3.7356360e-02 1.7085590e-02
  1.6453093e-01 2.4965851e-01 2.8330370e-02 5.9832500e-03 6.6786700e-03
  5.6496300e-03 2.2160080e-02 3.5386800e-03 4.3525190e-02 4.6733500e-03
  1.1580120e-02 7.9488500e-03 2.1315400e-02 4.2212860e-02 9.3833400e-03
  9.5094729e-01 4.3648122e-01 9.8508242e-01 8.8890251e-01 9.8950029e-01
  9.5574908e-01 1.4128373e-01 9.5935227e-01 8.8907398e-01 9.5686762e-01
  9.8408913e-01 9.3784409e-01 9.9878234e-01 5.7736982e-01 8.7920502e-01
  9.9110276e-01 9.9037643e-01 9.2300902e-01 9.3954873e-01 3.2501169e-01
  9.9756123e-01 7.1392579e-01 9.5636456e-01 8.8831111e-01 9.9852508e-01
  9.8870360e-01 8.8843043e-01 9.1727931e-01 9.9699750e-01 9.7123558e-01
  9.8220217e-01 9.1840508e-01 9.9618147e-01 8.1834382e-01 6.9291938e-01
  9.7690912e-01 9.8379963e-01 9.9182508e-01 9.0128769e-01 9.9871070e-01
  9.9597794e-01 9.9474341e-01 8.6807870e-01 9.9599724e-01 9.8843663e-01
  9.9471675e-01 9.1449656e-01 9.9316697e-01 9.7588866e-01 9.1278264e-01]
 [9.9867356e-01 9.9428363e-01 9.9760951e-01 9.9561148e-01 9.9905656e-01
  9.9011282e-01 9.9864924e-01 9.9963168e-01 9.8766935e-01 9.9797355e-01
  9.9779201e-01 9.9971304e-01 9.9635110e-01 9.9106561e-01 9.8215380e-01
  9.4727773e-01 9.9352906e-01 9.9994608e-01 9.9018635e-01 9.9856286e-01
  9.9940328e-01 9.9916808e-01 9.9909984e-01 9.9899120e-01 9.9979065e-01
  9.9710082e-01 9.9992503e-01 9.9994701e-01 9.9996006e-01 9.9923864e-01
  9.9849538e-01 9.9879182e-01 9.8867710e-01 9.7642778e-01 9.9820184e-01
  9.9936184e-01 9.9805682e-01 9.9769842e-01 9.8991358e-01 9.9967193e-01
  9.9952490e-01 8.6595000e-01 9.9432534e-01 9.9333857e-01 9.9113930e-01
  9.9015511e-01 9.9471963e-01 9.9486167e-01 9.9449063e-01 9.9720685e-01
  2.9278540e-02 1.4342860e-02 1.8705610e-02 1.2510790e-02 4.8808800e-03
  1.8204000e-03 1.4555080e-02 1.2143256e-01 6.0615600e-03 1.0221090e-02
  9.4728450e-02 1.7339100e-03 1.4564370e-02 8.4371000e-04 4.2814800e-03
  9.0821000e-03 1.8405300e-03 2.3507800e-03 4.6301300e-03 3.4805400e-03
  7.4005700e-03 1.3414000e-04 1.6225500e-03 3.0449000e-04 1.0863800e-03
  3.6408500e-03 4.8299900e-03 5.3405300e-03 2.0565000e-04 7.2273200e-03
  6.1995200e-03 1.1125560e-02 2.3667000e-04 1.1553500e-03 2.7019100e-03
  1.0251460e-02 5.6697100e-03 2.9431000e-03 1.5269500e-03 1.9034100e-03
  1.4044800e-03 1.0759800e-03 8.2443000e-04 5.5515920e-02 8.1736000e-04
  2.3859200e-03 1.1401700e-03 1.3557400e-03 4.9007520e-02 1.3254100e-03
  2.2982900e-03 3.8117700e-03 4.8659000e-04 1.1095200e-03 2.6318000e-04
  2.4353200e-03 1.6517610e-02 1.4390300e-03 1.7939500e-03 3.3474100e-03
  3.4308000e-04 7.2344000e-04 3.1830000e-05 5.6266000e-03 3.3789200e-03
  3.0083000e-04 1.6036000e-04 7.8829500e-03 3.8723100e-03 8.4900100e-03
  1.0864000e-04 5.0051600e-03 2.5496600e-03 1.4074900e-03 5.9540000e-05
  4.9944000e-04 1.5555500e-03 1.4125100e-03 7.8370000e-05 1.0818100e-03
  8.0045000e-04 8.8707800e-03 1.1968000e-04 3.1011700e-03 5.9976300e-03
  1.5808100e-03 9.4527000e-04 2.4823000e-04 2.4672000e-03 5.6980000e-05
  2.1005000e-04 2.6937000e-04 3.5867600e-03 2.2729000e-04 7.6631000e-04
  2.5535000e-04 2.5637900e-03 2.6644000e-04 1.5097800e-03 3.1090200e-03]]

Fungsi Objektif (J_10): 7.88423723

Akurasi Iterasi 10: 98.00%

--- ITERASI 11 ---
Cluster Pusat (V_11):
[[0.51310654 0.44310281 0.31152775 0.55435089 0.51391631]
 [0.84030098 0.66380604 0.42697199 0.78151277 0.81636766]
 [0.16411544 0.19629033 0.59160374 0.07903103 0.05999236]]

Matriks U (U_11):
[[1.1235200e-03 4.9524100e-03 2.0456700e-03 3.7817100e-03 7.9510000e-04
  8.2294200e-03 1.1520300e-03 3.1595000e-04 1.0645370e-02 1.7550700e-03
  1.8588500e-03 2.4659000e-04 3.1643200e-03 7.6062100e-03 1.4441480e-02
  4.1080410e-02 5.3706100e-03 4.6380000e-05 8.2641800e-03 1.2084200e-03
  5.1979000e-04 7.0951000e-04 7.5330000e-04 8.9729000e-04 1.8230000e-04
  2.5684000e-03 6.5780000e-05 4.5720000e-05 3.4630000e-05 6.6592000e-04
  1.3256900e-03 1.0635200e-03 9.1660200e-03 1.8835010e-02 1.5760400e-03
  5.5645000e-04 1.6714000e-03 2.0187900e-03 8.7693000e-03 2.8573000e-04
  4.1004000e-04 1.1800419e-01 4.8958000e-03 5.8761000e-03 7.5877100e-03
  8.7415300e-03 4.4473100e-03 4.4733900e-03 4.6807300e-03 2.4400100e-03
  8.0359838e-01 9.2351466e-01 8.1408324e-01 9.7316827e-01 9.6274485e-01
  9.9477307e-01 8.8383600e-01 8.4951927e-01 9.6226194e-01 9.7942910e-01
  8.6107001e-01 9.9230571e-01 9.6683534e-01 9.9416507e-01 9.9159955e-01
  9.1926994e-01 9.9091140e-01 9.9502295e-01 9.6275489e-01 9.9252597e-01
  8.6955157e-01 9.9940583e-01 9.7411107e-01 9.9804251e-01 9.9134655e-01
  9.5083971e-01 8.9201069e-01 6.5343530e-01 9.9737242e-01 9.8604073e-01
  9.8498523e-01 9.7683230e-01 9.9912118e-01 9.6166167e-01 9.8024580e-01
  8.2562333e-01 7.4534997e-01 9.6876631e-01 9.9249584e-01 9.9140426e-01
  9.9293726e-01 9.7688332e-01 9.9563144e-01 9.0084862e-01 9.9450854e-01
  9.8605094e-01 9.9092614e-01 9.7741685e-01 9.0868710e-01 9.8930326e-01
  4.6785300e-02 5.6061334e-01 1.4435210e-02 1.1046919e-01 1.0261610e-02
  4.1802020e-02 8.4231555e-01 3.9235360e-02 1.0942809e-01 3.9756270e-02
  1.5626150e-02 6.1731990e-02 1.1883300e-03 4.1767856e-01 1.1766035e-01
  8.6095100e-03 9.5234400e-03 6.9072110e-02 5.6568160e-02 6.6693122e-01
  2.3226200e-03 2.8166774e-01 4.1073000e-02 1.1072693e-01 1.4120300e-03
  1.0789920e-02 1.1044732e-01 8.1630550e-02 2.9389200e-03 2.7707570e-02
  1.6993220e-02 7.2688770e-02 3.7099100e-03 1.7904238e-01 3.0160899e-01
  2.1483250e-02 1.5252740e-02 7.9536900e-03 9.6521680e-02 1.2288200e-03
  3.8049400e-03 4.9806500e-03 1.2863115e-01 3.7654700e-03 1.0782400e-02
  5.0256600e-03 8.3121970e-02 6.5789400e-03 2.2607530e-02 8.4291330e-02]
 [2.0242000e-04 7.5988000e-04 3.4328000e-04 6.0371000e-04 1.4804000e-04
  1.6551900e-03 1.9796000e-04 5.2190000e-05 1.6759500e-03 2.6989000e-04
  3.4855000e-04 4.0210000e-05 4.8173000e-04 1.3218500e-03 3.4008100e-03
  1.1634160e-02 1.0987000e-03 7.5300000e-06 1.5466800e-03 2.2838000e-04
  7.6620000e-05 1.2217000e-04 1.4647000e-04 1.1066000e-04 2.6890000e-05
  3.2803000e-04 9.1300000e-06 7.2500000e-06 5.2900000e-06 9.4720000e-05
  1.7746000e-04 1.4390000e-04 2.1540500e-03 4.7322100e-03 2.2047000e-04
  8.1120000e-05 2.7086000e-04 2.8068000e-04 1.3085300e-03 4.2090000e-05
  6.4770000e-05 1.5937320e-02 7.7433000e-04 7.8079000e-04 1.2691800e-03
  1.0939300e-03 8.3097000e-04 6.6061000e-04 8.2625000e-04 3.5090000e-04
  1.6714693e-01 6.2159750e-02 1.6722999e-01 1.4294980e-02 3.2381700e-02
  3.4039000e-03 1.0162764e-01 2.8847870e-02 3.1685110e-02 1.0327580e-02
  4.4068180e-02 5.9626000e-03 1.8575240e-02 4.9936200e-03 4.1081800e-03
  7.1662480e-02 7.2494800e-03 2.6173900e-03 3.2614660e-02 3.9792300e-03
  1.2305878e-01 4.6008000e-04 2.4269290e-02 1.6537100e-03 7.5702500e-03
  4.5528200e-02 1.0316795e-01 3.4123006e-01 2.4232600e-03 6.7088300e-03
  8.7961900e-03 1.2011530e-02 6.4080000e-04 3.7186270e-02 1.7053690e-02
  1.6413804e-01 2.4898859e-01 2.8290900e-02 5.9768600e-03 6.6873800e-03
  5.6550500e-03 2.2044600e-02 3.5422100e-03 4.3549500e-02 4.6730000e-03
  1.1563420e-02 7.9341500e-03 2.1230720e-02 4.2232530e-02 9.3711200e-03
  9.5091733e-01 4.3557441e-01 9.8507868e-01 8.8841850e-01 9.8947492e-01
  9.5576588e-01 1.4116005e-01 9.5932633e-01 8.8877540e-01 9.5690188e-01
  9.8403002e-01 9.3754218e-01 9.9877982e-01 5.7669058e-01 8.7895688e-01
  9.9108956e-01 9.9031544e-01 9.2305559e-01 9.3956338e-01 3.2457692e-01
  9.9756921e-01 7.1332111e-01 9.5638040e-01 8.8786179e-01 9.9852864e-01
  9.8871153e-01 8.8799303e-01 9.1695318e-01 9.9698240e-01 9.7121084e-01
  9.8220732e-01 9.1845181e-01 9.9617017e-01 8.1785141e-01 6.9238767e-01
  9.7693927e-01 9.8380300e-01 9.9179752e-01 9.0100649e-01 9.9871442e-01
  9.9598560e-01 9.9475060e-01 8.6777653e-01 9.9600806e-01 9.8845300e-01
  9.9471934e-01 9.1431057e-01 9.9315438e-01 9.7588357e-01 9.1259539e-01]
 [9.9867406e-01 9.9428771e-01 9.9761104e-01 9.9561458e-01 9.9905685e-01
  9.9011539e-01 9.9865001e-01 9.9963185e-01 9.8767868e-01 9.9797504e-01
  9.9779260e-01 9.9971320e-01 9.9635395e-01 9.9107193e-01 9.8215771e-01
  9.4728543e-01 9.9353069e-01 9.9994609e-01 9.9018914e-01 9.9856320e-01
  9.9940359e-01 9.9916832e-01 9.9910023e-01 9.9899205e-01 9.9979081e-01
  9.9710356e-01 9.9992510e-01 9.9994703e-01 9.9996008e-01 9.9923937e-01
  9.9849685e-01 9.9879259e-01 9.8867992e-01 9.7643278e-01 9.9820349e-01
  9.9936243e-01 9.9805774e-01 9.9770052e-01 9.8992217e-01 9.9967217e-01
  9.9952519e-01 8.6605849e-01 9.9432987e-01 9.9334312e-01 9.9114311e-01
  9.9016454e-01 9.9472172e-01 9.9486600e-01 9.9449302e-01 9.9720909e-01
  2.9254680e-02 1.4325590e-02 1.8686760e-02 1.2536750e-02 4.8734500e-03
  1.8230200e-03 1.4536360e-02 1.2163287e-01 6.0529600e-03 1.0243320e-02
  9.4861810e-02 1.7316900e-03 1.4589420e-02 8.4132000e-04 4.2922700e-03
  9.0675800e-03 1.8391200e-03 2.3596500e-03 4.6304500e-03 3.4948000e-03
  7.3896500e-03 1.3410000e-04 1.6196400e-03 3.0379000e-04 1.0832000e-03
  3.6320900e-03 4.8213600e-03 5.3346500e-03 2.0432000e-04 7.2504400e-03
  6.2185700e-03 1.1156160e-02 2.3802000e-04 1.1520600e-03 2.7005000e-03
  1.0238640e-02 5.6614400e-03 2.9427900e-03 1.5273000e-03 1.9083600e-03
  1.4076900e-03 1.0720900e-03 8.2636000e-04 5.5601890e-02 8.1846000e-04
  2.3856400e-03 1.1397100e-03 1.3524300e-03 4.9080370e-02 1.3256300e-03
  2.2973700e-03 3.8122500e-03 4.8611000e-04 1.1123100e-03 2.6347000e-04
  2.4320900e-03 1.6524400e-02 1.4383100e-03 1.7965100e-03 3.3418500e-03
  3.4383000e-04 7.2583000e-04 3.1850000e-05 5.6308500e-03 3.3827800e-03
  3.0093000e-04 1.6113000e-04 7.8723000e-03 3.8684500e-03 8.4918600e-03
  1.0817000e-04 5.0111500e-03 2.5466000e-03 1.4112800e-03 5.9330000e-05
  4.9855000e-04 1.5596600e-03 1.4162700e-03 7.8680000e-05 1.0815900e-03
  7.9946000e-04 8.8594200e-03 1.1992000e-04 3.1062100e-03 6.0033400e-03
  1.5774800e-03 9.4425000e-04 2.4879000e-04 2.4718300e-03 5.6760000e-05
  2.0946000e-04 2.6875000e-04 3.5923200e-03 2.2648000e-04 7.6461000e-04
  2.5501000e-04 2.5674600e-03 2.6668000e-04 1.5089000e-03 3.1132800e-03]]

Fungsi Objektif (J_11): 7.88418319

Akurasi Iterasi 11: 98.00%

--- ITERASI 12 ---
Cluster Pusat (V_12):
[[0.51312569 0.44313493 0.31154903 0.55437896 0.51394958]
 [0.84031841 0.66385315 0.42700311 0.78153938 0.8164008 ]
 [0.16411642 0.19628963 0.59160101 0.07903146 0.05999301]]

Matriks U (U_12):
[[1.1233600e-03 4.9511700e-03 2.0452100e-03 3.7807900e-03 7.9501000e-04
  8.2285900e-03 1.1518000e-03 3.1590000e-04 1.0642600e-02 1.7546200e-03
  1.8586500e-03 2.4654000e-04 3.1634700e-03 7.6043700e-03 1.4440240e-02
  4.1078120e-02 5.3700800e-03 4.6380000e-05 8.2632700e-03 1.2083000e-03
  5.1969000e-04 7.0943000e-04 7.5318000e-04 8.9703000e-04 1.8225000e-04
  2.5675700e-03 6.5760000e-05 4.5720000e-05 3.4620000e-05 6.6570000e-04
  1.3252500e-03 1.0632800e-03 9.1651700e-03 1.8833510e-02 1.5755500e-03
  5.5628000e-04 1.6711100e-03 2.0181700e-03 8.7667700e-03 2.8566000e-04
  4.0995000e-04 1.1797192e-01 4.8944800e-03 5.8747100e-03 7.5865400e-03
  8.7387000e-03 4.4466700e-03 4.4721100e-03 4.6800000e-03 2.4393400e-03
  8.0367196e-01 9.2355659e-01 8.1417097e-01 9.7315547e-01 9.6277140e-01
  9.9477153e-01 8.8390664e-01 8.4944946e-01 9.6228639e-01 9.7941862e-01
  8.6102226e-01 9.9231050e-01 9.6682311e-01 9.9417178e-01 9.9159389e-01
  9.1932817e-01 9.9091635e-01 9.9501765e-01 9.6276750e-01 9.9251777e-01
  8.6966014e-01 9.9940596e-01 9.7413714e-01 9.9804446e-01 9.9135695e-01
  9.5089245e-01 8.9210852e-01 6.5368681e-01 9.9737908e-01 9.8602908e-01
  9.8497458e-01 9.7681718e-01 9.9911991e-01 9.6172062e-01 9.8025803e-01
  8.2575545e-01 7.4556712e-01 9.6878122e-01 9.9249829e-01 9.9140103e-01
  9.9293546e-01 9.7692274e-01 9.9563028e-01 9.0081749e-01 9.9450922e-01
  9.8605737e-01 9.9093206e-01 9.7744649e-01 9.0866158e-01 9.8930856e-01
  4.6794300e-02 5.6093576e-01 1.4435210e-02 1.1063525e-01 1.0269850e-02
  4.1794420e-02 8.4236619e-01 3.9241890e-02 1.0953046e-01 3.9743790e-02
  1.5645800e-02 6.1837690e-02 1.1890500e-03 4.1792611e-01 1.1774852e-01
  8.6138800e-03 9.5444500e-03 6.9055900e-02 5.6562340e-02 6.6709414e-01
  2.3197500e-03 2.8188671e-01 4.1066540e-02 1.1088691e-01 1.4107300e-03
  1.0786550e-02 1.1060346e-01 8.1746380e-02 2.9444000e-03 2.7714990e-02
  1.6990960e-02 7.2672920e-02 3.7141000e-03 1.7921738e-01 3.0180059e-01
  2.1472810e-02 1.5251840e-02 7.9635000e-03 9.6622600e-02 1.2275800e-03
  3.8024700e-03 4.9783100e-03 1.2874162e-01 3.7619000e-03 1.0777110e-02
  5.0250200e-03 8.3189760e-02 6.5836900e-03 2.2609870e-02 8.4359160e-02]
 [2.0240000e-04 7.5974000e-04 3.4323000e-04 6.0360000e-04 1.4803000e-04
  1.6550400e-03 1.9793000e-04 5.2190000e-05 1.6756300e-03 2.6984000e-04
  3.4852000e-04 4.0200000e-05 4.8163000e-04 1.3216100e-03 3.4005200e-03
  1.1633280e-02 1.0986000e-03 7.5300000e-06 1.5465200e-03 2.2836000e-04
  7.6610000e-05 1.2216000e-04 1.4646000e-04 1.1063000e-04 2.6880000e-05
  3.2795000e-04 9.1300000e-06 7.2500000e-06 5.2900000e-06 9.4690000e-05
  1.7741000e-04 1.4387000e-04 2.1538500e-03 4.7317900e-03 2.2042000e-04
  8.1100000e-05 2.7082000e-04 2.8062000e-04 1.3082500e-03 4.2090000e-05
  6.4760000e-05 1.5934430e-02 7.7417000e-04 7.8063000e-04 1.2690000e-03
  1.0936700e-03 8.3087000e-04 6.6047000e-04 8.2614000e-04 3.5083000e-04
  1.6707999e-01 6.2122570e-02 1.6714767e-01 1.4299480e-02 3.2357240e-02
  3.4044700e-03 1.0156241e-01 2.8853970e-02 3.1663000e-02 1.0330970e-02
  4.4074080e-02 5.9583800e-03 1.8579350e-02 4.9875900e-03 4.1101800e-03
  7.1608420e-02 7.2449300e-03 2.6197200e-03 3.2602000e-02 3.9828800e-03
  1.2295359e-01 4.5993000e-04 2.4244150e-02 1.6519500e-03 7.5607600e-03
  4.5478070e-02 1.0307274e-01 3.4098034e-01 2.4170200e-03 6.7131200e-03
  8.8009900e-03 1.2017170e-02 6.4165000e-04 3.7128410e-02 1.7042030e-02
  1.6400985e-01 2.4877397e-01 2.8276180e-02 5.9743500e-03 6.6892000e-03
  5.6559600e-03 2.2006420e-02 3.5428200e-03 4.3554500e-02 4.6720600e-03
  1.1557150e-02 7.9284600e-03 2.1202160e-02 4.2236020e-02 9.3658600e-03
  9.5090868e-01 4.3525178e-01 9.8507889e-01 8.8825146e-01 9.8946659e-01
  9.5577471e-01 1.4110780e-01 9.5932011e-01 8.8867212e-01 9.5691642e-01
  9.8401011e-01 9.3743562e-01 9.9877910e-01 5.7644149e-01 8.7886726e-01
  9.9108516e-01 9.9029416e-01 9.2307573e-01 9.3957062e-01 3.2441348e-01
  9.9757225e-01 7.1309993e-01 9.5638800e-01 8.8770042e-01 9.9853002e-01
  9.8871524e-01 8.8783538e-01 9.1683597e-01 9.9697681e-01 9.7120352e-01
  9.8220995e-01 9.1847183e-01 9.9616589e-01 8.1767457e-01 6.9219398e-01
  9.7695092e-01 9.8380425e-01 9.9178750e-01 9.0090385e-01 9.9871574e-01
  9.9598827e-01 9.9475315e-01 8.6766396e-01 9.9601191e-01 9.8845888e-01
  9.9472008e-01 9.1424138e-01 9.9314953e-01 9.7588149e-01 9.1252594e-01]
 [9.9867424e-01 9.9428908e-01 9.9761156e-01 9.9561561e-01 9.9905696e-01
  9.9011638e-01 9.9865027e-01 9.9963191e-01 9.8768177e-01 9.9797554e-01
  9.9779283e-01 9.9971326e-01 9.9635490e-01 9.9107402e-01 9.8215924e-01
  9.4728860e-01 9.9353132e-01 9.9994609e-01 9.9019021e-01 9.9856333e-01
  9.9940370e-01 9.9916841e-01 9.9910036e-01 9.9899234e-01 9.9979086e-01
  9.9710447e-01 9.9992512e-01 9.9994703e-01 9.9996009e-01 9.9923960e-01
  9.9849734e-01 9.9879285e-01 9.8868098e-01 9.7643471e-01 9.9820404e-01
  9.9936262e-01 9.9805807e-01 9.9770122e-01 9.8992498e-01 9.9967225e-01
  9.9952529e-01 8.6609365e-01 9.9433135e-01 9.9334466e-01 9.9114446e-01
  9.9016763e-01 9.9472246e-01 9.9486742e-01 9.9449387e-01 9.9720983e-01
  2.9248040e-02 1.4320840e-02 1.8681370e-02 1.2545040e-02 4.8713600e-03
  1.8240000e-03 1.4530950e-02 1.2169657e-01 6.0506100e-03 1.0250410e-02
  9.4903660e-02 1.7311200e-03 1.4597540e-02 8.4064000e-04 4.2959300e-03
  9.0634100e-03 1.8387200e-03 2.3626300e-03 4.6305000e-03 3.4993500e-03
  7.3862700e-03 1.3411000e-04 1.6187100e-03 3.0359000e-04 1.0822900e-03
  3.6294800e-03 4.8187400e-03 5.3328600e-03 2.0390000e-04 7.2578000e-03
  6.2244400e-03 1.1165650e-02 2.3844000e-04 1.1509600e-03 2.6999500e-03
  1.0234700e-02 5.6589200e-03 2.9426000e-03 1.5273600e-03 1.9097700e-03
  1.4085800e-03 1.0708300e-03 8.2689000e-04 5.5628010e-02 8.1872000e-04
  2.3854700e-03 1.1394800e-03 1.3513400e-03 4.9102400e-02 1.3255800e-03
  2.2970200e-03 3.8124600e-03 4.8591000e-04 1.1132900e-03 2.6356000e-04
  2.4308700e-03 1.6526010e-02 1.4380000e-03 1.7974200e-03 3.3397900e-03
  3.4409000e-04 7.2669000e-04 3.1850000e-05 5.6324000e-03 3.3842200e-03
  3.0096000e-04 1.6140000e-04 7.8683700e-03 3.8670400e-03 8.4923800e-03
  1.0800000e-04 5.0133600e-03 2.5454600e-03 1.4126700e-03 5.9250000e-05
  4.9822000e-04 1.5611600e-03 1.4176500e-03 7.8800000e-05 1.0814800e-03
  7.9909000e-04 8.8552400e-03 1.2001000e-04 3.1080600e-03 6.0054300e-03
  1.5762700e-03 9.4391000e-04 2.4900000e-04 2.4735500e-03 5.6680000e-05
  2.0926000e-04 2.6854000e-04 3.5944200e-03 2.2619000e-04 7.6401000e-04
  2.5489000e-04 2.5688600e-03 2.6679000e-04 1.5086300e-03 3.1149000e-03]]

Fungsi Objektif (J_12): 7.88416212

Akurasi Iterasi 12: 98.00%

--- ITERASI 13 ---
Cluster Pusat (V_13):
[[0.51313307 0.4431447  0.31155529 0.55438828 0.51396083]
 [0.84032397 0.66387049 0.42701453 0.78154899 0.81641249]
 [0.16411674 0.19628942 0.59160016 0.0790316  0.05999322]]

Matriks U (U_13):
[[1.1233000e-03 4.9507600e-03 2.0450600e-03 3.7804700e-03 7.9497000e-04
  8.2282700e-03 1.1517300e-03 3.1588000e-04 1.0641670e-02 1.7544700e-03
  1.8585800e-03 2.4653000e-04 3.1631800e-03 7.6037500e-03 1.4439760e-02
  4.1077190e-02 5.3698800e-03 4.6380000e-05 8.2629300e-03 1.2082600e-03
  5.1965000e-04 7.0940000e-04 7.5314000e-04 8.9694000e-04 1.8224000e-04
  2.5673000e-03 6.5750000e-05 4.5710000e-05 3.4620000e-05 6.6563000e-04
  1.3251100e-03 1.0631900e-03 9.1648500e-03 1.8832940e-02 1.5753800e-03
  5.5622000e-04 1.6710100e-03 2.0179600e-03 8.7659400e-03 2.8564000e-04
  4.0992000e-04 1.1796136e-01 4.8940400e-03 5.8742300e-03 7.5861200e-03
  8.7377600e-03 4.4464500e-03 4.4716900e-03 4.6797400e-03 2.4391200e-03
  8.0369408e-01 9.2356931e-01 8.1419790e-01 9.7315146e-01 9.6277961e-01
  9.9477095e-01 8.8392871e-01 8.4942712e-01 9.6229378e-01 9.7941533e-01
  8.6100747e-01 9.9231192e-01 9.6681923e-01 9.9417384e-01 9.9159198e-01
  9.1934623e-01 9.9091796e-01 9.9501586e-01 9.6277210e-01 9.9251516e-01
  8.6969607e-01 9.9940597e-01 9.7414593e-01 9.9804506e-01 9.9136018e-01
  9.5090922e-01 8.9214019e-01 6.5376879e-01 9.9738127e-01 9.8602538e-01
  9.8497139e-01 9.7681258e-01 9.9911952e-01 9.6174090e-01 9.8026248e-01
  8.2579924e-01 7.4563799e-01 9.6878672e-01 9.9249924e-01 9.9140031e-01
  9.9293516e-01 9.7693598e-01 9.9563008e-01 9.0080858e-01 9.9450972e-01
  9.8605977e-01 9.9093431e-01 9.7745661e-01 9.0865448e-01 9.8931072e-01
  4.6796980e-02 5.6105051e-01 1.4434810e-02 1.1069291e-01 1.0272590e-02
  4.1790980e-02 8.4238663e-01 3.9243420e-02 1.0956606e-01 3.9738740e-02
  1.5652500e-02 6.1875030e-02 1.1892600e-03 4.1801617e-01 1.1778023e-01
  8.6153600e-03 9.5518000e-03 6.9049220e-02 5.6559730e-02 6.6715448e-01
  2.3186800e-03 2.8196619e-01 4.1063720e-02 1.1094418e-01 1.4102300e-03
  1.0785110e-02 1.1065950e-01 8.1787870e-02 2.9464000e-03 2.7717240e-02
  1.6989940e-02 7.2666410e-02 3.7156500e-03 1.7928002e-01 3.0186991e-01
  2.1468850e-02 1.5251500e-02 7.9670400e-03 9.6659150e-02 1.2271400e-03
  3.8016100e-03 4.9774700e-03 1.2878222e-01 3.7606200e-03 1.0775210e-02
  5.0248400e-03 8.3214640e-02 6.5854700e-03 2.2610760e-02 8.4384000e-02]
 [2.0239000e-04 7.5969000e-04 3.4321000e-04 6.0356000e-04 1.4803000e-04
  1.6549800e-03 1.9792000e-04 5.2190000e-05 1.6755200e-03 2.6982000e-04
  3.4851000e-04 4.0200000e-05 4.8160000e-04 1.3215300e-03 3.4004200e-03
  1.1632960e-02 1.0985700e-03 7.5300000e-06 1.5464600e-03 2.2836000e-04
  7.6610000e-05 1.2216000e-04 1.4645000e-04 1.1063000e-04 2.6880000e-05
  3.2793000e-04 9.1200000e-06 7.2500000e-06 5.2900000e-06 9.4680000e-05
  1.7740000e-04 1.4386000e-04 2.1537800e-03 4.7316300e-03 2.2040000e-04
  8.1090000e-05 2.7081000e-04 2.8059000e-04 1.3081500e-03 4.2080000e-05
  6.4760000e-05 1.5933400e-02 7.7411000e-04 7.8058000e-04 1.2689400e-03
  1.0935800e-03 8.3083000e-04 6.6041000e-04 8.2610000e-04 3.5080000e-04
  1.6705974e-01 6.2111170e-02 1.6712230e-01 1.4300800e-02 3.2349620e-02
  3.4047000e-03 1.0154192e-01 2.8855660e-02 3.1656240e-02 1.0331950e-02
  4.4075480e-02 5.9571000e-03 1.8580550e-02 4.9857200e-03 4.1108400e-03
  7.1591570e-02 7.2434300e-03 2.6205000e-03 3.2597400e-02 3.9840200e-03
  1.2291873e-01 4.5991000e-04 2.4235670e-02 1.6514000e-03 7.5578000e-03
  4.5462090e-02 1.0304188e-01 3.4089890e-01 2.4149700e-03 6.7144300e-03
  8.8023400e-03 1.2018760e-02 6.4190000e-04 3.7108510e-02 1.7037780e-02
  1.6396729e-01 2.4870388e-01 2.8270760e-02 5.9733900e-03 6.6895100e-03
  5.6560100e-03 2.1993600e-02 3.5428700e-03 4.3555310e-02 4.6715100e-03
  1.1554840e-02 7.9263100e-03 2.1192410e-02 4.2236320e-02 9.3637500e-03
  9.5090613e-01 4.3513695e-01 9.8507937e-01 8.8819345e-01 9.8946381e-01
  9.5577861e-01 1.4108700e-01 9.5931870e-01 8.8863619e-01 9.5692222e-01
  9.8400332e-01 9.3739798e-01 9.9877889e-01 5.7635087e-01 8.7883503e-01
  9.9108367e-01 9.9028671e-01 9.2308384e-01 9.3957374e-01 3.2435298e-01
  9.9757339e-01 7.1301964e-01 9.5639123e-01 8.8764265e-01 9.9853055e-01
  9.8871680e-01 8.8777879e-01 9.1679398e-01 9.9697476e-01 9.7120132e-01
  9.8221110e-01 9.1847987e-01 9.9616430e-01 8.1761125e-01 6.9212389e-01
  9.7695532e-01 9.8380471e-01 9.9178388e-01 9.0086666e-01 9.9871621e-01
  9.9598920e-01 9.9475406e-01 8.6762259e-01 9.9601329e-01 9.8846099e-01
  9.9472030e-01 9.1421599e-01 9.9314771e-01 9.7588069e-01 9.1250050e-01]
 [9.9867431e-01 9.9428955e-01 9.9761174e-01 9.9561596e-01 9.9905700e-01
  9.9011675e-01 9.9865036e-01 9.9963193e-01 9.8768281e-01 9.9797571e-01
  9.9779292e-01 9.9971328e-01 9.9635522e-01 9.9107473e-01 9.8215982e-01
  9.4728985e-01 9.9353155e-01 9.9994610e-01 9.9019061e-01 9.9856338e-01
  9.9940374e-01 9.9916844e-01 9.9910041e-01 9.9899243e-01 9.9979088e-01
  9.9710478e-01 9.9992513e-01 9.9994703e-01 9.9996009e-01 9.9923968e-01
  9.9849750e-01 9.9879295e-01 9.8868137e-01 9.7643543e-01 9.9820422e-01
  9.9936268e-01 9.9805818e-01 9.9770145e-01 9.8992592e-01 9.9967228e-01
  9.9952532e-01 8.6610524e-01 9.9433185e-01 9.9334519e-01 9.9114494e-01
  9.9016866e-01 9.9472272e-01 9.9486790e-01 9.9449416e-01 9.9721008e-01
  2.9246170e-02 1.4319520e-02 1.8679800e-02 1.2547740e-02 4.8707700e-03
  1.8243500e-03 1.4529370e-02 1.2171721e-01 6.0499700e-03 1.0252710e-02
  9.4917050e-02 1.7309800e-03 1.4600220e-02 8.4044000e-04 4.2971800e-03
  9.0621900e-03 1.8386100e-03 2.3636400e-03 4.6305000e-03 3.5008200e-03
  7.3852000e-03 1.3412000e-04 1.6184100e-03 3.0354000e-04 1.0820200e-03
  3.6286900e-03 4.8179300e-03 5.3323100e-03 2.0376000e-04 7.2601900e-03
  6.2262700e-03 1.1168650e-02 2.3857000e-04 1.1505900e-03 2.6997300e-03
  1.0233460e-02 5.6581300e-03 2.9425200e-03 1.5273600e-03 1.9101800e-03
  1.4088300e-03 1.0704200e-03 8.2705000e-04 5.5636110e-02 8.1877000e-04
  2.3853900e-03 1.1393800e-03 1.3509800e-03 4.9109190e-02 1.3255300e-03
  2.2968900e-03 3.8125400e-03 4.8583000e-04 1.1136400e-03 2.6359000e-04
  2.4304200e-03 1.6526370e-02 1.4378800e-03 1.7977500e-03 3.3390400e-03
  3.4418000e-04 7.2700000e-04 3.1850000e-05 5.6329600e-03 3.3847500e-03
  3.0097000e-04 1.6149000e-04 7.8669300e-03 3.8665200e-03 8.4925300e-03
  1.0793000e-04 5.0141700e-03 2.5450400e-03 1.4131800e-03 5.9220000e-05
  4.9809000e-04 1.5617100e-03 1.4181500e-03 7.8840000e-05 1.0814400e-03
  7.9896000e-04 8.8537200e-03 1.2004000e-04 3.1087300e-03 6.0062000e-03
  1.5758300e-03 9.4379000e-04 2.4908000e-04 2.4741900e-03 5.6650000e-05
  2.0919000e-04 2.6847000e-04 3.5951900e-03 2.2609000e-04 7.6380000e-04
  2.5486000e-04 2.5693800e-03 2.6683000e-04 1.5085500e-03 3.1155000e-03]]

Fungsi Objektif (J_13): 7.88415405

Akurasi Iterasi 13: 98.00%

--- ITERASI 14 ---
Cluster Pusat (V_14):
[[0.51313584 0.44314774 0.31155717 0.55439143 0.51396468]
 [0.84032578 0.6638768  0.42701867 0.78155245 0.81641662]
 [0.16411684 0.19628935 0.59159989 0.07903164 0.05999329]]

Matriks U (U_14):
[[1.1232800e-03 4.9506100e-03 2.0450000e-03 3.7803700e-03 7.9496000e-04
  8.2281500e-03 1.1517000e-03 3.1587000e-04 1.0641360e-02 1.7544100e-03
  1.8585500e-03 2.4652000e-04 3.1630900e-03 7.6035400e-03 1.4439580e-02
  4.1076830e-02 5.3698100e-03 4.6380000e-05 8.2628000e-03 1.2082400e-03
  5.1964000e-04 7.0939000e-04 7.5313000e-04 8.9691000e-04 1.8223000e-04
  2.5672000e-03 6.5750000e-05 4.5710000e-05 3.4610000e-05 6.6561000e-04
  1.3250600e-03 1.0631600e-03 9.1647300e-03 1.8832720e-02 1.5753300e-03
  5.5620000e-04 1.6709700e-03 2.0178900e-03 8.7656600e-03 2.8563000e-04
  4.0991000e-04 1.1795785e-01 4.8938900e-03 5.8740700e-03 7.5859800e-03
  8.7374400e-03 4.4463700e-03 4.4715500e-03 4.6796500e-03 2.4390400e-03
  8.0370088e-01 9.2357325e-01 8.1420635e-01 9.7315017e-01 9.6278221e-01
  9.9477073e-01 8.8393575e-01 8.4941984e-01 9.6229607e-01 9.7941428e-01
  8.6100280e-01 9.9231236e-01 9.6681798e-01 9.9417448e-01 9.9159132e-01
  9.1935196e-01 9.9091850e-01 9.9501526e-01 9.6277376e-01 9.9251431e-01
  8.6970813e-01 9.9940597e-01 9.7414893e-01 9.9804525e-01 9.9136120e-01
  9.5091466e-01 8.9215063e-01 6.5379598e-01 9.9738200e-01 9.8602418e-01
  9.8497041e-01 9.7681116e-01 9.9911940e-01 9.6174793e-01 9.8026410e-01
  8.2581398e-01 7.4566152e-01 9.6878874e-01 9.9249960e-01 9.9140017e-01
  9.9293514e-01 9.7694048e-01 9.9563007e-01 9.0080598e-01 9.9450996e-01
  9.8606065e-01 9.9093515e-01 9.7746010e-01 9.0865248e-01 9.8931157e-01
  4.6797790e-02 5.6109135e-01 1.4434560e-02 1.1071304e-01 1.0273520e-02
  4.1789550e-02 8.4239455e-01 3.9243750e-02 1.0957851e-01 3.9736780e-02
  1.5654800e-02 6.1888230e-02 1.1893200e-03 4.1804873e-01 1.1779159e-01
  8.6158600e-03 9.5543800e-03 6.9046600e-02 5.6558660e-02 6.6717658e-01
  2.3182800e-03 2.8199488e-01 4.1062580e-02 1.1096464e-01 1.4100500e-03
  1.0784540e-02 1.1067956e-01 8.1802690e-02 2.9471300e-03 2.7717930e-02
  1.6989520e-02 7.2663860e-02 3.7162200e-03 1.7930240e-01 3.0189488e-01
  2.1467380e-02 1.5251370e-02 7.9683100e-03 9.6672320e-02 1.2269800e-03
  3.8013000e-03 4.9771700e-03 1.2879700e-01 3.7601700e-03 1.0774520e-02
  5.0247800e-03 8.3223690e-02 6.5861200e-03 2.2611100e-02 8.4393020e-02]
 [2.0239000e-04 7.5968000e-04 3.4320000e-04 6.0355000e-04 1.4803000e-04
  1.6549600e-03 1.9791000e-04 5.2190000e-05 1.6754800e-03 2.6981000e-04
  3.4851000e-04 4.0200000e-05 4.8159000e-04 1.3215000e-03 3.4003800e-03
  1.1632850e-02 1.0985500e-03 7.5300000e-06 1.5464400e-03 2.2835000e-04
  7.6610000e-05 1.2216000e-04 1.4645000e-04 1.1062000e-04 2.6880000e-05
  3.2792000e-04 9.1200000e-06 7.2500000e-06 5.2900000e-06 9.4680000e-05
  1.7739000e-04 1.4386000e-04 2.1537600e-03 4.7315800e-03 2.2039000e-04
  8.1090000e-05 2.7080000e-04 2.8058000e-04 1.3081100e-03 4.2080000e-05
  6.4760000e-05 1.5933030e-02 7.7409000e-04 7.8056000e-04 1.2689100e-03
  1.0935500e-03 8.3082000e-04 6.6040000e-04 8.2608000e-04 3.5079000e-04
  1.6705348e-01 6.2107600e-02 1.6711432e-01 1.4301200e-02 3.2347200e-02
  3.4047900e-03 1.0153536e-01 2.8856140e-02 3.1654130e-02 1.0332240e-02
  4.4075790e-02 5.9566900e-03 1.8580910e-02 4.9851300e-03 4.1110700e-03
  7.1586210e-02 7.2429300e-03 2.6207600e-03 3.2595740e-02 3.9843800e-03
  1.2290701e-01 4.5990000e-04 2.4232770e-02 1.6512300e-03 7.5568600e-03
  4.5456900e-02 1.0303170e-01 3.4087189e-01 2.4142800e-03 6.7148400e-03
  8.8027300e-03 1.2019220e-02 6.4198000e-04 3.7101600e-02 1.7036250e-02
  1.6395296e-01 2.4868060e-01 2.8268780e-02 5.9730300e-03 6.6895300e-03
  5.6559500e-03 2.1989230e-02 3.5428500e-03 4.3555340e-02 4.6712600e-03
  1.1553990e-02 7.9255100e-03 2.1189040e-02 4.2236180e-02 9.3629300e-03
  9.5090537e-01 4.3509608e-01 9.8507965e-01 8.8817319e-01 9.8946288e-01
  9.5578020e-01 1.4107901e-01 9.5931841e-01 8.8862363e-01 9.5692445e-01
  9.8400099e-01 9.3738466e-01 9.9877883e-01 5.7631811e-01 8.7882347e-01
  9.9108316e-01 9.9028409e-01 9.2308699e-01 9.3957500e-01 3.2433084e-01
  9.9757381e-01 7.1299065e-01 9.5639252e-01 8.8762201e-01 9.9853074e-01
  9.8871742e-01 8.8775853e-01 9.1677897e-01 9.9697402e-01 9.7120064e-01
  9.8221157e-01 9.1848297e-01 9.9616372e-01 8.1758863e-01 6.9209865e-01
  9.7695695e-01 9.8380488e-01 9.9178258e-01 9.0085326e-01 9.9871638e-01
  9.9598953e-01 9.9475439e-01 8.6760753e-01 9.9601378e-01 9.8846175e-01
  9.9472037e-01 9.1420675e-01 9.9314703e-01 9.7588039e-01 9.1249125e-01]
 [9.9867433e-01 9.9428971e-01 9.9761180e-01 9.9561608e-01 9.9905701e-01
  9.9011689e-01 9.9865039e-01 9.9963194e-01 9.8768316e-01 9.9797577e-01
  9.9779295e-01 9.9971328e-01 9.9635533e-01 9.9107496e-01 9.8216004e-01
  9.4729032e-01 9.9353164e-01 9.9994610e-01 9.9019076e-01 9.9856340e-01
  9.9940375e-01 9.9916845e-01 9.9910043e-01 9.9899247e-01 9.9979089e-01
  9.9710488e-01 9.9992513e-01 9.9994703e-01 9.9996009e-01 9.9923971e-01
  9.9849755e-01 9.9879298e-01 9.8868151e-01 9.7643570e-01 9.9820428e-01
  9.9936271e-01 9.9805822e-01 9.9770152e-01 9.8992623e-01 9.9967229e-01
  9.9952533e-01 8.6610912e-01 9.9433202e-01 9.9334537e-01 9.9114511e-01
  9.9016901e-01 9.9472281e-01 9.9486806e-01 9.9449427e-01 9.9721017e-01
  2.9245640e-02 1.4319150e-02 1.8679330e-02 1.2548630e-02 4.8705900e-03
  1.8244800e-03 1.4528890e-02 1.2172401e-01 6.0497900e-03 1.0253470e-02
  9.4921410e-02 1.7309500e-03 1.4601110e-02 8.4038000e-04 4.2976100e-03
  9.0618300e-03 1.8385700e-03 2.3639800e-03 4.6305000e-03 3.5013100e-03
  7.3848600e-03 1.3413000e-04 1.6183100e-03 3.0353000e-04 1.0819400e-03
  3.6284400e-03 4.8176700e-03 5.3321300e-03 2.0372000e-04 7.2609800e-03
  6.2268600e-03 1.1169620e-02 2.3862000e-04 1.1504700e-03 2.6996600e-03
  1.0233070e-02 5.6578800e-03 2.9424800e-03 1.5273600e-03 1.9102900e-03
  1.4089000e-03 1.0702800e-03 8.2709000e-04 5.5638670e-02 8.1878000e-04
  2.3853600e-03 1.1393400e-03 1.3508600e-03 4.9111330e-02 1.3255000e-03
  2.2968400e-03 3.8125700e-03 4.8580000e-04 1.1137700e-03 2.6360000e-04
  2.4302500e-03 1.6526440e-02 1.4378300e-03 1.7978600e-03 3.3387700e-03
  3.4421000e-04 7.2711000e-04 3.1850000e-05 5.6331600e-03 3.3849400e-03
  3.0097000e-04 1.6153000e-04 7.8664100e-03 3.8663400e-03 8.4925800e-03
  1.0791000e-04 5.0144600e-03 2.5448900e-03 1.4133600e-03 5.9210000e-05
  4.9804000e-04 1.5619100e-03 1.4183400e-03 7.8850000e-05 1.0814300e-03
  7.9891000e-04 8.8531700e-03 1.2006000e-04 3.1089700e-03 6.0064700e-03
  1.5756700e-03 9.4375000e-04 2.4911000e-04 2.4744200e-03 5.6640000e-05
  2.0916000e-04 2.6844000e-04 3.5954800e-03 2.2606000e-04 7.6373000e-04
  2.5485000e-04 2.5695700e-03 2.6684000e-04 1.5085200e-03 3.1157300e-03]]

Fungsi Objektif (J_14): 7.88415102

Akurasi Iterasi 14: 98.00%

--- ITERASI 15 ---
Cluster Pusat (V_15):
[[0.51313686 0.44314871 0.31155774 0.5543925  0.51396601]
 [0.84032638 0.66387909 0.42702017 0.78155369 0.81641808]
 [0.16411687 0.19628933 0.5915998  0.07903165 0.05999331]]

Matriks U (U_15):
[[1.1232700e-03 4.9505600e-03 2.0449900e-03 3.7803300e-03 7.9496000e-04
  8.2281100e-03 1.1516900e-03 3.1587000e-04 1.0641250e-02 1.7544000e-03
  1.8585400e-03 2.4652000e-04 3.1630500e-03 7.6034700e-03 1.4439520e-02
  4.1076690e-02 5.3697800e-03 4.6380000e-05 8.2627500e-03 1.2082400e-03
  5.1964000e-04 7.0938000e-04 7.5312000e-04 8.9690000e-04 1.8223000e-04
  2.5671700e-03 6.5750000e-05 4.5710000e-05 3.4610000e-05 6.6560000e-04
  1.3250400e-03 1.0631500e-03 9.1646900e-03 1.8832640e-02 1.5753100e-03
  5.5620000e-04 1.6709600e-03 2.0178700e-03 8.7655600e-03 2.8562000e-04
  4.0991000e-04 1.1795666e-01 4.8938400e-03 5.8740100e-03 7.5859300e-03
  8.7373400e-03 4.4463400e-03 4.4715000e-03 4.6796100e-03 2.4390200e-03
  8.0370301e-01 9.2357450e-01 8.1420906e-01 9.7314975e-01 9.6278305e-01
  9.9477065e-01 8.8393805e-01 8.4941743e-01 9.6229680e-01 9.7941394e-01
  8.6100129e-01 9.9231250e-01 9.6681756e-01 9.9417469e-01 9.9159109e-01
  9.1935381e-01 9.9091868e-01 9.9501505e-01 9.6277436e-01 9.9251403e-01
  8.6971224e-01 9.9940597e-01 9.7414996e-01 9.9804531e-01 9.9136153e-01
  9.5091646e-01 8.9215412e-01 6.5380512e-01 9.9738225e-01 9.8602379e-01
  9.8497011e-01 9.7681070e-01 9.9911936e-01 9.6175038e-01 9.8026468e-01
  8.2581899e-01 7.4566944e-01 9.6878947e-01 9.9249974e-01 9.9140015e-01
  9.9293516e-01 9.7694203e-01 9.9563007e-01 9.0080521e-01 9.9451006e-01
  9.8606097e-01 9.9093546e-01 9.7746131e-01 9.0865191e-01 9.8931189e-01
  4.6798050e-02 5.6110588e-01 1.4434440e-02 1.1072010e-01 1.0273840e-02
  4.1789000e-02 8.4239753e-01 3.9243820e-02 1.0958288e-01 3.9736050e-02
  1.5655590e-02 6.1892910e-02 1.1893400e-03 4.1806045e-01 1.1779565e-01
  8.6160400e-03 9.5552900e-03 6.9045600e-02 5.6558250e-02 6.6718461e-01
  2.3181400e-03 2.8200520e-01 4.1062140e-02 1.1097194e-01 1.4099800e-03
  1.0784320e-02 1.1068672e-01 8.1807980e-02 2.9473900e-03 2.7718150e-02
  1.6989360e-02 7.2662890e-02 3.7164300e-03 1.7931039e-01 3.0190383e-01
  2.1466840e-02 1.5251330e-02 7.9687600e-03 9.6677050e-02 1.2269200e-03
  3.8011900e-03 4.9770700e-03 1.2880235e-01 3.7600000e-03 1.0774280e-02
  5.0247700e-03 8.3226960e-02 6.5863600e-03 2.2611220e-02 8.4396280e-02]
 [2.0239000e-04 7.5967000e-04 3.4320000e-04 6.0354000e-04 1.4802000e-04
  1.6549500e-03 1.9791000e-04 5.2180000e-05 1.6754600e-03 2.6981000e-04
  3.4850000e-04 4.0200000e-05 4.8158000e-04 1.3214900e-03 3.4003700e-03
  1.1632810e-02 1.0985500e-03 7.5300000e-06 1.5464400e-03 2.2835000e-04
  7.6610000e-05 1.2216000e-04 1.4645000e-04 1.1062000e-04 2.6880000e-05
  3.2791000e-04 9.1200000e-06 7.2500000e-06 5.2900000e-06 9.4680000e-05
  1.7739000e-04 1.4386000e-04 2.1537500e-03 4.7315600e-03 2.2039000e-04
  8.1090000e-05 2.7080000e-04 2.8058000e-04 1.3081000e-03 4.2080000e-05
  6.4760000e-05 1.5932900e-02 7.7408000e-04 7.8055000e-04 1.2689100e-03
  1.0935400e-03 8.3081000e-04 6.6039000e-04 8.2608000e-04 3.5079000e-04
  1.6705150e-01 6.2106460e-02 1.6711175e-01 1.4301320e-02 3.2346410e-02
  3.4048200e-03 1.0153321e-01 2.8856280e-02 3.1653460e-02 1.0332330e-02
  4.4075860e-02 5.9565700e-03 1.8581020e-02 4.9849400e-03 4.1111400e-03
  7.1584470e-02 7.2427600e-03 2.6208500e-03 3.2595150e-02 3.9845000e-03
  1.2290301e-01 4.5990000e-04 2.4231770e-02 1.6511700e-03 7.5565500e-03
  4.5455180e-02 1.0302829e-01 3.4086281e-01 2.4140500e-03 6.7149700e-03
  8.8028400e-03 1.2019360e-02 6.4201000e-04 3.7099190e-02 1.7035700e-02
  1.6394807e-01 2.4867275e-01 2.8268060e-02 5.9729000e-03 6.6895200e-03
  5.6559100e-03 2.1987730e-02 3.5428200e-03 4.3555280e-02 4.6711600e-03
  1.1553680e-02 7.9252100e-03 2.1187870e-02 4.2236070e-02 9.3626300e-03
  9.5090513e-01 4.3508154e-01 9.8507978e-01 8.8816609e-01 9.8946256e-01
  9.5578081e-01 1.4107601e-01 9.5931837e-01 8.8861922e-01 9.5692529e-01
  9.8400018e-01 9.3737995e-01 9.9877881e-01 5.7630632e-01 8.7881934e-01
  9.9108299e-01 9.9028317e-01 9.2308817e-01 9.3957548e-01 3.2432280e-01
  9.9757396e-01 7.1298023e-01 9.5639302e-01 8.8761464e-01 9.9853082e-01
  9.8871765e-01 8.8775129e-01 9.1677362e-01 9.9697375e-01 9.7120043e-01
  9.8221175e-01 9.1848413e-01 9.9616351e-01 8.1758055e-01 6.9208960e-01
  9.7695754e-01 9.8380494e-01 9.9178212e-01 9.0084845e-01 9.9871644e-01
  9.9598965e-01 9.9475450e-01 8.6760208e-01 9.9601395e-01 9.8846202e-01
  9.9472039e-01 9.1420341e-01 9.9314679e-01 9.7588027e-01 9.1248791e-01]
 [9.9867434e-01 9.9428977e-01 9.9761182e-01 9.9561613e-01 9.9905702e-01
  9.9011694e-01 9.9865040e-01 9.9963194e-01 9.8768328e-01 9.9797579e-01
  9.9779296e-01 9.9971328e-01 9.9635537e-01 9.9107505e-01 9.8216012e-01
  9.4729050e-01 9.9353167e-01 9.9994610e-01 9.9019081e-01 9.9856341e-01
  9.9940375e-01 9.9916846e-01 9.9910043e-01 9.9899248e-01 9.9979089e-01
  9.9710492e-01 9.9992513e-01 9.9994703e-01 9.9996009e-01 9.9923972e-01
  9.9849757e-01 9.9879299e-01 9.8868156e-01 9.7643580e-01 9.9820430e-01
  9.9936271e-01 9.9805824e-01 9.9770155e-01 9.8992634e-01 9.9967229e-01
  9.9952534e-01 8.6611044e-01 9.9433207e-01 9.9334544e-01 9.9114517e-01
  9.9016913e-01 9.9472285e-01 9.9486811e-01 9.9449431e-01 9.9721020e-01
  2.9245480e-02 1.4319040e-02 1.8679190e-02 1.2548930e-02 4.8705400e-03
  1.8245300e-03 1.4528740e-02 1.2172629e-01 6.0497400e-03 1.0253730e-02
  9.4922860e-02 1.7309400e-03 1.4601420e-02 8.4036000e-04 4.2977600e-03
  9.0617200e-03 1.8385600e-03 2.3641000e-03 4.6304900e-03 3.5014700e-03
  7.3847500e-03 1.3413000e-04 1.6182700e-03 3.0352000e-04 1.0819100e-03
  3.6283600e-03 4.8175900e-03 5.3320700e-03 2.0370000e-04 7.2612500e-03
  6.2270500e-03 1.1169940e-02 2.3863000e-04 1.1504200e-03 2.6996300e-03
  1.0232940e-02 5.6578000e-03 2.9424700e-03 1.5273600e-03 1.9103300e-03
  1.4089200e-03 1.0702400e-03 8.2710000e-04 5.5639500e-02 8.1878000e-04
  2.3853500e-03 1.1393300e-03 1.3508200e-03 4.9112020e-02 1.3254900e-03
  2.2968200e-03 3.8125800e-03 4.8578000e-04 1.1138100e-03 2.6361000e-04
  2.4301900e-03 1.6526450e-02 1.4378100e-03 1.7979000e-03 3.3386700e-03
  3.4422000e-04 7.2715000e-04 3.1850000e-05 5.6332300e-03 3.3850100e-03
  3.0098000e-04 1.6154000e-04 7.8662300e-03 3.8662700e-03 8.4925900e-03
  1.0790000e-04 5.0145700e-03 2.5448400e-03 1.4134200e-03 5.9210000e-05
  4.9803000e-04 1.5619800e-03 1.4184000e-03 7.8860000e-05 1.0814200e-03
  7.9889000e-04 8.8529700e-03 1.2006000e-04 3.1090600e-03 6.0065700e-03
  1.5756200e-03 9.4373000e-04 2.4912000e-04 2.4745000e-03 5.6640000e-05
  2.0916000e-04 2.6843000e-04 3.5955800e-03 2.2604000e-04 7.6370000e-04
  2.5484000e-04 2.5696400e-03 2.6685000e-04 1.5085100e-03 3.1158100e-03]]

Fungsi Objektif (J_15): 7.88414989

Akurasi Iterasi 15: 98.00%

--- ITERASI 16 ---
Cluster Pusat (V_16):
[[0.51313723 0.44314902 0.31155792 0.55439287 0.51396647]
 [0.84032658 0.66387991 0.42702071 0.78155413 0.8164186 ]
 [0.16411688 0.19628932 0.59159977 0.07903166 0.05999332]]

Matriks U (U_16):
[[1.1232700e-03 4.9505500e-03 2.0449800e-03 3.7803200e-03 7.9495000e-04
  8.2281000e-03 1.1516900e-03 3.1587000e-04 1.0641220e-02 1.7543900e-03
  1.8585300e-03 2.4652000e-04 3.1630400e-03 7.6034400e-03 1.4439490e-02
  4.1076640e-02 5.3697700e-03 4.6380000e-05 8.2627400e-03 1.2082300e-03
  5.1964000e-04 7.0938000e-04 7.5312000e-04 8.9690000e-04 1.8223000e-04
  2.5671600e-03 6.5750000e-05 4.5710000e-05 3.4610000e-05 6.6560000e-04
  1.3250300e-03 1.0631500e-03 9.1646700e-03 1.8832620e-02 1.5753000e-03
  5.5619000e-04 1.6709600e-03 2.0178600e-03 8.7655300e-03 2.8562000e-04
  4.0991000e-04 1.1795626e-01 4.8938300e-03 5.8739900e-03 7.5859100e-03
  8.7373000e-03 4.4463300e-03 4.4714800e-03 4.6796000e-03 2.4390100e-03
  8.0370370e-01 9.2357491e-01 8.1420994e-01 9.7314961e-01 9.6278332e-01
  9.9477062e-01 8.8393881e-01 8.4941662e-01 9.6229703e-01 9.7941383e-01
  8.6100079e-01 9.9231254e-01 9.6681743e-01 9.9417476e-01 9.9159101e-01
  9.1935442e-01 9.9091874e-01 9.9501498e-01 9.6277457e-01 9.9251393e-01
  8.6971365e-01 9.9940596e-01 9.7415032e-01 9.9804532e-01 9.9136164e-01
  9.5091706e-01 8.9215530e-01 6.5380823e-01 9.9738233e-01 9.8602365e-01
  9.8497001e-01 9.7681056e-01 9.9911935e-01 9.6175124e-01 9.8026489e-01
  8.2582072e-01 7.4567214e-01 9.6878973e-01 9.9249979e-01 9.9140015e-01
  9.9293517e-01 9.7694256e-01 9.9563008e-01 9.0080498e-01 9.9451011e-01
  9.8606109e-01 9.9093557e-01 9.7746173e-01 9.0865174e-01 9.8931200e-01
  4.6798130e-02 5.6111105e-01 1.4434390e-02 1.1072258e-01 1.0273950e-02
  4.1788780e-02 8.4239864e-01 3.9243820e-02 1.0958442e-01 3.9735770e-02
  1.5655870e-02 6.1894570e-02 1.1893400e-03 4.1806465e-01 1.1779711e-01
  8.6161000e-03 9.5556100e-03 6.9045230e-02 5.6558090e-02 6.6718751e-01
  2.3180800e-03 2.8200889e-01 4.1061980e-02 1.1097454e-01 1.4099500e-03
  1.0784240e-02 1.1068928e-01 8.1809870e-02 2.9474800e-03 2.7718220e-02
  1.6989290e-02 7.2662530e-02 3.7165000e-03 1.7931323e-01 3.0190704e-01
  2.1466640e-02 1.5251310e-02 7.9689300e-03 9.6678740e-02 1.2269000e-03
  3.8011600e-03 4.9770300e-03 1.2880427e-01 3.7599500e-03 1.0774190e-02
  5.0247600e-03 8.3228130e-02 6.5864500e-03 2.2611260e-02 8.4397450e-02]
 [2.0239000e-04 7.5967000e-04 3.4320000e-04 6.0354000e-04 1.4802000e-04
  1.6549500e-03 1.9791000e-04 5.2180000e-05 1.6754600e-03 2.6981000e-04
  3.4850000e-04 4.0200000e-05 4.8158000e-04 1.3214800e-03 3.4003600e-03
  1.1632800e-02 1.0985500e-03 7.5300000e-06 1.5464300e-03 2.2835000e-04
  7.6610000e-05 1.2216000e-04 1.4645000e-04 1.1062000e-04 2.6880000e-05
  3.2791000e-04 9.1200000e-06 7.2500000e-06 5.2900000e-06 9.4680000e-05
  1.7739000e-04 1.4386000e-04 2.1537400e-03 4.7315500e-03 2.2039000e-04
  8.1090000e-05 2.7080000e-04 2.8058000e-04 1.3081000e-03 4.2080000e-05
  6.4760000e-05 1.5932860e-02 7.7408000e-04 7.8055000e-04 1.2689000e-03
  1.0935300e-03 8.3081000e-04 6.6039000e-04 8.2608000e-04 3.5079000e-04
  1.6705087e-01 6.2106080e-02 1.6711091e-01 1.4301360e-02 3.2346150e-02
  3.4048300e-03 1.0153250e-01 2.8856320e-02 3.1653240e-02 1.0332360e-02
  4.4075860e-02 5.9565300e-03 1.8581050e-02 4.9848800e-03 4.1111700e-03
  7.1583900e-02 7.2427000e-03 2.6208800e-03 3.2594930e-02 3.9845400e-03
  1.2290164e-01 4.5991000e-04 2.4231420e-02 1.6511600e-03 7.5564500e-03
  4.5454600e-02 1.0302713e-01 3.4085971e-01 2.4139700e-03 6.7150100e-03
  8.8028800e-03 1.2019400e-02 6.4202000e-04 3.7098350e-02 1.7035500e-02
  1.6394638e-01 2.4867008e-01 2.8267810e-02 5.9728500e-03 6.6895100e-03
  5.6559000e-03 2.1987210e-02 3.5428100e-03 4.3555240e-02 4.6711100e-03
  1.1553570e-02 7.9251100e-03 2.1187470e-02 4.2236010e-02 9.3625100e-03
  9.5090506e-01 4.3507637e-01 9.8507983e-01 8.8816359e-01 9.8946245e-01
  9.5578105e-01 1.4107491e-01 9.5931837e-01 8.8861766e-01 9.5692560e-01
  9.8399990e-01 9.3737827e-01 9.9877880e-01 5.7630209e-01 8.7881786e-01
  9.9108293e-01 9.9028285e-01 9.2308861e-01 9.3957567e-01 3.2431990e-01
  9.9757402e-01 7.1297650e-01 9.5639321e-01 8.8761202e-01 9.9853084e-01
  9.8871774e-01 8.8774871e-01 9.1677171e-01 9.9697366e-01 9.7120036e-01
  9.8221182e-01 9.1848457e-01 9.9616343e-01 8.1757768e-01 6.9208635e-01
  9.7695776e-01 9.8380496e-01 9.9178195e-01 9.0084672e-01 9.9871646e-01
  9.9598969e-01 9.9475454e-01 8.6760011e-01 9.9601401e-01 9.8846211e-01
  9.9472040e-01 9.1420221e-01 9.9314670e-01 9.7588023e-01 9.1248671e-01]
 [9.9867434e-01 9.9428979e-01 9.9761183e-01 9.9561614e-01 9.9905702e-01
  9.9011695e-01 9.9865040e-01 9.9963194e-01 9.8768332e-01 9.9797580e-01
  9.9779296e-01 9.9971329e-01 9.9635538e-01 9.9107507e-01 9.8216014e-01
  9.4729057e-01 9.9353168e-01 9.9994610e-01 9.9019083e-01 9.9856341e-01
  9.9940376e-01 9.9916846e-01 9.9910043e-01 9.9899248e-01 9.9979089e-01
  9.9710493e-01 9.9992513e-01 9.9994703e-01 9.9996009e-01 9.9923972e-01
  9.9849758e-01 9.9879299e-01 9.8868158e-01 9.7643583e-01 9.9820431e-01
  9.9936272e-01 9.9805824e-01 9.9770156e-01 9.8992638e-01 9.9967230e-01
  9.9952534e-01 8.6611089e-01 9.9433209e-01 9.9334546e-01 9.9114519e-01
  9.9016917e-01 9.9472286e-01 9.9486813e-01 9.9449432e-01 9.9721021e-01
  2.9245440e-02 1.4319010e-02 1.8679150e-02 1.2549030e-02 4.8705300e-03
  1.8245500e-03 1.4528700e-02 1.2172706e-01 6.0497300e-03 1.0253810e-02
  9.4923340e-02 1.7309400e-03 1.4601520e-02 8.4036000e-04 4.2978200e-03
  9.0616900e-03 1.8385600e-03 2.3641400e-03 4.6304900e-03 3.5015300e-03
  7.3847100e-03 1.3413000e-04 1.6182600e-03 3.0352000e-04 1.0819100e-03
  3.6283400e-03 4.8175600e-03 5.3320600e-03 2.0370000e-04 7.2613400e-03
  6.2271200e-03 1.1170040e-02 2.3864000e-04 1.1504100e-03 2.6996200e-03
  1.0232900e-02 5.6577800e-03 2.9424600e-03 1.5273600e-03 1.9103400e-03
  1.4089300e-03 1.0702200e-03 8.2711000e-04 5.5639780e-02 8.1878000e-04
  2.3853400e-03 1.1393200e-03 1.3508000e-03 4.9112250e-02 1.3254800e-03
  2.2968100e-03 3.8125900e-03 4.8578000e-04 1.1138300e-03 2.6361000e-04
  2.4301700e-03 1.6526450e-02 1.4378100e-03 1.7979200e-03 3.3386300e-03
  3.4423000e-04 7.2716000e-04 3.1850000e-05 5.6332600e-03 3.3850300e-03
  3.0098000e-04 1.6154000e-04 7.8661600e-03 3.8662500e-03 8.4925900e-03
  1.0790000e-04 5.0146100e-03 2.5448200e-03 1.4134500e-03 5.9210000e-05
  4.9802000e-04 1.5620100e-03 1.4184200e-03 7.8860000e-05 1.0814200e-03
  7.9889000e-04 8.8529000e-03 1.2007000e-04 3.1090900e-03 6.0066100e-03
  1.5756000e-03 9.4373000e-04 2.4912000e-04 2.4745400e-03 5.6640000e-05
  2.0915000e-04 2.6843000e-04 3.5956200e-03 2.2604000e-04 7.6370000e-04
  2.5484000e-04 2.5696600e-03 2.6685000e-04 1.5085100e-03 3.1158400e-03]]

Fungsi Objektif (J_16): 7.88414948

Akurasi Iterasi 16: 98.00%

--- ITERASI 17 ---
Cluster Pusat (V_17):
[[0.51313737 0.44314913 0.31155798 0.55439299 0.51396663]
 [0.84032665 0.66388021 0.42702091 0.78155429 0.81641878]
 [0.16411688 0.19628932 0.59159976 0.07903166 0.05999332]]

Matriks U (U_17):
[[1.1232700e-03 4.9505400e-03 2.0449800e-03 3.7803100e-03 7.9495000e-04
  8.2280900e-03 1.1516800e-03 3.1587000e-04 1.0641200e-02 1.7543900e-03
  1.8585300e-03 2.4652000e-04 3.1630400e-03 7.6034400e-03 1.4439490e-02
  4.1076620e-02 5.3697700e-03 4.6380000e-05 8.2627300e-03 1.2082300e-03
  5.1964000e-04 7.0938000e-04 7.5312000e-04 8.9689000e-04 1.8223000e-04
  2.5671500e-03 6.5750000e-05 4.5710000e-05 3.4610000e-05 6.6560000e-04
  1.3250300e-03 1.0631500e-03 9.1646700e-03 1.8832610e-02 1.5753000e-03
  5.5619000e-04 1.6709500e-03 2.0178600e-03 8.7655200e-03 2.8562000e-04
  4.0991000e-04 1.1795612e-01 4.8938200e-03 5.8739800e-03 7.5859000e-03
  8.7372900e-03 4.4463300e-03 4.4714800e-03 4.6796000e-03 2.4390100e-03
  8.0370392e-01 9.2357504e-01 8.1421024e-01 9.7314956e-01 9.6278342e-01
  9.9477061e-01 8.8393906e-01 8.4941634e-01 9.6229711e-01 9.7941379e-01
  8.6100063e-01 9.9231255e-01 9.6681738e-01 9.9417478e-01 9.9159099e-01
  9.1935462e-01 9.9091877e-01 9.9501495e-01 9.6277465e-01 9.9251390e-01
  8.6971414e-01 9.9940596e-01 9.7415044e-01 9.9804533e-01 9.9136168e-01
  9.5091726e-01 8.9215571e-01 6.5380931e-01 9.9738236e-01 9.8602361e-01
  9.8496998e-01 9.7681051e-01 9.9911934e-01 9.6175155e-01 9.8026496e-01
  8.2582132e-01 7.4567307e-01 9.6878983e-01 9.9249981e-01 9.9140016e-01
  9.9293518e-01 9.7694275e-01 9.9563009e-01 9.0080491e-01 9.9451012e-01
  9.8606113e-01 9.9093561e-01 9.7746188e-01 9.0865169e-01 9.8931205e-01
  4.6798150e-02 5.6111289e-01 1.4434370e-02 1.1072346e-01 1.0273980e-02
  4.1788710e-02 8.4239905e-01 3.9243820e-02 1.0958496e-01 3.9735670e-02
  1.5655970e-02 6.1895150e-02 1.1893500e-03 4.1806616e-01 1.1779762e-01
  8.6161200e-03 9.5557200e-03 6.9045100e-02 5.6558030e-02 6.6718855e-01
  2.3180600e-03 2.8201022e-01 4.1061920e-02 1.1097546e-01 1.4099400e-03
  1.0784210e-02 1.1069019e-01 8.1810540e-02 2.9475100e-03 2.7718250e-02
  1.6989270e-02 7.2662400e-02 3.7165300e-03 1.7931425e-01 3.0190819e-01
  2.1466570e-02 1.5251300e-02 7.9689900e-03 9.6679350e-02 1.2268900e-03
  3.8011400e-03 4.9770200e-03 1.2880496e-01 3.7599300e-03 1.0774160e-02
  5.0247600e-03 8.3228550e-02 6.5864800e-03 2.2611280e-02 8.4397870e-02]
 [2.0239000e-04 7.5967000e-04 3.4320000e-04 6.0354000e-04 1.4802000e-04
  1.6549500e-03 1.9791000e-04 5.2180000e-05 1.6754600e-03 2.6981000e-04
  3.4850000e-04 4.0200000e-05 4.8158000e-04 1.3214800e-03 3.4003600e-03
  1.1632790e-02 1.0985500e-03 7.5300000e-06 1.5464300e-03 2.2835000e-04
  7.6610000e-05 1.2216000e-04 1.4645000e-04 1.1062000e-04 2.6880000e-05
  3.2791000e-04 9.1200000e-06 7.2500000e-06 5.2900000e-06 9.4680000e-05
  1.7739000e-04 1.4386000e-04 2.1537400e-03 4.7315500e-03 2.2039000e-04
  8.1090000e-05 2.7080000e-04 2.8058000e-04 1.3081000e-03 4.2080000e-05
  6.4760000e-05 1.5932840e-02 7.7408000e-04 7.8055000e-04 1.2689000e-03
  1.0935300e-03 8.3081000e-04 6.6039000e-04 8.2608000e-04 3.5079000e-04
  1.6705066e-01 6.2105960e-02 1.6711063e-01 1.4301370e-02 3.2346060e-02
  3.4048400e-03 1.0153226e-01 2.8856330e-02 3.1653170e-02 1.0332370e-02
  4.4075860e-02 5.9565100e-03 1.8581060e-02 4.9848600e-03 4.1111800e-03
  7.1583710e-02 7.2426800e-03 2.6208900e-03 3.2594860e-02 3.9845500e-03
  1.2290117e-01 4.5991000e-04 2.4231300e-02 1.6511500e-03 7.5564200e-03
  4.5454400e-02 1.0302673e-01 3.4085865e-01 2.4139500e-03 6.7150300e-03
  8.8028900e-03 1.2019410e-02 6.4202000e-04 3.7098050e-02 1.7035430e-02
  1.6394580e-01 2.4866916e-01 2.8267710e-02 5.9728400e-03 6.6895000e-03
  5.6558900e-03 2.1987030e-02 3.5428100e-03 4.3555230e-02 4.6711000e-03
  1.1553530e-02 7.9250700e-03 2.1187320e-02 4.2235980e-02 9.3624700e-03
  9.5090504e-01 4.3507453e-01 9.8507985e-01 8.8816271e-01 9.8946241e-01
  9.5578114e-01 1.4107450e-01 9.5931837e-01 8.8861712e-01 9.5692571e-01
  9.8399980e-01 9.3737768e-01 9.9877880e-01 5.7630058e-01 8.7881733e-01
  9.9108291e-01 9.9028273e-01 9.2308877e-01 9.3957573e-01 3.2431885e-01
  9.9757404e-01 7.1297516e-01 9.5639328e-01 8.8761108e-01 9.9853085e-01
  9.8871778e-01 8.8774779e-01 9.1677103e-01 9.9697362e-01 9.7120034e-01
  9.8221184e-01 9.1848472e-01 9.9616340e-01 8.1757665e-01 6.9208519e-01
  9.7695784e-01 9.8380497e-01 9.9178189e-01 9.0084611e-01 9.9871647e-01
  9.9598971e-01 9.9475456e-01 8.6759941e-01 9.9601404e-01 9.8846215e-01
  9.9472040e-01 9.1420178e-01 9.9314667e-01 9.7588022e-01 9.1248628e-01]
 [9.9867435e-01 9.9428979e-01 9.9761183e-01 9.9561615e-01 9.9905702e-01
  9.9011696e-01 9.9865041e-01 9.9963195e-01 9.8768334e-01 9.9797580e-01
  9.9779296e-01 9.9971329e-01 9.9635539e-01 9.9107508e-01 9.8216016e-01
  9.4729059e-01 9.9353169e-01 9.9994610e-01 9.9019084e-01 9.9856341e-01
  9.9940376e-01 9.9916846e-01 9.9910043e-01 9.9899248e-01 9.9979089e-01
  9.9710493e-01 9.9992513e-01 9.9994703e-01 9.9996009e-01 9.9923972e-01
  9.9849758e-01 9.9879300e-01 9.8868159e-01 9.7643585e-01 9.9820431e-01
  9.9936272e-01 9.9805824e-01 9.9770156e-01 9.8992639e-01 9.9967230e-01
  9.9952534e-01 8.6611104e-01 9.9433210e-01 9.9334547e-01 9.9114520e-01
  9.9016918e-01 9.9472286e-01 9.9486814e-01 9.9449432e-01 9.9721021e-01
  2.9245420e-02 1.4319000e-02 1.8679130e-02 1.2549070e-02 4.8705200e-03
  1.8245500e-03 1.4528680e-02 1.2172733e-01 6.0497300e-03 1.0253840e-02
  9.4923510e-02 1.7309400e-03 1.4601560e-02 8.4036000e-04 4.2978300e-03
  9.0616800e-03 1.8385600e-03 2.3641600e-03 4.6304900e-03 3.5015500e-03
  7.3847000e-03 1.3413000e-04 1.6182600e-03 3.0352000e-04 1.0819000e-03
  3.6283300e-03 4.8175600e-03 5.3320500e-03 2.0369000e-04 7.2613700e-03
  6.2271400e-03 1.1170080e-02 2.3864000e-04 1.1504000e-03 2.6996100e-03
  1.0232880e-02 5.6577700e-03 2.9424600e-03 1.5273600e-03 1.9103400e-03
  1.4089300e-03 1.0702200e-03 8.2711000e-04 5.5639870e-02 8.1878000e-04
  2.3853400e-03 1.1393200e-03 1.3508000e-03 4.9112320e-02 1.3254800e-03
  2.2968100e-03 3.8125900e-03 4.8578000e-04 1.1138400e-03 2.6361000e-04
  2.4301600e-03 1.6526450e-02 1.4378100e-03 1.7979200e-03 3.3386200e-03
  3.4423000e-04 7.2716000e-04 3.1850000e-05 5.6332700e-03 3.3850400e-03
  3.0098000e-04 1.6155000e-04 7.8661300e-03 3.8662400e-03 8.4926000e-03
  1.0790000e-04 5.0146200e-03 2.5448100e-03 1.4134500e-03 5.9210000e-05
  4.9802000e-04 1.5620200e-03 1.4184300e-03 7.8860000e-05 1.0814200e-03
  7.9888000e-04 8.8528800e-03 1.2007000e-04 3.1091000e-03 6.0066200e-03
  1.5755900e-03 9.4373000e-04 2.4912000e-04 2.4745500e-03 5.6640000e-05
  2.0915000e-04 2.6843000e-04 3.5956300e-03 2.2604000e-04 7.6369000e-04
  2.5484000e-04 2.5696700e-03 2.6685000e-04 1.5085100e-03 3.1158500e-03]]

Fungsi Objektif (J_17): 7.88414933

Akurasi Iterasi 17: 98.00%

Konvergen pada iterasi 17.

### HASIL AKHIR UNTUK DATA IRIS ###
Cluster Tengah Final (V_final):
[[&#39;0,51313737&#39; &#39;0,44314913&#39; &#39;0,31155798&#39; &#39;0,55439299&#39; &#39;0,51396663&#39;]
 [&#39;0,84032665&#39; &#39;0,66388021&#39; &#39;0,42702091&#39; &#39;0,78155429&#39; &#39;0,81641878&#39;]
 [&#39;0,16411688&#39; &#39;0,19628932&#39; &#39;0,59159976&#39; &#39;0,07903166&#39; &#39;0,05999332&#39;]]

Matriks Keanggotaan Final (U_final):
[[&#39;0,00112327&#39; &#39;0,00495054&#39; &#39;0,00204498&#39; &#39;0,00378031&#39; &#39;0,00079495&#39;
  &#39;0,00822809&#39; &#39;0,00115168&#39; &#39;0,00031587&#39; &#39;0,01064120&#39; &#39;0,00175439&#39;
  &#39;0,00185853&#39; &#39;0,00024652&#39; &#39;0,00316304&#39; &#39;0,00760344&#39; &#39;0,01443949&#39;
  &#39;0,04107662&#39; &#39;0,00536977&#39; &#39;0,00004638&#39; &#39;0,00826273&#39; &#39;0,00120823&#39;
  &#39;0,00051964&#39; &#39;0,00070938&#39; &#39;0,00075312&#39; &#39;0,00089689&#39; &#39;0,00018223&#39;
  &#39;0,00256715&#39; &#39;0,00006575&#39; &#39;0,00004571&#39; &#39;0,00003461&#39; &#39;0,00066560&#39;
  &#39;0,00132503&#39; &#39;0,00106315&#39; &#39;0,00916467&#39; &#39;0,01883261&#39; &#39;0,00157530&#39;
  &#39;0,00055619&#39; &#39;0,00167095&#39; &#39;0,00201786&#39; &#39;0,00876552&#39; &#39;0,00028562&#39;
  &#39;0,00040991&#39; &#39;0,11795612&#39; &#39;0,00489382&#39; &#39;0,00587398&#39; &#39;0,00758590&#39;
  &#39;0,00873729&#39; &#39;0,00444633&#39; &#39;0,00447148&#39; &#39;0,00467960&#39; &#39;0,00243901&#39;
  &#39;0,80370392&#39; &#39;0,92357504&#39; &#39;0,81421024&#39; &#39;0,97314956&#39; &#39;0,96278342&#39;
  &#39;0,99477061&#39; &#39;0,88393906&#39; &#39;0,84941634&#39; &#39;0,96229711&#39; &#39;0,97941379&#39;
  &#39;0,86100063&#39; &#39;0,99231255&#39; &#39;0,96681738&#39; &#39;0,99417478&#39; &#39;0,99159099&#39;
  &#39;0,91935462&#39; &#39;0,99091877&#39; &#39;0,99501495&#39; &#39;0,96277465&#39; &#39;0,99251390&#39;
  &#39;0,86971414&#39; &#39;0,99940596&#39; &#39;0,97415044&#39; &#39;0,99804533&#39; &#39;0,99136168&#39;
  &#39;0,95091726&#39; &#39;0,89215571&#39; &#39;0,65380931&#39; &#39;0,99738236&#39; &#39;0,98602361&#39;
  &#39;0,98496998&#39; &#39;0,97681051&#39; &#39;0,99911934&#39; &#39;0,96175155&#39; &#39;0,98026496&#39;
  &#39;0,82582132&#39; &#39;0,74567307&#39; &#39;0,96878983&#39; &#39;0,99249981&#39; &#39;0,99140016&#39;
  &#39;0,99293518&#39; &#39;0,97694275&#39; &#39;0,99563009&#39; &#39;0,90080491&#39; &#39;0,99451012&#39;
  &#39;0,98606113&#39; &#39;0,99093561&#39; &#39;0,97746188&#39; &#39;0,90865169&#39; &#39;0,98931205&#39;
  &#39;0,04679815&#39; &#39;0,56111289&#39; &#39;0,01443437&#39; &#39;0,11072346&#39; &#39;0,01027398&#39;
  &#39;0,04178871&#39; &#39;0,84239905&#39; &#39;0,03924382&#39; &#39;0,10958496&#39; &#39;0,03973567&#39;
  &#39;0,01565597&#39; &#39;0,06189515&#39; &#39;0,00118935&#39; &#39;0,41806616&#39; &#39;0,11779762&#39;
  &#39;0,00861612&#39; &#39;0,00955572&#39; &#39;0,06904510&#39; &#39;0,05655803&#39; &#39;0,66718855&#39;
  &#39;0,00231806&#39; &#39;0,28201022&#39; &#39;0,04106192&#39; &#39;0,11097546&#39; &#39;0,00140994&#39;
  &#39;0,01078421&#39; &#39;0,11069019&#39; &#39;0,08181054&#39; &#39;0,00294751&#39; &#39;0,02771825&#39;
  &#39;0,01698927&#39; &#39;0,07266240&#39; &#39;0,00371653&#39; &#39;0,17931425&#39; &#39;0,30190819&#39;
  &#39;0,02146657&#39; &#39;0,01525130&#39; &#39;0,00796899&#39; &#39;0,09667935&#39; &#39;0,00122689&#39;
  &#39;0,00380114&#39; &#39;0,00497702&#39; &#39;0,12880496&#39; &#39;0,00375993&#39; &#39;0,01077416&#39;
  &#39;0,00502476&#39; &#39;0,08322855&#39; &#39;0,00658648&#39; &#39;0,02261128&#39; &#39;0,08439787&#39;]
 [&#39;0,00020239&#39; &#39;0,00075967&#39; &#39;0,00034320&#39; &#39;0,00060354&#39; &#39;0,00014802&#39;
  &#39;0,00165495&#39; &#39;0,00019791&#39; &#39;0,00005218&#39; &#39;0,00167546&#39; &#39;0,00026981&#39;
  &#39;0,00034850&#39; &#39;0,00004020&#39; &#39;0,00048158&#39; &#39;0,00132148&#39; &#39;0,00340036&#39;
  &#39;0,01163279&#39; &#39;0,00109855&#39; &#39;0,00000753&#39; &#39;0,00154643&#39; &#39;0,00022835&#39;
  &#39;0,00007661&#39; &#39;0,00012216&#39; &#39;0,00014645&#39; &#39;0,00011062&#39; &#39;0,00002688&#39;
  &#39;0,00032791&#39; &#39;0,00000912&#39; &#39;0,00000725&#39; &#39;0,00000529&#39; &#39;0,00009468&#39;
  &#39;0,00017739&#39; &#39;0,00014386&#39; &#39;0,00215374&#39; &#39;0,00473155&#39; &#39;0,00022039&#39;
  &#39;0,00008109&#39; &#39;0,00027080&#39; &#39;0,00028058&#39; &#39;0,00130810&#39; &#39;0,00004208&#39;
  &#39;0,00006476&#39; &#39;0,01593284&#39; &#39;0,00077408&#39; &#39;0,00078055&#39; &#39;0,00126890&#39;
  &#39;0,00109353&#39; &#39;0,00083081&#39; &#39;0,00066039&#39; &#39;0,00082608&#39; &#39;0,00035079&#39;
  &#39;0,16705066&#39; &#39;0,06210596&#39; &#39;0,16711063&#39; &#39;0,01430137&#39; &#39;0,03234606&#39;
  &#39;0,00340484&#39; &#39;0,10153226&#39; &#39;0,02885633&#39; &#39;0,03165317&#39; &#39;0,01033237&#39;
  &#39;0,04407586&#39; &#39;0,00595651&#39; &#39;0,01858106&#39; &#39;0,00498486&#39; &#39;0,00411118&#39;
  &#39;0,07158371&#39; &#39;0,00724268&#39; &#39;0,00262089&#39; &#39;0,03259486&#39; &#39;0,00398455&#39;
  &#39;0,12290117&#39; &#39;0,00045991&#39; &#39;0,02423130&#39; &#39;0,00165115&#39; &#39;0,00755642&#39;
  &#39;0,04545440&#39; &#39;0,10302673&#39; &#39;0,34085865&#39; &#39;0,00241395&#39; &#39;0,00671503&#39;
  &#39;0,00880289&#39; &#39;0,01201941&#39; &#39;0,00064202&#39; &#39;0,03709805&#39; &#39;0,01703543&#39;
  &#39;0,16394580&#39; &#39;0,24866916&#39; &#39;0,02826771&#39; &#39;0,00597284&#39; &#39;0,00668950&#39;
  &#39;0,00565589&#39; &#39;0,02198703&#39; &#39;0,00354281&#39; &#39;0,04355523&#39; &#39;0,00467110&#39;
  &#39;0,01155353&#39; &#39;0,00792507&#39; &#39;0,02118732&#39; &#39;0,04223598&#39; &#39;0,00936247&#39;
  &#39;0,95090504&#39; &#39;0,43507453&#39; &#39;0,98507985&#39; &#39;0,88816271&#39; &#39;0,98946241&#39;
  &#39;0,95578114&#39; &#39;0,14107450&#39; &#39;0,95931837&#39; &#39;0,88861712&#39; &#39;0,95692571&#39;
  &#39;0,98399980&#39; &#39;0,93737768&#39; &#39;0,99877880&#39; &#39;0,57630058&#39; &#39;0,87881733&#39;
  &#39;0,99108291&#39; &#39;0,99028273&#39; &#39;0,92308877&#39; &#39;0,93957573&#39; &#39;0,32431885&#39;
  &#39;0,99757404&#39; &#39;0,71297516&#39; &#39;0,95639328&#39; &#39;0,88761108&#39; &#39;0,99853085&#39;
  &#39;0,98871778&#39; &#39;0,88774779&#39; &#39;0,91677103&#39; &#39;0,99697362&#39; &#39;0,97120034&#39;
  &#39;0,98221184&#39; &#39;0,91848472&#39; &#39;0,99616340&#39; &#39;0,81757665&#39; &#39;0,69208519&#39;
  &#39;0,97695784&#39; &#39;0,98380497&#39; &#39;0,99178189&#39; &#39;0,90084611&#39; &#39;0,99871647&#39;
  &#39;0,99598971&#39; &#39;0,99475456&#39; &#39;0,86759941&#39; &#39;0,99601404&#39; &#39;0,98846215&#39;
  &#39;0,99472040&#39; &#39;0,91420178&#39; &#39;0,99314667&#39; &#39;0,97588022&#39; &#39;0,91248628&#39;]
 [&#39;0,99867435&#39; &#39;0,99428979&#39; &#39;0,99761183&#39; &#39;0,99561615&#39; &#39;0,99905702&#39;
  &#39;0,99011696&#39; &#39;0,99865041&#39; &#39;0,99963195&#39; &#39;0,98768334&#39; &#39;0,99797580&#39;
  &#39;0,99779296&#39; &#39;0,99971329&#39; &#39;0,99635539&#39; &#39;0,99107508&#39; &#39;0,98216016&#39;
  &#39;0,94729059&#39; &#39;0,99353169&#39; &#39;0,99994610&#39; &#39;0,99019084&#39; &#39;0,99856341&#39;
  &#39;0,99940376&#39; &#39;0,99916846&#39; &#39;0,99910043&#39; &#39;0,99899248&#39; &#39;0,99979089&#39;
  &#39;0,99710493&#39; &#39;0,99992513&#39; &#39;0,99994703&#39; &#39;0,99996009&#39; &#39;0,99923972&#39;
  &#39;0,99849758&#39; &#39;0,99879300&#39; &#39;0,98868159&#39; &#39;0,97643585&#39; &#39;0,99820431&#39;
  &#39;0,99936272&#39; &#39;0,99805824&#39; &#39;0,99770156&#39; &#39;0,98992639&#39; &#39;0,99967230&#39;
  &#39;0,99952534&#39; &#39;0,86611104&#39; &#39;0,99433210&#39; &#39;0,99334547&#39; &#39;0,99114520&#39;
  &#39;0,99016918&#39; &#39;0,99472286&#39; &#39;0,99486814&#39; &#39;0,99449432&#39; &#39;0,99721021&#39;
  &#39;0,02924542&#39; &#39;0,01431900&#39; &#39;0,01867913&#39; &#39;0,01254907&#39; &#39;0,00487052&#39;
  &#39;0,00182455&#39; &#39;0,01452868&#39; &#39;0,12172733&#39; &#39;0,00604973&#39; &#39;0,01025384&#39;
  &#39;0,09492351&#39; &#39;0,00173094&#39; &#39;0,01460156&#39; &#39;0,00084036&#39; &#39;0,00429783&#39;
  &#39;0,00906168&#39; &#39;0,00183856&#39; &#39;0,00236416&#39; &#39;0,00463049&#39; &#39;0,00350155&#39;
  &#39;0,00738470&#39; &#39;0,00013413&#39; &#39;0,00161826&#39; &#39;0,00030352&#39; &#39;0,00108190&#39;
  &#39;0,00362833&#39; &#39;0,00481756&#39; &#39;0,00533205&#39; &#39;0,00020369&#39; &#39;0,00726137&#39;
  &#39;0,00622714&#39; &#39;0,01117008&#39; &#39;0,00023864&#39; &#39;0,00115040&#39; &#39;0,00269961&#39;
  &#39;0,01023288&#39; &#39;0,00565777&#39; &#39;0,00294246&#39; &#39;0,00152736&#39; &#39;0,00191034&#39;
  &#39;0,00140893&#39; &#39;0,00107022&#39; &#39;0,00082711&#39; &#39;0,05563987&#39; &#39;0,00081878&#39;
  &#39;0,00238534&#39; &#39;0,00113932&#39; &#39;0,00135080&#39; &#39;0,04911232&#39; &#39;0,00132548&#39;
  &#39;0,00229681&#39; &#39;0,00381259&#39; &#39;0,00048578&#39; &#39;0,00111384&#39; &#39;0,00026361&#39;
  &#39;0,00243016&#39; &#39;0,01652645&#39; &#39;0,00143781&#39; &#39;0,00179792&#39; &#39;0,00333862&#39;
  &#39;0,00034423&#39; &#39;0,00072716&#39; &#39;0,00003185&#39; &#39;0,00563327&#39; &#39;0,00338504&#39;
  &#39;0,00030098&#39; &#39;0,00016155&#39; &#39;0,00786613&#39; &#39;0,00386624&#39; &#39;0,00849260&#39;
  &#39;0,00010790&#39; &#39;0,00501462&#39; &#39;0,00254481&#39; &#39;0,00141345&#39; &#39;0,00005921&#39;
  &#39;0,00049802&#39; &#39;0,00156202&#39; &#39;0,00141843&#39; &#39;0,00007886&#39; &#39;0,00108142&#39;
  &#39;0,00079888&#39; &#39;0,00885288&#39; &#39;0,00012007&#39; &#39;0,00310910&#39; &#39;0,00600662&#39;
  &#39;0,00157559&#39; &#39;0,00094373&#39; &#39;0,00024912&#39; &#39;0,00247455&#39; &#39;0,00005664&#39;
  &#39;0,00020915&#39; &#39;0,00026843&#39; &#39;0,00359563&#39; &#39;0,00022604&#39; &#39;0,00076369&#39;
  &#39;0,00025484&#39; &#39;0,00256967&#39; &#39;0,00026685&#39; &#39;0,00150851&#39; &#39;0,00311585&#39;]]

Cluster Penugasan (berdasarkan keanggotaan tertinggi):
Data [0.         0.22222222 0.625      0.06779661 0.04166667] -&gt; Klaster 2
Data [0.00671141 0.16666667 0.41666667 0.06779661 0.04166667] -&gt; Klaster 2
Data [0.01342282 0.11111111 0.5        0.05084746 0.04166667] -&gt; Klaster 2
Data [0.02013423 0.08333333 0.45833333 0.08474576 0.04166667] -&gt; Klaster 2
Data [0.02684564 0.19444444 0.66666667 0.06779661 0.04166667] -&gt; Klaster 2
Data [0.03355705 0.30555556 0.79166667 0.11864407 0.125     ] -&gt; Klaster 2
Data [0.04026846 0.08333333 0.58333333 0.06779661 0.08333333] -&gt; Klaster 2
Data [0.04697987 0.19444444 0.58333333 0.08474576 0.04166667] -&gt; Klaster 2
Data [0.05369128 0.02777778 0.375      0.06779661 0.04166667] -&gt; Klaster 2
Data [0.06040268 0.16666667 0.45833333 0.08474576 0.        ] -&gt; Klaster 2
Data [0.06711409 0.30555556 0.70833333 0.08474576 0.04166667] -&gt; Klaster 2
Data [0.0738255  0.13888889 0.58333333 0.10169492 0.04166667] -&gt; Klaster 2
Data [0.08053691 0.13888889 0.41666667 0.06779661 0.        ] -&gt; Klaster 2
Data [0.08724832 0.         0.41666667 0.01694915 0.        ] -&gt; Klaster 2
Data [0.09395973 0.41666667 0.83333333 0.03389831 0.04166667] -&gt; Klaster 2

### EVALUASI AKURASI DENGAN PSEUDO-TRUE-LABELS ###
Akurasi Clustering (setelah optimal mapping dengan pseudo-true-labels): 98.00%
Mapping Klaster ID ke Pseudo-True-Label ID terbaik: {&#39;Klaster 0&#39;: &#39;Pseudo-Label 1&#39;, &#39;Klaster 1&#39;: &#39;Pseudo-Label 2&#39;, &#39;Klaster 2&#39;: &#39;Pseudo-Label 0&#39;}

Catatan: Akurasi dihitung dengan mencoba semua permutasi pemetaan antara cluster hasil FCM dan label yang diasumsikan (pseudo-true-labels).

Distribusi Pseudo-True-Labels (diasumsikan setiap 50 data sama):
Pseudo-Label 0: 50 data
Pseudo-Label 1: 50 data
Pseudo-Label 2: 50 data

Distribusi Predicted Clusters:
Klaster 0: 53 data
Klaster 1: 47 data
Klaster 2: 50 data
</pre></div>
</div>
</div>
</div>
</section>
<section id="evaluasi-akurasi-dengan-pseudo-true-labels">
<h3>EVALUASI AKURASI DENGAN PSEUDO-TRUE-LABELS<a class="headerlink" href="#evaluasi-akurasi-dengan-pseudo-true-labels" title="Link to this heading">#</a></h3>
<p>Akurasi Clustering (setelah optimal mapping dengan pseudo-true-labels): 98.00% Mapping Klaster ID ke Pseudo-True-Label ID terbaik: {â€˜Klaster 0â€™: â€˜Pseudo-Label 1â€™, â€˜Klaster 1â€™: â€˜Pseudo-Label 0â€™, â€˜Klaster 2â€™: â€˜Pseudo-Label 2â€™} Catatan: Akurasi dihitung dengan mencoba semua permutasi pemetaan antara cluster hasil FCM dan label yang diasumsikan (pseudo-true-labels). Distribusi Pseudo-True-Labels (diasumsikan setiap 50 data sama): Pseudo-Label 0: 50 data Pseudo-Label 1: 50 data Pseudo-Label 2: 50 data Distribusi Predicted Clusters: Klaster 0: 53 data Klaster 1: 50 data Klaster 2: 47 data
Tentu, mari kita bedah hasil evaluasi akurasi Fuzzy C-Means (FCM) Clustering Anda pada dataset Iris! ğŸ‰ğŸ“Š</p>
<p>Laporan Hasil Evaluasi Akurasi FCM Clustering pada Dataset Iris</p>
<p>Hasil evaluasi menunjukkan bahwa algoritma FCM berhasil mengelompokkan data Iris dengan tingkat akurasi yang sangat tinggi, yaitu 98.00%! âœ¨ Ini berarti sebagian besar titik data (98 dari setiap 100 data) ditempatkan pada klaster yang sesuai dengan â€œlabel asliâ€ yang kita asumsikan.</p>
<p>Kami menggunakan â€œpseudo-true-labelsâ€ karena FCM adalah metode unsupervised, yang berarti tidak menggunakan label asli saat pelatihan. Pseudo-label ini dibuat berdasarkan asumsi bahwa 50 data pertama adalah satu jenis, 50 data berikutnya jenis lain, dan 50 data terakhir jenis ketiga.</p>
<p>Detail Hasil:</p>
<p>Akurasi: Tingkat keberhasilan penempatan data ke klaster yang benar mencapai 98.00%. Angka ini didapatkan setelah sistem menemukan cara terbaik untuk â€œmencocokkanâ€ klaster hasil FCM dengan pseudo-label asli. ğŸ†
Pemetaan Klaster: Sistem menemukan pemetaan terbaik sebagai berikut:
Klaster 0 hasil FCM paling cocok dengan Pseudo-Label 1.
Klaster 1 hasil FCM paling cocok dengan Pseudo-Label 0.
Klaster 2 hasil FCM paling cocok dengan Pseudo-Label 2. Ini menunjukkan bahwa urutan klaster yang ditemukan oleh FCM (Klaster 0, 1, 2) mungkin tidak sama dengan urutan pseudo-label asli (Label 0, 1, 2), tetapi isinya sangat mirip. ğŸ—ºï¸ğŸ”„
Distribusi Data:
Pseudo-label asli memiliki distribusi merata: 50 data per label (0, 1, dan 2).
Klaster hasil prediksi FCM juga memiliki distribusi yang sangat mirip: 53 data di Klaster 0, 50 data di Klaster 1, dan 47 data di Klaster 2. Perbedaan kecil ini wajar dalam proses clustering. ğŸ“ŠğŸ”
Kesimpulan:</p>
<p>Secara keseluruhan, performa FCM pada dataset Iris dengan parameter yang Anda gunakan sangat memuaskan. Tingkat akurasi 98% menunjukkan bahwa algoritma ini mampu memisahkan kelompok-kelompok dalam data Iris dengan sangat efektif, sejalan dengan struktur yang kita harapkan dari dataset ini. Meskipun ada sedikit perbedaan dalam jumlah data per klaster hasil prediksi dibandingkan pseudo-label, pemetaan terbaik yang ditemukan mengkonfirmasi bahwa klaster-klaster tersebut secara substansial sesuai dengan kelompok data yang seharusnya.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">silhouette_samples</span><span class="p">,</span> <span class="n">silhouette_score</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.cm</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cm</span>

<span class="c1"># Asumsikan Anda sudah memiliki variabel X_scaled_iris (data yang sudah dinormalisasi)</span>
<span class="c1"># dan predicted_labels_iris (label hasil clustering FCM, hard assignment)</span>
<span class="c1"># serta n_clusters_iris (jumlah cluster yang digunakan)</span>

<span class="c1"># Pastikan data dan label ada dan memiliki panjang yang sama</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_scaled_iris</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted_labels_iris</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_scaled_iris</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted_labels_iris</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data atau label prediksi kosong, atau panjangnya tidak sesuai. Tidak dapat membuat silhouette plot.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># Hitung Silhouette Score untuk keseluruhan clustering</span>
    <span class="n">silhouette_avg</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_scaled_iris</span><span class="p">,</span> <span class="n">predicted_labels_iris</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Overall Silhouette Score untuk </span><span class="si">{</span><span class="n">n_clusters_iris</span><span class="si">}</span><span class="s2"> cluster (hasil FCM): </span><span class="si">{</span><span class="n">silhouette_avg</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Hitung Silhouette Coefficient untuk setiap sampel</span>
    <span class="n">sample_silhouette_values</span> <span class="o">=</span> <span class="n">silhouette_samples</span><span class="p">(</span><span class="n">X_scaled_iris</span><span class="p">,</span> <span class="n">predicted_labels_iris</span><span class="p">)</span>

    <span class="c1"># Buat Silhouette Plot</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

    <span class="n">y_lower</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters_iris</span><span class="p">):</span>
        <span class="c1"># Agregat silhouette scores untuk sampel yang termasuk dalam cluster i, dan urutkan</span>
        <span class="n">ith_cluster_silhouette_values</span> <span class="o">=</span> <span class="n">sample_silhouette_values</span><span class="p">[</span><span class="n">predicted_labels_iris</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">ith_cluster_silhouette_values</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

        <span class="n">size_cluster_i</span> <span class="o">=</span> <span class="n">ith_cluster_silhouette_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y_upper</span> <span class="o">=</span> <span class="n">y_lower</span> <span class="o">+</span> <span class="n">size_cluster_i</span>

        <span class="n">color</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">nipy_spectral</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_clusters_iris</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">fill_betweenx</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_lower</span><span class="p">,</span> <span class="n">y_upper</span><span class="p">),</span>
                          <span class="mi">0</span><span class="p">,</span> <span class="n">ith_cluster_silhouette_values</span><span class="p">,</span>
                          <span class="n">facecolor</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

        <span class="c1"># Label the silhouette plots with their cluster numbers at the middle</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">y_lower</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">size_cluster_i</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

        <span class="c1"># Compute the new y_lower for next plot</span>
        <span class="n">y_lower</span> <span class="o">=</span> <span class="n">y_upper</span> <span class="o">+</span> <span class="mi">10</span> <span class="c1"># 10 for the 0 samples</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Silhouette Plot for FCM Clustering with </span><span class="si">{</span><span class="n">n_clusters_iris</span><span class="si">}</span><span class="s2"> Clusters&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Silhouette Coefficient Values&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Cluster label&quot;</span><span class="p">)</span>

    <span class="c1"># The vertical line for average silhouette score of all the values</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">silhouette_avg</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Average Silhouette Score: </span><span class="si">{</span><span class="n">silhouette_avg</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>  <span class="c1"># Clear the y-axis labels / ticks</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">))</span> <span class="c1"># Set x-ticks from -0.1 to 1.0</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overall Silhouette Score untuk 3 cluster (hasil FCM): 0.5204
</pre></div>
</div>
<img alt="_images/4d41f5e4ba0c7764efe54aa3a0b84f3cb26cd96761796fb0dc594bfa02b08dab.png" src="_images/4d41f5e4ba0c7764efe54aa3a0b84f3cb26cd96761796fb0dc594bfa02b08dab.png" />
</div>
</div>
<p>Nilai Silhouette Score memberikan gambaran tentang seberapa baik setiap titik data cocok dengan klaster-nya sendiri dibandingkan dengan klaster tetangganya. Skor ini berkisar antara -1 hingga 1.</p>
<p>Nilai mendekati 1 berarti titik data sangat cocok dengan klaster-nya sendiri dan jauh dari klaster lain (pengelompokan sangat baik). ğŸ‘
Nilai mendekati 0 berarti titik data berada sangat dekat dengan batas antara dua klaster, dan mungkin bisa masuk ke klaster lain (pengelompokan tumpang tindih atau kurang jelas). âš ï¸
Nilai mendekati -1 berarti titik data kemungkinan besar salah diklasifikasikan ke klaster yang salah (pengelompokan sangat buruk). ğŸ‘
Dengan Overall Silhouette Score sebesar 0.5204 untuk 3 klaster:</p>
<p>Ini menunjukkan bahwa hasil clustering FCM Anda memiliki kualitas wajar (karena skor berada antara 0.5 dan 0.7). âœ¨
Mayoritas titik data cukup cocok dengan klaster tempat mereka ditugaskan dan ada pemisahan yang reasonable antar klaster.
Namun, karena skor tidak mendekati 1, mungkin ada beberapa titik data yang berada di dekat batas klaster atau tumpang tindih, yang bisa dilihat lebih detail pada silhouette plot per klaster.
Kesimpulan:</p>
<p>Skor 0.5204 mengindikasikan bahwa dengan 3 klaster, FCM berhasil membuat pengelompokan yang cukup baik dan dapat diterima. Data Iris memang dikenal cukup terpisah menjadi 3 kelompok, dan skor ini mencerminkan kemampuan algoritma FCM dalam menemukan struktur tersebut meskipun tidak sesempurna jika skor mendekati 1.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="UTS.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">UTS Analisis data</p>
      </div>
    </a>
    <a class="right-next"
       href="Decisiontree.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Memahami Decision Tree: Dari Konsep Hingga Perhitungan</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">ğŸ§© Clustering</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-clustering">ğŸ” Apa itu Clustering?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mengapa-clustering-penting">ğŸ¯ Mengapa Clustering Penting?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jenis-clustering">âš™ï¸ Jenis Clustering</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fokus-kita-k-means-clustering">ğŸ† Fokus Kita: K-Means Clustering</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#instalasi-pustaka-untuk-load-database-di-google-colab">ğŸ—ï¸ Instalasi Pustaka untuk Load Database di Google Colab</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mengapa-perlu-instalasi-pustaka">ğŸ” Mengapa Perlu Instalasi Pustaka?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-instalasi-pustaka">âš¡ Langkah Instalasi Pustaka</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#koneksi-ke-database-mysql-di-google-colab">ğŸ”— Koneksi ke Database MySQL di Google Colab</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-koneksi-ke-database">ğŸ“Œ Langkah Koneksi ke Database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#informasi-koneksi">ğŸ—ï¸ Informasi Koneksi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kode-koneksi-ke-database">âš¡ Kode Koneksi ke Database</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#menghitung-jarak-ke-centroid-dalam-k-means-clustering">ğŸ“ Menghitung Jarak ke Centroid dalam K-Means Clustering</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-jarak-ke-centroid">ğŸ” Apa Itu Jarak ke Centroid?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rumus-jarak-euclidean">ğŸ“ Rumus Jarak Euclidean</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#proses-perhitungan-jarak-dalam-k-means">âš™ï¸ Proses Perhitungan Jarak dalam K-Means</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mengapa-jarak-euclidean-digunakan">ğŸ† Mengapa Jarak Euclidean Digunakan?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-k-means-clustering-pada-dataset-iris">ğŸ“Š Implementasi K-Means Clustering pada Dataset Iris</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means">ğŸ”k-means</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-implementasi">âš™ï¸ Langkah-langkah Implementasi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-visualisasi">ğŸ¨ Hasil Visualisasi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#informasi-tambahan">ğŸ” Informasi tambahan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-akhir-k-means-clustering">Hasil Akhir K-Means Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#centroid-akhir">Centroid Akhir:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cluster-assignment-untuk-setiap-titik-data">Cluster Assignment untuk Setiap Titik Data:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#centroid-akhir-per-fitur-setiap-cluster">Centroid Akhir per Fitur (Setiap Cluster):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretasi-singkat">Interpretasi Singkat:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#memahami-inertia-dalam-k-means-clustering">ğŸ” Memahami Inertia dalam K-Means Clustering ğŸ’¡</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-inertia">ğŸ“Œ Apa Itu Inertia?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rumus-inertia">ğŸ“ Rumus Inertia</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#peran-inertia-dalam-menentukan-jumlah-klaster-optimal-k">ğŸ¯ Peran Inertia dalam Menentukan Jumlah Klaster Optimal (K)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretasi-nilai-inertia">ğŸ† Interpretasi Nilai Inertia</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#penjelasan-kode-mencari-inertia-untuk-k-means-clustering">Penjelasan Kode: Mencari Inertia untuk K-Means Clustering</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metode-elbow-menentukan-jumlah-cluster-optimal-dalam-k-means">ğŸ“‰ Metode Elbow: Menentukan Jumlah Cluster Optimal dalam K-Means</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cara-kerja-metode-elbow">âš™ï¸ Cara Kerja Metode Elbow</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#code-elbow">code elbow</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretasi-grafik-elbow">ğŸ’¡ Interpretasi Grafik Elbow</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metode-elbow-menentukan-jumlah-cluster-optimal-k-dalam-k-means-fokus-pada-k-3">ğŸ“‰ Metode Elbow: Menentukan Jumlah Cluster Optimal (K) dalam K-Means (Fokus pada K=3)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretasi-grafik-elbow-dengan-siku-di-k-3">âš™ï¸ Interpretasi Grafik Elbow dengan Siku di K=3</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#memahami-silhouette-score-dalam-clustering">Memahami Silhouette Score dalam Clustering ğŸ§â†”ï¸ğŸ§â€â™€ï¸</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rumus-silhouette-score">Rumus Silhouette Score ğŸ“</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretasi-nilai-silhouette-score">Interpretasi Nilai Silhouette Score ğŸ¤”</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan-sementara">Kesimpulan Sementara ğŸ¤”</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#penggunaan-silhouette-score-dalam-praktik">Penggunaan Silhouette Score dalam Praktik ğŸ› ï¸</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kelebihan-silhouette-score">Kelebihan Silhouette Score âœ¨</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kekurangan-silhouette-score">Kekurangan Silhouette Score âš ï¸</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#algoritma-fuzzy-c-mean-clustering-fcm">algoritma Fuzzy C-Mean Clustering (FCM)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-fcm">Langkah-langkah FCM:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#iterasi-1">Iterasi 1</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#perhitungan-pusat-cluster-v-1">1. Perhitungan Pusat Cluster (<span class="math notranslate nohighlight">\(V^{(1)}\)</span>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#perhitungan-matriks-keanggotaan-u-1">2. Perhitungan Matriks Keanggotaan (<span class="math notranslate nohighlight">\(U^{(1)}\)</span>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#perhitungan-fungsi-objektif-j-1-opsional-untuk-verifikasi">3. Perhitungan Fungsi Objektif (<span class="math notranslate nohighlight">\(J^{(1)}\)</span>) (Opsional, untuk verifikasi)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#normalisasi-data">normalisasi data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#penjelasan-normalisasi-min-max-scaling">Penjelasan Normalisasi (Min-Max Scaling)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mengapa-normalisasi-penting">Mengapa Normalisasi Penting?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bagaimana-minmaxscaler-bekerja">Bagaimana <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code> Bekerja?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-dalam-kode-anda">Implementasi dalam Kode Anda:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluasi-akurasi-dengan-pseudo-true-labels">EVALUASI AKURASI DENGAN PSEUDO-TRUE-LABELS</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By M. Aldi Rahmandika
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>